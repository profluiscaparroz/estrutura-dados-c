# M√©todos de Ordena√ß√£o em C

Este diret√≥rio cont√©m implementa√ß√µes completas e detalhadas de algoritmos cl√°ssicos de ordena√ß√£o em linguagem C, acompanhadas de an√°lises te√≥ricas profundas, exemplos pr√°ticos passo-a-passo e compara√ß√µes rigorosas de desempenho.

## üìñ Introdu√ß√£o aos Algoritmos de Ordena√ß√£o

### O que √© Ordena√ß√£o?

Ordena√ß√£o √© um processo fundamental em ci√™ncia da computa√ß√£o que consiste em **reorganizar uma sequ√™ncia de elementos em uma ordem espec√≠fica** (geralmente crescente ou decrescente). Este √© um dos problemas mais estudados e aplicados na computa√ß√£o, sendo essencial para:

- **Otimiza√ß√£o de Buscas**: Estruturas ordenadas permitem buscas eficientes (O(log n) vs O(n))
- **An√°lise de Dados**: Facilita identifica√ß√£o de medianas, quartis e outliers
- **Prepara√ß√£o para Algoritmos**: Muitos algoritmos requerem dados pr√©-ordenados
- **Interface com Usu√°rios**: Apresenta√ß√£o organizada de informa√ß√µes
- **Otimiza√ß√£o de I/O**: Acesso sequencial otimizado em sistemas de arquivos

### Conceitos Fundamentais

#### Estabilidade
Um algoritmo √© **est√°vel** quando mant√©m a ordem relativa de elementos com chaves iguais. Por exemplo, se temos dois registros com o mesmo valor de ordena√ß√£o, um algoritmo est√°vel garantir√° que a ordem original entre eles seja preservada.

**Exemplo Pr√°tico**: Ordenando uma lista de alunos primeiro por nome e depois por nota. Um algoritmo est√°vel mant√©m a ordem alfab√©tica para alunos com a mesma nota.

#### In-Place
Um algoritmo √© **in-place** quando requer apenas O(1) ou O(log n) de mem√≥ria adicional, al√©m do espa√ßo ocupado pela entrada. Isso significa que a ordena√ß√£o ocorre sobre o pr√≥prio array original, sem necessidade de copiar grandes volumes de dados.

#### Adaptatividade
Um algoritmo √© **adaptativo** quando seu desempenho melhora significativamente para entradas j√° parcialmente ordenadas. Por exemplo, o Insertion Sort atinge O(n) para arrays quase ordenados.

### Por que estudar diferentes algoritmos?

N√£o existe um "melhor algoritmo universal" de ordena√ß√£o. A escolha depende de:
- **Tamanho da entrada**: Algoritmos simples podem ser mais r√°pidos para pequenas entradas
- **Distribui√ß√£o dos dados**: Arrays quase ordenados, completamente aleat√≥rios, ou invertidos
- **Restri√ß√µes de mem√≥ria**: Alguns algoritmos requerem espa√ßo adicional significativo
- **Necessidade de estabilidade**: Quando a ordem relativa deve ser preservada
- **Hardware dispon√≠vel**: Cache, processadores paralelos, mem√≥ria dispon√≠vel

## üìÅ Arquivos Dispon√≠veis

### Algoritmos de Ordena√ß√£o Implementados

| Arquivo | Algoritmo | Complexidade (Tempo) | Complexidade (Espa√ßo) | Est√°vel | In-Place |
|---------|-----------|---------------------|----------------------|---------|----------|
| `bubbleSort.c` | Bubble Sort | O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `bubbleSortOptimized.c` | Bubble Sort Otimizado | O(n) a O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `insertSort.c` | Insertion Sort | O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `selectSort.c` | Selection Sort | O(n¬≤) | O(1) | ‚ùå N√£o | ‚úÖ Sim |
| `quickSort.c` | Quick Sort | O(n log n) avg, O(n¬≤) worst | O(log n) | ‚ùå N√£o | ‚úÖ Sim |
| `mergeSort.c` | Merge Sort | O(n log n) | O(n) | ‚úÖ Sim | ‚ùå N√£o |
| `heapSort.c` | Heap Sort | O(n log n) | O(1) | ‚ùå N√£o | ‚úÖ Sim |
| `shellSort.c` | Shell Sort | O(n^1.5) | O(1) | ‚ùå N√£o | ‚úÖ Sim |

### Ferramentas e Exemplos

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `comparacao.c` | Benchmark de performance entre algoritmos |
| `ordenacao_busca.c` | Integra√ß√£o de ordena√ß√£o com algoritmos de busca |
| `Makefile` | Sistema de compila√ß√£o automatizado |
| `README.md` | Esta documenta√ß√£o |

## üîç Detalhes dos Algoritmos

### 1. Bubble Sort (`bubbleSort.c`)

#### Explica√ß√£o Acad√™mica

O **Bubble Sort** √© um algoritmo de ordena√ß√£o por compara√ß√£o que recebe seu nome da forma como os elementos maiores "borbulham" para o topo (final) do array, assim como bolhas de ar sobem na √°gua. √â o algoritmo de ordena√ß√£o mais simples de entender e implementar, sendo frequentemente usado como introdu√ß√£o ao estudo de algoritmos.

**Princ√≠pio de Funcionamento:**
O algoritmo realiza m√∫ltiplas passagens pelo array, comparando pares de elementos adjacentes e trocando-os se estiverem fora de ordem. A cada passagem completa, o maior elemento ainda n√£o ordenado √© movido para sua posi√ß√£o final.

**An√°lise Matem√°tica da Complexidade:**
- **N√∫mero de compara√ß√µes**: No pior caso, s√£o necess√°rias n-1 compara√ß√µes na primeira passagem, n-2 na segunda, at√© 1 na √∫ltima. O total √©: (n-1) + (n-2) + ... + 1 = n(n-1)/2 = O(n¬≤)
- **N√∫mero de trocas**: No pior caso (array em ordem reversa), cada compara√ß√£o resulta em uma troca, totalizando O(n¬≤) trocas
- **Melhor caso**: Quando o array j√° est√° ordenado, s√£o feitas n-1 compara√ß√µes sem trocas, resultando em O(n) com a otimiza√ß√£o de flag

**Invariante do Algoritmo:**
Ap√≥s a i-√©sima itera√ß√£o do loop externo, os i maiores elementos est√£o em suas posi√ß√µes finais corretas no final do array.

**Como funciona:**
- Compara elementos adjacentes e os troca se estiverem fora de ordem
- Repete o processo at√© que nenhuma troca seja necess√°ria
- O maior elemento "borbulha" para o final a cada passagem
- A cada itera√ß√£o, o n√∫mero de compara√ß√µes necess√°rias diminui em 1

**Quando usar:**
- Listas muito pequenas (< 10 elementos) onde a simplicidade √© mais importante
- Fins educacionais para ensinar conceitos de ordena√ß√£o
- Quando simplicidade de implementa√ß√£o √© cr√≠tica
- Arrays que j√° est√£o quase ordenados (com a vers√£o otimizada)

**Exemplo de uso passo-a-passo:**
```c
int arr[] = {64, 34, 25, 12, 22, 11, 90};
int n = 7;

// Estado inicial: [64, 34, 25, 12, 22, 11, 90]

// Passagem 1:
// [34, 64, 25, 12, 22, 11, 90] (troca 64 e 34)
// [34, 25, 64, 12, 22, 11, 90] (troca 64 e 25)
// [34, 25, 12, 64, 22, 11, 90] (troca 64 e 12)
// [34, 25, 12, 22, 64, 11, 90] (troca 64 e 22)
// [34, 25, 12, 22, 11, 64, 90] (troca 64 e 11)
// [34, 25, 12, 22, 11, 64, 90] (64 < 90, sem troca)
// Resultado: 90 est√° na posi√ß√£o final

// Passagem 2:
// [25, 34, 12, 22, 11, 64, 90]
// [25, 12, 34, 22, 11, 64, 90]
// [25, 12, 22, 34, 11, 64, 90]
// [25, 12, 22, 11, 34, 64, 90]
// Resultado: 64 est√° na posi√ß√£o final

// ... continua at√© estar completamente ordenado
// Resultado final: [11, 12, 22, 25, 34, 64, 90]

bubbleSort(arr, n);
```

**Pseudoc√≥digo Formal:**
```
BUBBLE-SORT(A, n)
1  for i ‚Üê 1 to n-1
2      for j ‚Üê 1 to n-i
3          if A[j] > A[j+1]
4              swap A[j] with A[j+1]
```

### 2. Insertion Sort (`insertSort.c`)

#### Explica√ß√£o Acad√™mica

O **Insertion Sort** √© um algoritmo de ordena√ß√£o intuitivo que simula a forma como naturalmente ordenamos cartas em nossas m√£os. O algoritmo mant√©m uma sublista ordenada √† esquerda e insere, um por vez, cada elemento restante na posi√ß√£o correta dentro dessa sublista ordenada.

**Princ√≠pio de Funcionamento:**
O algoritmo divide conceitualmente o array em duas partes: uma parte ordenada (inicialmente contendo apenas o primeiro elemento) e uma parte n√£o ordenada (o restante). A cada itera√ß√£o, o algoritmo pega o primeiro elemento da parte n√£o ordenada e o insere na posi√ß√£o correta da parte ordenada.

**An√°lise Matem√°tica da Complexidade:**
- **Melhor caso (O(n))**: Quando o array j√° est√° ordenado, cada elemento requer apenas uma compara√ß√£o para confirmar que est√° na posi√ß√£o correta
- **Pior caso (O(n¬≤))**: Quando o array est√° em ordem reversa, cada novo elemento deve ser comparado com todos os elementos j√° ordenados e movido para o in√≠cio
- **Caso m√©dio (O(n¬≤))**: Em m√©dia, cada elemento precisa ser comparado com metade dos elementos j√° ordenados

**Caracter√≠sticas Especiais:**
- **Online**: Pode ordenar elementos conforme eles chegam (n√£o precisa ter todos os dados de uma vez)
- **Adaptativo**: Desempenho melhora significativamente com dados parcialmente ordenados
- **Est√°vel**: Mant√©m a ordem relativa de elementos iguais

**Como funciona:**
- Constr√≥i a lista ordenada um elemento por vez, da esquerda para a direita
- Insere cada elemento na posi√ß√£o correta em rela√ß√£o aos j√° ordenados
- Similar a organizar cartas na m√£o: voc√™ pega uma carta e a insere no lugar certo
- Elementos maiores s√£o "deslocados" para a direita para abrir espa√ßo

**Quando usar:**
- Arrays pequenos ou quase ordenados (extremamente eficiente nestes casos)
- Como parte de algoritmos h√≠bridos (ex: Timsort usa Insertion Sort para pequenos subarrays)
- Quando estabilidade √© importante
- Ordena√ß√£o online (dados chegando em tempo real)
- Quando a simplicidade de implementa√ß√£o √© cr√≠tica

**Exemplo de uso detalhado:**
```c
int arr[] = {12, 11, 13, 5, 6};
int n = 5;

// Estado inicial: [12, 11, 13, 5, 6]
// Parte ordenada: [12] | Parte n√£o ordenada: [11, 13, 5, 6]

// Itera√ß√£o 1: Inserir 11
// Comparar 11 com 12: 11 < 12, ent√£o mover 12 para direita
// Inserir 11 na posi√ß√£o 0
// Resultado: [11, 12, 13, 5, 6]
// Parte ordenada: [11, 12] | Parte n√£o ordenada: [13, 5, 6]

// Itera√ß√£o 2: Inserir 13
// Comparar 13 com 12: 13 > 12, j√° est√° no lugar certo
// Resultado: [11, 12, 13, 5, 6]
// Parte ordenada: [11, 12, 13] | Parte n√£o ordenada: [5, 6]

// Itera√ß√£o 3: Inserir 5
// Comparar 5 com 13: 5 < 13, mover 13
// Comparar 5 com 12: 5 < 12, mover 12
// Comparar 5 com 11: 5 < 11, mover 11
// Inserir 5 na posi√ß√£o 0
// Resultado: [5, 11, 12, 13, 6]
// Parte ordenada: [5, 11, 12, 13] | Parte n√£o ordenada: [6]

// Itera√ß√£o 4: Inserir 6
// Comparar 6 com 13: 6 < 13, mover 13
// Comparar 6 com 12: 6 < 12, mover 12
// Comparar 6 com 11: 6 < 11, mover 11
// Comparar 6 com 5: 6 > 5, inserir ap√≥s 5
// Resultado: [5, 6, 11, 12, 13]

insertionSort(arr, n);
// Resultado final: {5, 6, 11, 12, 13}
```

**Pseudoc√≥digo Formal:**
```
INSERTION-SORT(A, n)
1  for i ‚Üê 2 to n
2      key ‚Üê A[i]
3      j ‚Üê i - 1
4      while j > 0 and A[j] > key
5          A[j+1] ‚Üê A[j]
6          j ‚Üê j - 1
7      A[j+1] ‚Üê key
```

**Otimiza√ß√µes Poss√≠veis:**
- **Binary Insertion Sort**: Usar busca bin√°ria para encontrar a posi√ß√£o de inser√ß√£o (reduz compara√ß√µes mas n√£o trocas)
- **Shell Sort**: Varia√ß√£o que compara elementos distantes primeiro

### 3. Selection Sort (`selectSort.c`)

#### Explica√ß√£o Acad√™mica

O **Selection Sort** √© um algoritmo de ordena√ß√£o por compara√ß√£o que divide o array em duas partes: uma sublista ordenada e uma sublista n√£o ordenada. A cada itera√ß√£o, o algoritmo **seleciona** o menor (ou maior) elemento da parte n√£o ordenada e o move para o final da parte ordenada.

**Princ√≠pio de Funcionamento:**
O algoritmo mant√©m um invariante: ap√≥s i itera√ß√µes, os i menores elementos est√£o em suas posi√ß√µes finais corretas. Para cada posi√ß√£o no array, o algoritmo procura o menor elemento na parte n√£o ordenada e o coloca na posi√ß√£o atual.

**An√°lise Matem√°tica da Complexidade:**
- **Todas as varia√ß√µes (melhor, m√©dio e pior caso): O(n¬≤)**
- **Compara√ß√µes**: Sempre realiza exatamente (n-1) + (n-2) + ... + 1 = n(n-1)/2 compara√ß√µes
- **Trocas**: Realiza no m√°ximo n-1 trocas (uma por itera√ß√£o)
- A complexidade √© sempre O(n¬≤), independente da configura√ß√£o inicial dos dados

**Caracter√≠sticas Distintivas:**
- **N√∫mero m√≠nimo de trocas**: Entre os algoritmos O(n¬≤), realiza o menor n√∫mero de opera√ß√µes de troca
- **N√£o adaptativo**: N√£o se beneficia de dados parcialmente ordenados
- **N√£o est√°vel**: Pode alterar a ordem relativa de elementos iguais (mas pode ser tornado est√°vel com modifica√ß√µes)

**Como funciona:**
- Encontra o menor elemento e o coloca na primeira posi√ß√£o
- Encontra o segundo menor e o coloca na segunda posi√ß√£o
- Repete at√© ordenar toda a lista
- Em cada itera√ß√£o i, apenas a posi√ß√£o i √© modificada (ap√≥s encontrar o m√≠nimo)

**Quando usar:**
- Quando o n√∫mero de trocas deve ser minimizado (importante em sistemas onde escrever √© custoso)
- Listas pequenas onde simplicidade √© importante
- Quando a mem√≥ria √© extremamente limitada (O(1) adicional)
- Em sistemas embarcados onde opera√ß√µes de escrita s√£o caras

**Exemplo de uso detalhado:**
```c
int arr[] = {64, 25, 12, 22, 11};
int n = 5;

// Estado inicial: [64, 25, 12, 22, 11]

// Itera√ß√£o 1: Encontrar m√≠nimo de posi√ß√£o 0 at√© 4
// M√≠nimo encontrado: 11 (posi√ß√£o 4)
// Trocar arr[0] com arr[4]
// Resultado: [11, 25, 12, 22, 64]
// Parte ordenada: [11] | N√£o ordenada: [25, 12, 22, 64]

// Itera√ß√£o 2: Encontrar m√≠nimo de posi√ß√£o 1 at√© 4
// M√≠nimo encontrado: 12 (posi√ß√£o 2)
// Trocar arr[1] com arr[2]
// Resultado: [11, 12, 25, 22, 64]
// Parte ordenada: [11, 12] | N√£o ordenada: [25, 22, 64]

// Itera√ß√£o 3: Encontrar m√≠nimo de posi√ß√£o 2 at√© 4
// M√≠nimo encontrado: 22 (posi√ß√£o 3)
// Trocar arr[2] com arr[3]
// Resultado: [11, 12, 22, 25, 64]
// Parte ordenada: [11, 12, 22] | N√£o ordenada: [25, 64]

// Itera√ß√£o 4: Encontrar m√≠nimo de posi√ß√£o 3 at√© 4
// M√≠nimo encontrado: 25 (posi√ß√£o 3)
// Sem troca necess√°ria (j√° est√° no lugar)
// Resultado: [11, 12, 22, 25, 64]
// Parte ordenada: [11, 12, 22, 25] | N√£o ordenada: [64]

// √öltimo elemento j√° est√° ordenado
// Resultado final: [11, 12, 22, 25, 64]

selectionSort(arr, n);
// Total de trocas: 3 (muito menos que Bubble Sort)
```

**Pseudoc√≥digo Formal:**
```
SELECTION-SORT(A, n)
1  for i ‚Üê 1 to n-1
2      min ‚Üê i
3      for j ‚Üê i+1 to n
4          if A[j] < A[min]
5              min ‚Üê j
6      if min ‚â† i
7          swap A[i] with A[min]
```

**Compara√ß√£o com outros algoritmos O(n¬≤):**
- **vs Bubble Sort**: Menos trocas, mas sempre O(n¬≤)
- **vs Insertion Sort**: N√£o se adapta a dados parcialmente ordenados
- **Vantagem √∫nica**: M√≠nimo n√∫mero de escritas na mem√≥ria

### 4. Quick Sort (`quickSort.c`)

#### Explica√ß√£o Acad√™mica

O **Quick Sort** √© um dos algoritmos de ordena√ß√£o mais eficientes e amplamente utilizados na pr√°tica. Desenvolvido por Tony Hoare em 1959, ele utiliza a estrat√©gia de **divis√£o e conquista** (divide-and-conquer) para alcan√ßar um desempenho m√©dio de O(n log n).

**Princ√≠pio de Funcionamento:**
O algoritmo seleciona um elemento como **piv√¥** e particiona o array de forma que:
1. Todos os elementos menores que o piv√¥ ficam √† sua esquerda
2. Todos os elementos maiores que o piv√¥ ficam √† sua direita
3. O piv√¥ est√° em sua posi√ß√£o final correta
4. O processo √© aplicado recursivamente √†s sublistas esquerda e direita

**An√°lise Matem√°tica da Complexidade:**

**Melhor e Caso M√©dio: O(n log n)**
- Ocorre quando o piv√¥ divide o array aproximadamente ao meio a cada n√≠vel
- Profundidade da √°rvore de recurs√£o: log‚ÇÇ(n)
- Trabalho em cada n√≠vel: O(n) para particionar
- Total: O(n) √ó log(n) = O(n log n)

**Pior Caso: O(n¬≤)**
- Ocorre quando o piv√¥ √© sempre o menor ou maior elemento
- Array j√° ordenado ou em ordem reversa (com piv√¥ simples)
- Profundidade da recurs√£o: n
- Total: n + (n-1) + (n-2) + ... + 1 = O(n¬≤)

**An√°lise de Recorr√™ncia:**
- Melhor caso: T(n) = 2T(n/2) + O(n) = O(n log n) (Teorema Mestre)
- Pior caso: T(n) = T(n-1) + O(n) = O(n¬≤)

**Por que √© r√°pido na pr√°tica?**
1. **Constantes pequenas**: O fator constante no O(n log n) √© pequeno
2. **Cache-friendly**: Boa localidade de refer√™ncia
3. **In-place**: N√£o requer mem√≥ria adicional significativa
4. **Piv√¥ aleat√≥rio**: Com piv√¥ aleat√≥rio, o pior caso √© muito raro

**Como funciona:**
- Escolhe um piv√¥ e particiona o array
- Elementos menores ficam √† esquerda, maiores √† direita
- Aplica recursivamente o processo nas parti√ß√µes
- Piv√¥ fica em sua posi√ß√£o final a cada parti√ß√£o

**Quando usar:**
- Listas grandes (a escolha padr√£o para ordena√ß√£o de uso geral)
- Quando velocidade m√©dia √© importante
- Implementa√ß√£o padr√£o em muitas bibliotecas (qsort em C)
- Quando mem√≥ria extra √© limitada

**Exemplo de uso detalhado:**
```c
int arr[] = {10, 7, 8, 9, 1, 5};
int n = 6;

// Estado inicial: [10, 7, 8, 9, 1, 5]
// Escolher piv√¥: 5 (√∫ltimo elemento)

// Parti√ß√£o 1:
// i = -1
// j=0: arr[0]=10 > 5, n√£o faz nada
// j=1: arr[1]=7 > 5, n√£o faz nada  
// j=2: arr[2]=8 > 5, n√£o faz nada
// j=3: arr[3]=9 > 5, n√£o faz nada
// j=4: arr[4]=1 < 5, i++, trocar arr[0] e arr[4]
// Array: [1, 7, 8, 9, 10, 5]
// Colocar piv√¥ na posi√ß√£o correta: trocar arr[1] e arr[5]
// Array: [1, 5, 8, 9, 10, 7]
// Piv√¥ 5 est√° na posi√ß√£o 1 (posi√ß√£o final)

// Recurs√£o esquerda: [1] (j√° ordenado)
// Recurs√£o direita: [8, 9, 10, 7]

// Parti√ß√£o da direita (escolher 7 como piv√¥):
// Array: [1, 5, 7, 9, 10, 8]
// Piv√¥ 7 na posi√ß√£o 2

// Recurs√£o: [8, 9, 10]
// Array: [1, 5, 7, 8, 9, 10]

quickSort(arr, 0, n - 1);
// Resultado final: {1, 5, 7, 8, 9, 10}
```

**Pseudoc√≥digo Formal:**
```
QUICKSORT(A, p, r)
1  if p < r
2      q ‚Üê PARTITION(A, p, r)
3      QUICKSORT(A, p, q-1)
4      QUICKSORT(A, q+1, r)

PARTITION(A, p, r)
1  pivot ‚Üê A[r]
2  i ‚Üê p - 1
3  for j ‚Üê p to r-1
4      if A[j] ‚â§ pivot
5          i ‚Üê i + 1
6          swap A[i] with A[j]
7  swap A[i+1] with A[r]
8  return i + 1
```

**Estrat√©gias de Escolha de Piv√¥:**
1. **√öltimo elemento**: Simples, mas pior caso para arrays ordenados
2. **Primeiro elemento**: Similar ao √∫ltimo
3. **Elemento aleat√≥rio**: Evita pior caso com alta probabilidade
4. **Mediana de tr√™s**: Escolhe a mediana entre primeiro, meio e √∫ltimo (boa na pr√°tica)
5. **Mediana das medianas**: Garante O(n log n) mas com overhead

**Otimiza√ß√µes Avan√ßadas:**
- **Cutoff para Insertion Sort**: Usar Insertion Sort para subarrays pequenos (< 10 elementos)
- **Tail recursion**: Eliminar uma chamada recursiva
- **3-way partitioning**: Lidar eficientemente com elementos duplicados

### 5. Merge Sort (`mergeSort.c`)

#### Explica√ß√£o Acad√™mica

O **Merge Sort** √© um algoritmo de ordena√ß√£o baseado no paradigma de **divis√£o e conquista**, desenvolvido por John von Neumann em 1945. √â not√°vel por sua **garantia de complexidade O(n log n)** em todos os casos e por ser um algoritmo **est√°vel**.

**Princ√≠pio de Funcionamento:**
O algoritmo divide recursivamente o array em duas metades at√© que cada subarray contenha apenas um elemento (que est√° trivialmente ordenado). Em seguida, combina (merge) esses subarrays de forma ordenada, construindo progressivamente arrays maiores ordenados at√© reconstruir o array completo.

**An√°lise Matem√°tica da Complexidade:**

A rela√ß√£o de recorr√™ncia do Merge Sort √©:
```
T(n) = 2T(n/2) + O(n)
```
Onde:
- `2T(n/2)`: Ordenar duas metades do array
- `O(n)`: Tempo para combinar (merge) as duas metades ordenadas

**Aplicando o Teorema Mestre:**
- a = 2 (n√∫mero de subproblemas)
- b = 2 (tamanho de cada subproblema)
- f(n) = O(n) (trabalho para combinar)
- log_b(a) = log_2(2) = 1

Como f(n) = Œò(n^log_b(a)), aplicamos o caso 2 do Teorema Mestre:
**T(n) = Œò(n log n)**

**Profundidade da Recurs√£o**: log‚ÇÇ(n) n√≠veis
**Trabalho por n√≠vel**: O(n) compara√ß√µes e c√≥pias
**Total**: O(n) √ó log(n) = **O(n log n)** em todos os casos

**Caracter√≠sticas √önicas:**
- **Garantia de performance**: Sempre O(n log n), mesmo no pior caso
- **Est√°vel**: Mant√©m ordem relativa de elementos iguais
- **N√£o in-place**: Requer O(n) mem√≥ria adicional
- **Paraleliz√°vel**: As duas metades podem ser ordenadas em paralelo

**Como funciona:**
- Divide o array recursivamente ao meio at√© ter subarrays de tamanho 1
- Combina (merge) pares de subarrays ordenados em arrays maiores ordenados
- Repete o processo at√© reconstruir o array completo ordenado
- A opera√ß√£o de merge √© fundamental: combina dois arrays ordenados em um

**Quando usar:**
- Quando garantia de O(n log n) √© essencial (sistemas cr√≠ticos)
- Quando estabilidade √© requerida
- Quando mem√≥ria extra est√° dispon√≠vel
- Ordena√ß√£o externa (arquivos muito grandes)
- Dados em listas encadeadas (n√£o requer acesso aleat√≥rio)

**Exemplo de uso detalhado:**
```c
int arr[] = {38, 27, 43, 3, 9, 82, 10};
int n = 7;

// Divis√£o (fase top-down):
//          [38, 27, 43, 3, 9, 82, 10]
//         /                           \
//    [38, 27, 43, 3]              [9, 82, 10]
//    /            \                /         \
// [38, 27]      [43, 3]        [9, 82]      [10]
//  /    \        /   \          /   \
// [38] [27]    [43] [3]       [9] [82]

// Conquista (fase bottom-up - merge):

// N√≠vel 1: Merge de pares individuais
// [38] + [27] ‚Üí [27, 38]
// [43] + [3]  ‚Üí [3, 43]
// [9] + [82]  ‚Üí [9, 82]
// [10] permanece

// N√≠vel 2: Merge de pares ordenados
// [27, 38] + [3, 43]  ‚Üí [3, 27, 38, 43]
//   Passo a passo:
//   Compare 27 e 3:  3 < 27  ‚Üí [3]
//   Compare 27 e 43: 27 < 43 ‚Üí [3, 27]
//   Compare 38 e 43: 38 < 43 ‚Üí [3, 27, 38]
//   Restou 43              ‚Üí [3, 27, 38, 43]

// [9, 82] + [10] ‚Üí [9, 10, 82]
//   Compare 9 e 10:  9 < 10  ‚Üí [9]
//   Compare 82 e 10: 10 < 82 ‚Üí [9, 10]
//   Restou 82              ‚Üí [9, 10, 82]

// N√≠vel 3: Merge final
// [3, 27, 38, 43] + [9, 10, 82] ‚Üí [3, 9, 10, 27, 38, 43, 82]
//   Compare 3 e 9:   3 < 9   ‚Üí [3]
//   Compare 27 e 9:  9 < 27  ‚Üí [3, 9]
//   Compare 27 e 10: 10 < 27 ‚Üí [3, 9, 10]
//   Compare 27 e 82: 27 < 82 ‚Üí [3, 9, 10, 27]
//   Compare 38 e 82: 38 < 82 ‚Üí [3, 9, 10, 27, 38]
//   Compare 43 e 82: 43 < 82 ‚Üí [3, 9, 10, 27, 38, 43]
//   Restou 82              ‚Üí [3, 9, 10, 27, 38, 43, 82]

mergeSort(arr, 0, n - 1);
// Resultado final: {3, 9, 10, 27, 38, 43, 82}
```

**Pseudoc√≥digo Formal:**
```
MERGE-SORT(A, p, r)
1  if p < r
2      q ‚Üê ‚åä(p + r) / 2‚åã
3      MERGE-SORT(A, p, q)
4      MERGE-SORT(A, q+1, r)
5      MERGE(A, p, q, r)

MERGE(A, p, q, r)
1  n1 ‚Üê q - p + 1
2  n2 ‚Üê r - q
3  create arrays L[1..n1] and R[1..n2]
4  for i ‚Üê 1 to n1
5      L[i] ‚Üê A[p + i - 1]
6  for j ‚Üê 1 to n2
7      R[j] ‚Üê A[q + j]
8  i ‚Üê 1, j ‚Üê 1, k ‚Üê p
9  while i ‚â§ n1 and j ‚â§ n2
10     if L[i] ‚â§ R[j]
11         A[k] ‚Üê L[i]
12         i ‚Üê i + 1
13     else
14         A[k] ‚Üê R[j]
15         j ‚Üê j + 1
16     k ‚Üê k + 1
17 while i ‚â§ n1
18     A[k] ‚Üê L[i]
19     i ‚Üê i + 1, k ‚Üê k + 1
20 while j ‚â§ n2
21     A[k] ‚Üê R[j]
22     j ‚Üê j + 1, k ‚Üê k + 1
```

**Varia√ß√µes e Otimiza√ß√µes:**

1. **Bottom-Up Merge Sort (iterativo)**:
```c
// Evita recurs√£o, √∫til em sistemas com stack limitado
void mergeSortBottomUp(int arr[], int n) {
    for (int size = 1; size < n; size *= 2) {
        for (int start = 0; start < n - size; start += 2 * size) {
            int mid = start + size - 1;
            int end = min(start + 2 * size - 1, n - 1);
            merge(arr, start, mid, end);
        }
    }
}
```

2. **Natural Merge Sort**:
   - Detecta runs (sequ√™ncias j√° ordenadas) naturalmente presentes nos dados
   - Base do Tim Sort usado no Python

3. **In-Place Merge Sort**:
   - Reduz uso de mem√≥ria para O(1), mas com complexidade maior
   - Mais complexo de implementar

**Aplica√ß√µes Especiais:**

- **Ordena√ß√£o Externa**: Para arquivos maiores que a RAM
  ```
  Exemplo: Ordenar arquivo de 100GB com 8GB RAM
  1. Divide arquivo em chunks de 8GB
  2. Ordena cada chunk com Quick Sort
  3. Faz merge externo dos chunks ordenados
  ```

- **Listas Encadeadas**: Merge Sort √© ideal (O(1) extra)
  ```c
  // N√£o precisa de array auxiliar!
  Node* mergeSortList(Node* head) {
      if (!head || !head->next) return head;
      Node* mid = getMiddle(head);
      Node* left = head;
      Node* right = mid->next;
      mid->next = NULL;
      return merge(mergeSortList(left), mergeSortList(right));
  }
  ```

**Compara√ß√£o: Merge Sort vs Quick Sort**

| Aspecto | Merge Sort | Quick Sort |
|---------|-----------|------------|
| Pior caso | O(n log n) ‚úÖ | O(n¬≤) ‚ùå |
| M√©dio caso | O(n log n) | O(n log n) |
| Mem√≥ria | O(n) ‚ùå | O(log n) ‚úÖ |
| Est√°vel | Sim ‚úÖ | N√£o ‚ùå |
| Cache | Menos eficiente | Mais eficiente ‚úÖ |
| Paraleliza√ß√£o | F√°cil ‚úÖ | Mais dif√≠cil |

### 6. Heap Sort (`heapSort.c`)

#### Explica√ß√£o Acad√™mica

O **Heap Sort** √© um algoritmo de ordena√ß√£o baseado na estrutura de dados **heap bin√°rio**. Desenvolvido por J. W. J. Williams em 1964, combina as melhores caracter√≠sticas de Merge Sort (garantia O(n log n)) e Insertion Sort (in-place, O(1) extra).

**Estrutura de Dados: Heap Bin√°rio**

Um **max-heap** √© uma √°rvore bin√°ria completa onde cada n√≥ √© maior ou igual a seus filhos:
```
        90
       /  \
     85    30
    /  \   /
   70  10 15

Propriedade: arr[i] ‚â• arr[2i+1] e arr[i] ‚â• arr[2i+2]
```

**Representa√ß√£o em Array:**
```c
arr[] = [90, 85, 30, 70, 10, 15]
√çndices dos filhos de arr[i]:
- Filho esquerdo: 2*i + 1
- Filho direito:  2*i + 2
- Pai de arr[i]: (i-1)/2
```

**Princ√≠pio de Funcionamento:**

1. **Construir heap**: Transforma o array em um max-heap (O(n))
2. **Extra√ß√£o iterativa**: Remove o m√°ximo (raiz) e reconstr√≥i heap (n √ó O(log n))

**An√°lise Matem√°tica:**

**Fase 1 - Build Heap: O(n)**
```
Surpreendentemente, construir heap √© O(n), n√£o O(n log n)!

An√°lise:
- Altura h = log n
- N√≥s na altura h: n/2^(h+1)
- Custo de heapify na altura h: O(h)
- Total: Œ£(h=0 to log n) [n/2^(h+1) √ó h] = O(n)
```

**Fase 2 - Ordena√ß√£o: O(n log n)**
```
- n itera√ß√µes (uma por elemento)
- Cada itera√ß√£o: heapify O(log n)
- Total: n √ó log n = O(n log n)
```

**Como funciona:**
- Constr√≥i um max-heap a partir do array
- Troca o maior elemento (raiz) com o √∫ltimo
- Reduz o tamanho do heap e reconstr√≥i (heapify)
- Repete at√© ordenar todo o array
- Elementos v√£o sendo colocados em ordem no final do array

**Quando usar:**
- Quando garantia de O(n log n) √© necess√°ria **e** mem√≥ria √© limitada
- Sistemas em tempo real com requisitos previs√≠veis
- Quando estabilidade n√£o √© importante
- Implementa√ß√£o de fila de prioridade com ordena√ß√£o

**Exemplo de uso detalhado:**
```c
int arr[] = {12, 11, 13, 5, 6, 7};
int n = 6;

// Fase 1: Construir Max-Heap
// Array original: [12, 11, 13, 5, 6, 7]

// Come√ßar do √∫ltimo n√≥ n√£o-folha: i = n/2 - 1 = 2
// √çndice 2 (valor 13): j√° satisfaz propriedade heap
//       12
//      /  \
//    11    13
//   /  \   /
//  5   6  7

// √çndice 1 (valor 11): comparar com filhos (5, 6)
// 11 > 6, ok
//       12
//      /  \
//    11    13
//   /  \   /
//  5   6  7

// √çndice 0 (valor 12): comparar com filhos (11, 13)
// 12 < 13, trocar!
//       13
//      /  \
//    11    12
//   /  \   /
//  5   6  7

// Array ap√≥s build-heap: [13, 11, 12, 5, 6, 7]

// Fase 2: Ordena√ß√£o (extrair m√°ximo repetidamente)

// Itera√ß√£o 1:
// Trocar raiz (13) com √∫ltimo elemento (7)
// [7, 11, 12, 5, 6, | 13]
// Heapify na raiz:
//       12
//      /  \
//    11    7
//   /  \
//  5   6
// Array: [12, 11, 7, 5, 6, | 13]

// Itera√ß√£o 2:
// Trocar raiz (12) com √∫ltimo n√£o-ordenado (6)
// [6, 11, 7, 5, | 12, 13]
// Heapify:
//       11
//      /  \
//    6     7
//   /
//  5
// Array: [11, 6, 7, 5, | 12, 13]

// Itera√ß√£o 3:
// [5, 6, 7, | 11, 12, 13]
// Heapify:
//       7
//      /  \
//    6     5
// Array: [7, 6, 5, | 11, 12, 13]

// Itera√ß√£o 4:
// [5, 6, | 7, 11, 12, 13]
// Heapify:
//       6
//      /
//    5
// Array: [6, 5, | 7, 11, 12, 13]

// Itera√ß√£o 5:
// [5, | 6, 7, 11, 12, 13]

// Resultado final: [5, 6, 7, 11, 12, 13]

heapSort(arr, n);
```

**Pseudoc√≥digo Formal:**
```
HEAP-SORT(A, n)
1  BUILD-MAX-HEAP(A, n)
2  for i ‚Üê n downto 2
3      swap A[1] with A[i]
4      heap-size ‚Üê heap-size - 1
5      MAX-HEAPIFY(A, 1)

BUILD-MAX-HEAP(A, n)
1  heap-size ‚Üê n
2  for i ‚Üê ‚åän/2‚åã downto 1
3      MAX-HEAPIFY(A, i)

MAX-HEAPIFY(A, i)
1  l ‚Üê LEFT(i)
2  r ‚Üê RIGHT(i)
3  if l ‚â§ heap-size and A[l] > A[i]
4      largest ‚Üê l
5  else largest ‚Üê i
6  if r ‚â§ heap-size and A[r] > A[largest]
7      largest ‚Üê r
8  if largest ‚â† i
9      swap A[i] with A[largest]
10     MAX-HEAPIFY(A, largest)
```

**Aplica√ß√µes do Heap:**
- **Ordena√ß√£o**: Heap Sort
- **Fila de prioridade**: Hospitais (triagem), SO (escalonamento)
- **Algoritmo de Dijkstra**: Caminho mais curto
- **Huffman coding**: Compress√£o de dados
- **K maiores elementos**: Heap de tamanho k

### 7. Shell Sort (`shellSort.c`)

#### Explica√ß√£o Acad√™mica

O **Shell Sort**, desenvolvido por Donald Shell em 1959, √© uma **generaliza√ß√£o sofisticada do Insertion Sort**. Ele supera a limita√ß√£o do Insertion Sort de comparar apenas elementos adjacentes, usando uma sequ√™ncia de "gaps" (intervalos) decrescentes.

**Princ√≠pio de Funcionamento:**

Em vez de comparar elementos adjacentes (gap = 1), o Shell Sort come√ßa comparando elementos distantes e gradualmente reduz o gap at√© chegar a 1 (Insertion Sort normal). Esta estrat√©gia move elementos para perto de suas posi√ß√µes finais mais rapidamente.

**Como funciona:**
- Generaliza√ß√£o do Insertion Sort com gaps decrescentes
- Come√ßa comparando elementos distantes (gap grande)
- Reduz o gap progressivamente
- Termina com gap = 1 (Insertion Sort cl√°ssico)
- Array fica "quase ordenado" antes do passo final

**An√°lise de Complexidade:**

A complexidade depende **crucialmente da sequ√™ncia de gaps escolhida**:

| Sequ√™ncia de Gap | Complexidade | Autor |
|------------------|--------------|-------|
| n/2, n/4, ..., 1 | O(n¬≤) | Shell (original) |
| 2^k - 1 | O(n^1.5) | Hibbard |
| 2^i √ó 3^j | O(n log¬≤ n) | Pratt |
| (9√ó4^i - 9√ó2^i + 1)/5 | O(n^1.3) | Sedgewick |
| Desconhecido | ? | Ciura (melhor na pr√°tica) |

**Sequ√™ncias de Gap Comuns:**

1. **Shell Original**: n/2, n/4, n/8, ..., 1
   ```c
   for (gap = n/2; gap > 0; gap /= 2)
   ```
   - Simples mas pior caso O(n¬≤)

2. **Knuth**: (3^k - 1)/2 = 1, 4, 13, 40, 121, ...
   ```c
   gap = 1;
   while (gap < n/3) gap = 3*gap + 1;
   for (; gap > 0; gap /= 3)
   ```
   - Complexidade O(n^1.5)
   - Popular e eficiente

3. **Ciura**: 1, 4, 10, 23, 57, 132, 301, 701, 1750, ...
   ```c
   int gaps[] = {701, 301, 132, 57, 23, 10, 4, 1};
   ```
   - Melhor desempenho pr√°tico
   - Empiricamente determinado

**Quando usar:**
- Arrays de tamanho m√©dio (1000-5000 elementos)
- Quando simplicidade de implementa√ß√£o √© importante
- Como alternativa ao Insertion Sort para arrays maiores
- Quando n√£o pode usar recurs√£o (sistemas embarcados)
- C√≥digo legado que precisa ser simples e eficiente

**Exemplo de uso detalhado:**
```c
int arr[] = {23, 29, 15, 19, 31, 7, 9, 5, 2};
int n = 9;

// Usando sequ√™ncia de Knuth: gaps = [4, 1]

// Gap = 4:
// Comparar elementos a dist√¢ncia 4
// Sublistas: 
//   [23, 31, 2] (√≠ndices 0, 4, 8)
//   [29, 7]     (√≠ndices 1, 5)
//   [15, 9]     (√≠ndices 2, 6)
//   [19, 5]     (√≠ndices 3, 7)

// Ordenar cada sublista com Insertion Sort:
// [23, 31, 2] ‚Üí [2, 23, 31]  arr: [2, 29, 15, 19, 31, 7, 9, 5, 23]
// [29, 7]     ‚Üí [7, 29]       arr: [2, 7, 15, 19, 31, 29, 9, 5, 23]
// [15, 9]     ‚Üí [9, 15]       arr: [2, 7, 9, 19, 31, 29, 15, 5, 23]
// [19, 5]     ‚Üí [5, 19]       arr: [2, 7, 9, 5, 31, 29, 15, 19, 23]

// Array ap√≥s gap=4: [2, 7, 9, 5, 31, 29, 15, 19, 23]
// Observe: n√£o est√° ordenado, mas elementos grandes moveram para direita

// Gap = 1 (Insertion Sort normal):
// [2, 7, 9, 5, 31, 29, 15, 19, 23]
// Inserir 5: [2, 5, 7, 9, 31, 29, 15, 19, 23]
// Inserir 31: j√° no lugar
// Inserir 29: [2, 5, 7, 9, 29, 31, 15, 19, 23]
// Inserir 15: [2, 5, 7, 9, 15, 29, 31, 19, 23]
// Inserir 19: [2, 5, 7, 9, 15, 19, 29, 31, 23]
// Inserir 23: [2, 5, 7, 9, 15, 19, 23, 29, 31]

shellSort(arr, n);
// Resultado final: {2, 5, 7, 9, 15, 19, 23, 29, 31}

// Vantagem: O passo final (gap=1) √© muito mais r√°pido porque
// o array j√° est√° "quase ordenado" pelos passos anteriores
```

**Pseudoc√≥digo Formal (Knuth):**
```
SHELL-SORT(A, n)
1  gap ‚Üê 1
2  while gap < n/3
3      gap ‚Üê 3 √ó gap + 1
4  while gap > 0
5      for i ‚Üê gap to n
6          temp ‚Üê A[i]
7          j ‚Üê i
8          while j ‚â• gap and A[j-gap] > temp
9              A[j] ‚Üê A[j-gap]
10             j ‚Üê j - gap
11         A[j] ‚Üê temp
12     gap ‚Üê gap / 3
```

**Por que Shell Sort funciona?**

**Intui√ß√£o**: Mover elementos para perto de suas posi√ß√µes finais rapidamente
```
Array inicial: [100, 90, 80, 70, ..., 3, 2, 1]

Insertion Sort normal (gap=1):
- 100 precisa mover 99 posi√ß√µes ‚Üí 99 trocas
- Total: O(n¬≤) movimenta√ß√µes

Shell Sort com gaps grandes:
- Gap=33: 100 move 3 posi√ß√µes ‚Üí 3 trocas
- Gap=11: Ajustes finos
- Gap=1:  Array j√° quase ordenado ‚Üí O(n)
```

**An√°lise Visual:**

```
Gap grande (h): "desentupir" invers√µes distantes
          ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄh‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
[9, 2, 8, 3, 7, 4, 6, 5, 1]
 ‚Üì              ‚Üì          ‚Üì
Compara elementos distantes

Gap pequeno: ajustes finos locais
    ‚ï≠‚îÄh‚îÄ‚ïÆ
[1, 3, 2, 5, 4, 7, 6, 9, 8]
```

**Compara√ß√£o com outros algoritmos:**

| Aspecto | Shell Sort | Insertion Sort | Quick Sort |
|---------|-----------|----------------|------------|
| Complexidade | O(n^1.3) * | O(n¬≤) | O(n log n) |
| Mem√≥ria | O(1) ‚úÖ | O(1) ‚úÖ | O(log n) |
| Est√°vel | N√£o ‚ùå | Sim ‚úÖ | N√£o ‚ùå |
| Adaptativo | Sim ‚úÖ | Sim ‚úÖ | N√£o ‚ùå |
| Recurs√£o | N√£o ‚úÖ | N√£o ‚úÖ | Sim ‚ùå |
| Implementa√ß√£o | Simples ‚úÖ | Muito simples | M√©dia |

*Depende da sequ√™ncia de gaps

**Quando N√ÉO usar Shell Sort:**
- Arrays muito grandes (> 100k): Quick/Merge Sort s√£o melhores
- Necessidade de estabilidade: Use Merge Sort
- Performance cr√≠tica: Quick Sort √© mais r√°pido
- Necessita garantia O(n log n): Merge/Heap Sort

**Exemplo de uso:**
```c
int arr[] = {23, 29, 15, 19, 31, 7, 9, 5, 2};
int n = 9;
shellSort(arr, n);
// Resultado: {2, 5, 7, 9, 15, 19, 23, 29, 31}
```

### 8. Bubble Sort Otimizado (`bubbleSortOptimized.c`)

**Como funciona:**
- Vers√£o melhorada do Bubble Sort
- Para quando nenhuma troca √© feita (array j√° ordenado)
- Reduz o melhor caso de O(n¬≤) para O(n)

**Quando usar:**
- Fins educacionais para mostrar otimiza√ß√µes
- Arrays pequenos que podem estar parcialmente ordenados

## üõ†Ô∏è Ferramentas Dispon√≠veis

### Compara√ß√£o de Performance (`comparacao.c`)

Ferramenta completa para benchmark dos algoritmos:
- Testa diferentes tipos de arrays (aleat√≥rio, ordenado, reverso)
- Mede tempo de execu√ß√£o
- Verifica corretude dos resultados
- Gera relat√≥rio comparativo

### Integra√ß√£o com Busca (`ordenacao_busca.c`)

Demonstra a rela√ß√£o entre ordena√ß√£o e algoritmos de busca:
- Compara busca linear vs. bin√°ria
- Mostra quando vale a pena ordenar antes de buscar
- Inclui busca interpolada
- An√°lise de trade-offs

## üöÄ Como Compilar e Executar

### Uso do Makefile (Recomendado)

Este diret√≥rio inclui um Makefile completo para facilitar a compila√ß√£o e teste:

```bash
# Compilar todos os algoritmos
make all

# Executar algoritmos b√°sicos
make run-all

# Executar algoritmos avan√ßados  
make run-advanced

# Executar benchmark de performance
make benchmark

# Testar se todos compilam
make test

# Ver ajuda completa
make help
```

### Compila√ß√£o Individual
```bash
gcc -Wall -Wextra -std=c99 -o bubbleSort bubbleSort.c
./bubbleSort
```

### Compila√ß√£o com Otimiza√ß√£o
```bash
# Debug
make debug

# Release (m√°xima otimiza√ß√£o)
make release
```

## üìä Compara√ß√£o de Desempenho

### Para Arrays Pequenos (n < 50)
1. **Insertion Sort** - Melhor para arrays quase ordenados
2. **Selection Sort** - Menor n√∫mero de trocas
3. **Bubble Sort** - Apenas para fins educacionais

### Para Arrays M√©dios (50 < n < 1000)
1. **Quick Sort** - Geralmente o mais r√°pido
2. **Merge Sort** - Consistente, est√°vel
3. **Insertion Sort** - Para arrays quase ordenados

### Para Arrays Grandes (n > 1000)
1. **Merge Sort** - Consistente O(n log n)
2. **Quick Sort** - R√°pido em m√©dia, mas O(n¬≤) no pior caso
3. **Evitar** algoritmos O(n¬≤)

## üõ†Ô∏è Otimiza√ß√µes Poss√≠veis

### Bubble Sort Otimizado
- Parar quando nenhuma troca for feita
- Reduzir o alcance a cada passagem

### Quick Sort Otimizado
- Escolha inteligente do piv√¥ (mediana de tr√™s)
- Alternar para Insertion Sort em arrays pequenos
- Implementa√ß√£o iterativa para evitar stack overflow

### Merge Sort Otimizado
- Usar arrays pr√©-alocados para merge
- Alternar para Insertion Sort em subarrays pequenos

## üß™ Casos de Teste Recomendados

### Casos B√°sicos
```c
// Array vazio
int arr[] = {};
int n = 0;

// Array com um elemento
int arr[] = {42};
int n = 1;

// Array j√° ordenado
int arr[] = {1, 2, 3, 4, 5};
int n = 5;

// Array em ordem inversa
int arr[] = {5, 4, 3, 2, 1};
int n = 5;

// Array com elementos duplicados
int arr[] = {3, 1, 4, 1, 5, 9, 2, 6, 5};
int n = 9;
```

## üìö Refer√™ncias

- Donald E. Knuth. *The Art of Computer Programming, Volume 3: Sorting and Searching*
- Robert Sedgewick. *Algorithms in C*
- Thomas H. Cormen et al. *Introduction to Algorithms* (CLRS)

## ü§î Quest√µes para Reflex√£o (com Respostas Detalhadas)

### Quest√£o 1: Estabilidade em Algoritmos de Ordena√ß√£o

**Pergunta**: Por que a estabilidade √© importante em algoritmos de ordena√ß√£o? D√™ um exemplo pr√°tico onde isso seria relevante.

**Resposta Detalhada**:

A **estabilidade** √© a propriedade de um algoritmo de ordena√ß√£o que garante que elementos com chaves iguais mantenham sua ordem relativa original ap√≥s a ordena√ß√£o. 

**Por que √© importante?**

1. **Ordena√ß√£o em m√∫ltiplas etapas**: Quando queremos ordenar por m√∫ltiplos crit√©rios sequencialmente
2. **Preserva√ß√£o de ordem anterior**: Quando dados j√° possuem alguma ordena√ß√£o significativa
3. **Consist√™ncia de resultados**: Garante comportamento previs√≠vel e reproduz√≠vel

**Exemplo Pr√°tico Detalhado**:

Imagine uma tabela de alunos com nome e nota:
```
Original:
[("Maria", 85), ("Jo√£o", 90), ("Ana", 85), ("Pedro", 90)]
```

Se ordenarmos primeiro por nome (alfabeticamente):
```
[("Ana", 85), ("Jo√£o", 90), ("Maria", 85), ("Pedro", 90)]
```

Agora, ordenando por nota de forma **est√°vel**:
```
[("Ana", 85), ("Maria", 85), ("Jo√£o", 90), ("Pedro", 90)]
```
Note que Ana continua antes de Maria (ambas com 85) e Jo√£o antes de Pedro (ambos com 90), mantendo a ordem alfab√©tica.

Se us√°ssemos um algoritmo **inst√°vel** (como Quick Sort padr√£o):
```
[("Maria", 85), ("Ana", 85), ("Pedro", 90), ("Jo√£o", 90)]
```
A ordem alfab√©tica foi perdida para alunos com a mesma nota.

**Aplica√ß√µes Reais**:
- **Banco de dados**: Consultas com ORDER BY m√∫ltiplo (ORDER BY departamento, nome)
- **Sistemas de arquivos**: Ordena√ß√£o por tipo e depois por data
- **E-commerce**: Ordenar produtos por categoria, depois por pre√ßo
- **Processamento de logs**: Ordenar por timestamp mantendo ordem de eventos simult√¢neos

**Algoritmos Est√°veis vs Inst√°veis**:
- ‚úÖ **Est√°veis**: Merge Sort, Insertion Sort, Bubble Sort, Counting Sort
- ‚ùå **Inst√°veis**: Quick Sort, Heap Sort, Selection Sort, Shell Sort

### Quest√£o 2: Quick Sort - Paradoxo da Complexidade

**Pergunta**: Explique por que Quick Sort tem complexidade O(n¬≤) no pior caso, mas ainda √© considerado um dos melhores algoritmos na pr√°tica.

**Resposta Detalhada**:

**Por que O(n¬≤) no pior caso?**

O pior caso ocorre quando o piv√¥ escolhido √© sempre o menor ou maior elemento, criando parti√ß√µes extremamente desbalanceadas:

```
Array: [1, 2, 3, 4, 5]
Escolhendo √∫ltimo elemento como piv√¥:

N√≠vel 1: piv√¥=5, particiona em [1,2,3,4] e []  - n compara√ß√µes
N√≠vel 2: piv√¥=4, particiona em [1,2,3] e []    - (n-1) compara√ß√µes  
N√≠vel 3: piv√¥=3, particiona em [1,2] e []      - (n-2) compara√ß√µes
...
Total: n + (n-1) + (n-2) + ... + 1 = n(n+1)/2 = O(n¬≤)
```

**Por que ainda √© o melhor na pr√°tica?**

1. **Caso M√©dio Dominante**: 
   - O(n log n) ocorre em ~99.99% dos casos com dados reais
   - Pior caso O(n¬≤) √© extremamente raro com piv√¥ aleat√≥rio
   - Probabilidade de pior caso com piv√¥ aleat√≥rio: < 1/(n!)

2. **Constantes Pequenas**:
   ```
   Quick Sort: ~1.4 √ó n log n compara√ß√µes (m√©dia)
   Merge Sort: ~1.0 √ó n log n compara√ß√µes, mas mais movimenta√ß√µes
   Heap Sort: ~2.0 √ó n log n compara√ß√µes
   ```

3. **Cache Efficiency**:
   - Quick Sort trabalha in-place com boa localidade de refer√™ncia
   - Acessa dados sequencialmente (friendly para cache L1/L2)
   - Merge Sort requer mem√≥ria adicional e mais cache misses

4. **Otimiza√ß√µes Pr√°ticas**:
   - **Mediana de tr√™s**: Escolhe piv√¥ melhor que primeiro/√∫ltimo
   - **Introsort**: Detecta recurs√£o profunda e muda para Heap Sort
   - **Cutoff**: Usa Insertion Sort para subarrays pequenos (< 10)

5. **Compara√ß√£o Real-World** (array de 1 milh√£o de elementos):
   ```
   Quick Sort (otimizado):  ~50ms
   Merge Sort:              ~80ms  (est√°vel, mas mais lento)
   Heap Sort:               ~120ms (garantia O(n log n), mas lento)
   ```

**Conclus√£o**: Na pr√°tica, Quick Sort combina velocidade m√©dia excepcional com baixo uso de mem√≥ria, superando as garantias te√≥ricas de pior caso atrav√©s de otimiza√ß√µes inteligentes.

### Quest√£o 3: Escolha de Algoritmo para Dados Parcialmente Ordenados

**Pergunta**: Para um array de 1 milh√£o de elementos j√° parcialmente ordenado, qual algoritmo voc√™ escolheria e por qu√™?

**Resposta Detalhada**:

**Resposta curta**: **Insertion Sort** ou **Tim Sort** (h√≠brido).

**An√°lise Completa**:

**Insertion Sort** seria surpreendentemente a melhor escolha! Aqui est√° o porqu√™:

1. **Adaptatividade**:
   - Em arrays parcialmente ordenados, muitos elementos j√° est√£o pr√≥ximos de suas posi√ß√µes finais
   - Insertion Sort requer apenas O(1) compara√ß√£o por elemento j√° posicionado
   - Complexidade: O(n + d) onde d = n√∫mero de invers√µes

2. **An√°lise Quantitativa**:
   ```
   Array 90% ordenado (1M elementos):
   - Insertion Sort: ~0.1n compara√ß√µes = 100k compara√ß√µes
   - Quick Sort: ~1.4n log n = 28M compara√ß√µes
   - Merge Sort: ~1.0n log n = 20M compara√ß√µes
   ```

3. **Exemplo Num√©rico**:
   ```
   Array: [1,2,3,4,5,100,7,8,9,10]
   
   Insertion Sort:
   - Elementos 1-5: J√° ordenados, 1 compara√ß√£o cada
   - Elemento 100: 1 compara√ß√£o (100 > 5)
   - Elemento 7: 2 compara√ß√µes (move 100)
   - Elementos 8-10: 1 compara√ß√£o cada
   Total: ~12 compara√ß√µes
   
   Quick Sort:
   - Deve processar todo array recursivamente
   - N√£o se beneficia da ordem parcial
   Total: ~30+ compara√ß√µes
   ```

**Tim Sort - A Solu√ß√£o Industrial**:

O algoritmo usado no Python e Java combina o melhor dos dois mundos:
```python
def timsort(array):
    # 1. Detecta "runs" (sequ√™ncias ordenadas)
    runs = find_runs(array)  # Encontra subsequ√™ncias ordenadas
    
    # 2. Estende runs curtos com Insertion Sort
    for run in runs:
        if len(run) < MIN_MERGE:
            insertion_sort(run)
    
    # 3. Merge runs usando Merge Sort
    while len(runs) > 1:
        merge_runs(runs)
```

**Caracter√≠sticas do Tim Sort**:
- Detecta e aproveita ordem parcial existente
- Est√°vel
- O(n) no melhor caso, O(n log n) no pior
- Usado em: Python's sorted(), Java's Arrays.sort(), Android

**Quando usar cada um**:
- **70%+ ordenado**: Insertion Sort puro
- **Dados mistos**: Tim Sort
- **Sem informa√ß√£o**: Quick Sort ou Merge Sort

**Benchmark Real** (1M elementos, 80% ordenados):
```
Insertion Sort: ~15ms
Tim Sort:       ~20ms
Quick Sort:     ~80ms
Merge Sort:     ~100ms
```

### Quest√£o 4: Otimiza√ß√£o do Bubble Sort

**Pergunta**: Como o Bubble Sort otimizado consegue atingir O(n) no melhor caso?

**Resposta Detalhada**:

**Mecanismo da Otimiza√ß√£o**:

O Bubble Sort otimizado usa uma **flag booleana** para detectar quando o array j√° est√° ordenado:

```c
void bubbleSortOptimized(int arr[], int n) {
    for (int i = 0; i < n - 1; i++) {
        int swapped = 0;  // Flag: assumindo que n√£o h√° trocas
        
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
                swapped = 1;  // Marca que houve troca
            }
        }
        
        // Se n√£o houve troca, array est√° ordenado
        if (swapped == 0) {
            break;  // Termina o algoritmo
        }
    }
}
```

**An√°lise do Melhor Caso**:

Para um array **j√° ordenado** [1, 2, 3, 4, 5]:

```
Passagem 1:
- Compara 1 e 2: 1 < 2, sem troca
- Compara 2 e 3: 2 < 3, sem troca
- Compara 3 e 4: 3 < 4, sem troca
- Compara 4 e 5: 4 < 5, sem troca
- swapped = 0 (nenhuma troca feita)
- BREAK - algoritmo termina!

Total: n-1 compara√ß√µes = O(n)
```

**Sem otimiza√ß√£o**:
```
Passagem 1: (n-1) compara√ß√µes
Passagem 2: (n-2) compara√ß√µes
Passagem 3: (n-3) compara√ß√µes
...
Total: (n-1) + (n-2) + ... + 1 = O(n¬≤)
```

**Otimiza√ß√µes Adicionais**:

1. **Cocktail Sort** (Bubble Sort bidirecional):
```c
void cocktailSort(int arr[], int n) {
    int swapped = 1;
    int start = 0, end = n - 1;
    
    while (swapped) {
        swapped = 0;
        
        // Passagem da esquerda para direita
        for (int i = start; i < end; i++) {
            if (arr[i] > arr[i + 1]) {
                swap(&arr[i], &arr[i + 1]);
                swapped = 1;
            }
        }
        
        if (!swapped) break;
        
        end--;
        swapped = 0;
        
        // Passagem da direita para esquerda
        for (int i = end - 1; i >= start; i--) {
            if (arr[i] > arr[i + 1]) {
                swap(&arr[i], &arr[i + 1]);
                swapped = 1;
            }
        }
        
        start++;
    }
}
```
**Benef√≠cio**: Elementos pequenos no final "descem" mais r√°pido.

2. **Redu√ß√£o de range**:
```c
// Memoriza a √∫ltima posi√ß√£o de troca
int lastSwap = n - 1;
for (int i = 0; i < n - 1; i++) {
    int newLastSwap = 0;
    for (int j = 0; j < lastSwap; j++) {
        if (arr[j] > arr[j + 1]) {
            swap(&arr[j], &arr[j + 1]);
            newLastSwap = j;
        }
    }
    if (newLastSwap == 0) break;
    lastSwap = newLastSwap;
}
```

**Quando a Otimiza√ß√£o Realmente Ajuda**:
- Arrays j√° ordenados: O(n¬≤) ‚Üí O(n)
- Arrays quase ordenados: Reduz itera√ß√µes significativamente
- Arrays aleat√≥rios: Pouca melhora (ainda O(n¬≤))

### Quest√£o 5: Insertion Sort vs Quick Sort - Quando Usar?

**Pergunta**: Em que situa√ß√µes espec√≠ficas voc√™ usaria Insertion Sort em vez de Quick Sort?

**Resposta Detalhada**:

**Situa√ß√µes Favor√°veis ao Insertion Sort**:

1. **Arrays Pequenos (n < 10-50)**:
```
Benchmark (milissegundos):
n=10:  Insertion Sort: 0.001ms, Quick Sort: 0.002ms
n=20:  Insertion Sort: 0.003ms, Quick Sort: 0.005ms
n=50:  Insertion Sort: 0.015ms, Quick Sort: 0.025ms

Motivo: Overhead de recurs√£o do Quick Sort supera o benef√≠cio
```

2. **Arrays Quase Ordenados**:
```c
// Array 95% ordenado
int arr[] = {1,2,3,4,5,100,7,8,9,10,11,12};

Insertion Sort: O(n + d) onde d = invers√µes
- Apenas ~7 invers√µes para corrigir
- Tempo: ~O(n)

Quick Sort: O(n log n)
- N√£o detecta ordem existente
- Sempre divide e conquista
```

3. **Ordena√ß√£o Online (streaming)**:
```c
// Recebendo dados em tempo real
void processNewData(int value) {
    addToArray(value);
    insertionSort(array, size);  // Incrementalmente mant√©m ordenado
}

// Insertion Sort insere novo elemento em O(n)
// Quick Sort precisaria reordenar tudo em O(n log n)
```

4. **Estabilidade Requerida com Mem√≥ria Limitada**:
```
Requisitos:
- Deve ser est√°vel: ‚úì Insertion Sort, ‚úó Quick Sort
- Deve ser in-place: ‚úì Ambos
- Mem√≥ria O(1): ‚úì Insertion Sort O(1), Quick Sort O(log n) pela pilha

Escolha: Insertion Sort
```

5. **Sistemas Embarcados com Restri√ß√µes**:
```c
// Microcontrolador com 4KB RAM, processando 20 sensores
struct SensorData sensors[20];

// Insertion Sort:
// - C√≥digo simples: ~30 linhas
// - Sem recurs√£o: stack pequeno
// - Previs√≠vel: sempre n¬≤ no pior caso

// Quick Sort:
// - Mais complexo: ~100 linhas  
// - Recurs√£o: pode estourar stack
// - Imprevis√≠vel: n¬≤ no pior caso inesperado
```

6. **Quando Simplicidade √© Cr√≠tica**:
```c
// Insertion Sort - cristalino
void insertionSort(int arr[], int n) {
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}
// 9 linhas, f√°cil de auditar e provar correto

// Quick Sort - mais complexo
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
// Requer fun√ß√£o partition adicional, recurs√£o, mais dif√≠cil provar
```

**Tabela de Decis√£o Pr√°tica**:

| Cen√°rio | Escolha | Raz√£o |
|---------|---------|-------|
| n < 50 | Insertion Sort | Menos overhead |
| 90%+ ordenado | Insertion Sort | O(n) adaptativo |
| Dados aleat√≥rios grandes | Quick Sort | O(n log n) m√©dio |
| Streaming/Online | Insertion Sort | Insere incrementalmente |
| Est√°vel + In-place | Insertion Sort | Quick Sort n√£o √© est√°vel |
| Embarcado/Cr√≠tico | Insertion Sort | Sem recurs√£o, simples |
| Performance m√°xima | Tim Sort/Introsort | H√≠brido = melhor dos 2 |

**Solu√ß√£o Industrial - Algoritmos H√≠bridos**:

A maioria das bibliotecas modernas usa uma combina√ß√£o:

```c
void hybridSort(int arr[], int low, int high) {
    int size = high - low + 1;
    
    // Arrays pequenos: Insertion Sort
    if (size < CUTOFF) {  // CUTOFF = 10-20
        insertionSort(arr, low, high);
        return;
    }
    
    // Arrays grandes: Quick Sort
    int pi = partition(arr, low, high);
    hybridSort(arr, low, pi - 1);
    hybridSort(arr, pi + 1, high);
}
```

**Exemplos Reais**:
- **C++ std::sort**: Introsort (Quick + Heap + Insertion)
- **Python sorted()**: Tim Sort (Merge + Insertion)
- **Java Arrays.sort()**: Dual-Pivot Quick + Insertion
- **Linux kernel**: Heap Sort (garantias em kernel space)

**Conclus√£o**: Insertion Sort domina em pequenas escalas e dados parcialmente ordenados. Quick Sort domina em grandes volumes de dados aleat√≥rios. Algoritmos modernos combinam ambos para obter o melhor resultado.

## üìã Exerc√≠cios Pr√°ticos

### N√≠vel B√°sico
1. Implemente uma vers√£o do Bubble Sort que conte o n√∫mero de trocas realizadas
2. Modifique o Selection Sort para encontrar simultaneamente o maior e menor elemento
3. Crie uma vers√£o do Insertion Sort que ordene em ordem decrescente

### N√≠vel Intermedi√°rio
4. Implemente uma vers√£o h√≠brida que use Insertion Sort para subarrays pequenos (< 10 elementos) e Quick Sort para arrays maiores
5. Desenvolva uma fun√ß√£o que determine automaticamente o melhor algoritmo baseado no tamanho e caracter√≠sticas do array
6. Crie um Merge Sort iterativo (bottom-up) em vez da vers√£o recursiva

### N√≠vel Avan√ßado
7. Implemente o algoritmo Introsort (Quick Sort com fallback para Heap Sort)
8. Desenvolva uma vers√£o paralela do Merge Sort usando threads
9. Crie um algoritmo de ordena√ß√£o adaptativo que detecte padr√µes nos dados

### Desafios
10. Implemente Radix Sort para n√∫meros negativos
11. Desenvolva um algoritmo de ordena√ß√£o externo para arquivos que n√£o cabem na mem√≥ria
12. Crie um visualizador em tempo real dos algoritmos de ordena√ß√£o

## üîß Pr√≥ximas Implementa√ß√µes

- [ ] Radix Sort (ordena√ß√£o por d√≠gitos)
- [ ] Counting Sort (ordena√ß√£o por contagem)
- [ ] Bucket Sort (ordena√ß√£o por baldes)
- [ ] Tim Sort (algoritmo h√≠brido usado no Python)
- [ ] Introsort (Quick Sort + Heap Sort h√≠brido)
- [ ] Visualizador gr√°fico de algoritmos
- [ ] Testes automatizados unit√°rios
- [ ] An√°lise de estabilidade detalhada
- [ ] Implementa√ß√µes paralelas (OpenMP)
- [ ] Compara√ß√£o com bibliotecas padr√£o (qsort)