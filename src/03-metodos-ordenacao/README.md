# M√©todos de Ordena√ß√£o em C

Este diret√≥rio cont√©m implementa√ß√µes completas e detalhadas de algoritmos cl√°ssicos de ordena√ß√£o em linguagem C, acompanhadas de an√°lises te√≥ricas profundas, exemplos pr√°ticos passo-a-passo e compara√ß√µes rigorosas de desempenho.

## üìñ Introdu√ß√£o aos Algoritmos de Ordena√ß√£o

### O que √© Ordena√ß√£o?

Ordena√ß√£o √© um processo fundamental em ci√™ncia da computa√ß√£o que consiste em **reorganizar uma sequ√™ncia de elementos em uma ordem espec√≠fica** (geralmente crescente ou decrescente). Este √© um dos problemas mais estudados e aplicados na computa√ß√£o, sendo essencial para:

- **Otimiza√ß√£o de Buscas**: Estruturas ordenadas permitem buscas eficientes (O(log n) vs O(n))
- **An√°lise de Dados**: Facilita identifica√ß√£o de medianas, quartis e outliers
- **Prepara√ß√£o para Algoritmos**: Muitos algoritmos requerem dados pr√©-ordenados
- **Interface com Usu√°rios**: Apresenta√ß√£o organizada de informa√ß√µes
- **Otimiza√ß√£o de I/O**: Acesso sequencial otimizado em sistemas de arquivos

### Conceitos Fundamentais

#### Estabilidade
Um algoritmo √© **est√°vel** quando mant√©m a ordem relativa de elementos com chaves iguais. Por exemplo, se temos dois registros com o mesmo valor de ordena√ß√£o, um algoritmo est√°vel garantir√° que a ordem original entre eles seja preservada.

**Exemplo Pr√°tico**: Ordenando uma lista de alunos primeiro por nome e depois por nota. Um algoritmo est√°vel mant√©m a ordem alfab√©tica para alunos com a mesma nota.

#### In-Place
Um algoritmo √© **in-place** quando requer apenas O(1) ou O(log n) de mem√≥ria adicional, al√©m do espa√ßo ocupado pela entrada. Isso significa que a ordena√ß√£o ocorre sobre o pr√≥prio array original, sem necessidade de copiar grandes volumes de dados.

#### Adaptatividade
Um algoritmo √© **adaptativo** quando seu desempenho melhora significativamente para entradas j√° parcialmente ordenadas. Por exemplo, o Insertion Sort atinge O(n) para arrays quase ordenados.

### Por que estudar diferentes algoritmos?

N√£o existe um "melhor algoritmo universal" de ordena√ß√£o. A escolha depende de:
- **Tamanho da entrada**: Algoritmos simples podem ser mais r√°pidos para pequenas entradas
- **Distribui√ß√£o dos dados**: Arrays quase ordenados, completamente aleat√≥rios, ou invertidos
- **Restri√ß√µes de mem√≥ria**: Alguns algoritmos requerem espa√ßo adicional significativo
- **Necessidade de estabilidade**: Quando a ordem relativa deve ser preservada
- **Hardware dispon√≠vel**: Cache, processadores paralelos, mem√≥ria dispon√≠vel

## üìÅ Arquivos Dispon√≠veis

### Algoritmos de Ordena√ß√£o Implementados

| Arquivo | Algoritmo | Complexidade (Tempo) | Complexidade (Espa√ßo) | Est√°vel | In-Place |
|---------|-----------|---------------------|----------------------|---------|----------|
| `bubbleSort.c` | Bubble Sort | O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `bubbleSortOptimized.c` | Bubble Sort Otimizado | O(n) a O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `insertSort.c` | Insertion Sort | O(n¬≤) | O(1) | ‚úÖ Sim | ‚úÖ Sim |
| `selectSort.c` | Selection Sort | O(n¬≤) | O(1) | ‚ùå N√£o | ‚úÖ Sim |
| `quickSort.c` | Quick Sort | O(n log n) avg, O(n¬≤) worst | O(log n) | ‚ùå N√£o | ‚úÖ Sim |
| `mergeSort.c` | Merge Sort | O(n log n) | O(n) | ‚úÖ Sim | ‚ùå N√£o |
| `heapSort.c` | Heap Sort | O(n log n) | O(1) | ‚ùå N√£o | ‚úÖ Sim |
| `shellSort.c` | Shell Sort | O(n^1.5) | O(1) | ‚ùå N√£o | ‚úÖ Sim |

### Algoritmos de Ordena√ß√£o Sem Compara√ß√£o

Diret√≥rio especial contendo algoritmos que n√£o usam compara√ß√µes entre elementos:

| Localiza√ß√£o | Descri√ß√£o |
|-------------|-----------|
| `algoritmos-sem-comparacao/` | **Pasta com algoritmos de ordena√ß√£o sem compara√ß√£o** |
| `algoritmos-sem-comparacao/countingSort.c` | Counting Sort - Ordena√ß√£o por contagem O(n + k) |
| `algoritmos-sem-comparacao/radixSort.c` | Radix Sort - Ordena√ß√£o por d√≠gitos O(d √ó (n + k)) |
| `algoritmos-sem-comparacao/bucketSort.c` | Bucket Sort - Ordena√ß√£o por baldes O(n + k) |
| `algoritmos-sem-comparacao/README.md` | Documenta√ß√£o detalhada dos algoritmos sem compara√ß√£o |

### Ferramentas e Exemplos

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `comparacao.c` | Benchmark de performance entre algoritmos |
| `ordenacao_busca.c` | Integra√ß√£o de ordena√ß√£o com algoritmos de busca |
| `Makefile` | Sistema de compila√ß√£o automatizado |
| `README.md` | Esta documenta√ß√£o |

## üîç Detalhes dos Algoritmos

### 1. Bubble Sort (`bubbleSort.c`)

#### Explica√ß√£o Acad√™mica

O **Bubble Sort** √© um algoritmo de ordena√ß√£o por compara√ß√£o que recebe seu nome da forma como os elementos maiores "borbulham" para o topo (final) do array, assim como bolhas de ar sobem na √°gua. √â o algoritmo de ordena√ß√£o mais simples de entender e implementar, sendo frequentemente usado como introdu√ß√£o ao estudo de algoritmos.

**Princ√≠pio de Funcionamento:**
O algoritmo realiza m√∫ltiplas passagens pelo array, comparando pares de elementos adjacentes e trocando-os se estiverem fora de ordem. A cada passagem completa, o maior elemento ainda n√£o ordenado √© movido para sua posi√ß√£o final.

**An√°lise Matem√°tica da Complexidade:**
- **N√∫mero de compara√ß√µes**: No pior caso, s√£o necess√°rias n-1 compara√ß√µes na primeira passagem, n-2 na segunda, at√© 1 na √∫ltima. O total √©: (n-1) + (n-2) + ... + 1 = n(n-1)/2 = O(n¬≤)
- **N√∫mero de trocas**: No pior caso (array em ordem reversa), cada compara√ß√£o resulta em uma troca, totalizando O(n¬≤) trocas
- **Melhor caso**: Quando o array j√° est√° ordenado, s√£o feitas n-1 compara√ß√µes sem trocas, resultando em O(n) com a otimiza√ß√£o de flag

**Invariante do Algoritmo:**
Ap√≥s a i-√©sima itera√ß√£o do loop externo, os i maiores elementos est√£o em suas posi√ß√µes finais corretas no final do array.

**Como funciona:**
- Compara elementos adjacentes e os troca se estiverem fora de ordem
- Repete o processo at√© que nenhuma troca seja necess√°ria
- O maior elemento "borbulha" para o final a cada passagem
- A cada itera√ß√£o, o n√∫mero de compara√ß√µes necess√°rias diminui em 1

**Quando usar:**
- Listas muito pequenas (< 10 elementos) onde a simplicidade √© mais importante
- Fins educacionais para ensinar conceitos de ordena√ß√£o
- Quando simplicidade de implementa√ß√£o √© cr√≠tica
- Arrays que j√° est√£o quase ordenados (com a vers√£o otimizada)

**Exemplo de uso passo-a-passo:**
```c
int arr[] = {64, 34, 25, 12, 22, 11, 90};
int n = 7;

// Estado inicial: [64, 34, 25, 12, 22, 11, 90]

// Passagem 1:
// [34, 64, 25, 12, 22, 11, 90] (troca 64 e 34)
// [34, 25, 64, 12, 22, 11, 90] (troca 64 e 25)
// [34, 25, 12, 64, 22, 11, 90] (troca 64 e 12)
// [34, 25, 12, 22, 64, 11, 90] (troca 64 e 22)
// [34, 25, 12, 22, 11, 64, 90] (troca 64 e 11)
// [34, 25, 12, 22, 11, 64, 90] (64 < 90, sem troca)
// Resultado: 90 est√° na posi√ß√£o final

// Passagem 2:
// [25, 34, 12, 22, 11, 64, 90]
// [25, 12, 34, 22, 11, 64, 90]
// [25, 12, 22, 34, 11, 64, 90]
// [25, 12, 22, 11, 34, 64, 90]
// Resultado: 64 est√° na posi√ß√£o final

// ... continua at√© estar completamente ordenado
// Resultado final: [11, 12, 22, 25, 34, 64, 90]

bubbleSort(arr, n);
```

**Pseudoc√≥digo Formal:**
```
BUBBLE-SORT(A, n)
1  for i ‚Üê 1 to n-1
2      for j ‚Üê 1 to n-i
3          if A[j] > A[j+1]
4              swap A[j] with A[j+1]
```

### 2. Insertion Sort (`insertSort.c`)

#### Explica√ß√£o Acad√™mica

O **Insertion Sort** √© um algoritmo de ordena√ß√£o intuitivo que simula a forma como naturalmente ordenamos cartas em nossas m√£os. O algoritmo mant√©m uma sublista ordenada √† esquerda e insere, um por vez, cada elemento restante na posi√ß√£o correta dentro dessa sublista ordenada.

**Princ√≠pio de Funcionamento:**
O algoritmo divide conceitualmente o array em duas partes: uma parte ordenada (inicialmente contendo apenas o primeiro elemento) e uma parte n√£o ordenada (o restante). A cada itera√ß√£o, o algoritmo pega o primeiro elemento da parte n√£o ordenada e o insere na posi√ß√£o correta da parte ordenada.

**An√°lise Matem√°tica da Complexidade:**
- **Melhor caso (O(n))**: Quando o array j√° est√° ordenado, cada elemento requer apenas uma compara√ß√£o para confirmar que est√° na posi√ß√£o correta
- **Pior caso (O(n¬≤))**: Quando o array est√° em ordem reversa, cada novo elemento deve ser comparado com todos os elementos j√° ordenados e movido para o in√≠cio
- **Caso m√©dio (O(n¬≤))**: Em m√©dia, cada elemento precisa ser comparado com metade dos elementos j√° ordenados

**Caracter√≠sticas Especiais:**
- **Online**: Pode ordenar elementos conforme eles chegam (n√£o precisa ter todos os dados de uma vez)
- **Adaptativo**: Desempenho melhora significativamente com dados parcialmente ordenados
- **Est√°vel**: Mant√©m a ordem relativa de elementos iguais

**Como funciona:**
- Constr√≥i a lista ordenada um elemento por vez, da esquerda para a direita
- Insere cada elemento na posi√ß√£o correta em rela√ß√£o aos j√° ordenados
- Similar a organizar cartas na m√£o: voc√™ pega uma carta e a insere no lugar certo
- Elementos maiores s√£o "deslocados" para a direita para abrir espa√ßo

**Quando usar:**
- Arrays pequenos ou quase ordenados (extremamente eficiente nestes casos)
- Como parte de algoritmos h√≠bridos (ex: Timsort usa Insertion Sort para pequenos subarrays)
- Quando estabilidade √© importante
- Ordena√ß√£o online (dados chegando em tempo real)
- Quando a simplicidade de implementa√ß√£o √© cr√≠tica

**Exemplo de uso detalhado:**
```c
int arr[] = {12, 11, 13, 5, 6};
int n = 5;

// Estado inicial: [12, 11, 13, 5, 6]
// Parte ordenada: [12] | Parte n√£o ordenada: [11, 13, 5, 6]

// Itera√ß√£o 1: Inserir 11
// Comparar 11 com 12: 11 < 12, ent√£o mover 12 para direita
// Inserir 11 na posi√ß√£o 0
// Resultado: [11, 12, 13, 5, 6]
// Parte ordenada: [11, 12] | Parte n√£o ordenada: [13, 5, 6]

// Itera√ß√£o 2: Inserir 13
// Comparar 13 com 12: 13 > 12, j√° est√° no lugar certo
// Resultado: [11, 12, 13, 5, 6]
// Parte ordenada: [11, 12, 13] | Parte n√£o ordenada: [5, 6]

// Itera√ß√£o 3: Inserir 5
// Comparar 5 com 13: 5 < 13, mover 13
// Comparar 5 com 12: 5 < 12, mover 12
// Comparar 5 com 11: 5 < 11, mover 11
// Inserir 5 na posi√ß√£o 0
// Resultado: [5, 11, 12, 13, 6]
// Parte ordenada: [5, 11, 12, 13] | Parte n√£o ordenada: [6]

// Itera√ß√£o 4: Inserir 6
// Comparar 6 com 13: 6 < 13, mover 13
// Comparar 6 com 12: 6 < 12, mover 12
// Comparar 6 com 11: 6 < 11, mover 11
// Comparar 6 com 5: 6 > 5, inserir ap√≥s 5
// Resultado: [5, 6, 11, 12, 13]

insertionSort(arr, n);
// Resultado final: {5, 6, 11, 12, 13}
```

**Pseudoc√≥digo Formal:**
```
INSERTION-SORT(A, n)
1  for i ‚Üê 2 to n
2      key ‚Üê A[i]
3      j ‚Üê i - 1
4      while j > 0 and A[j] > key
5          A[j+1] ‚Üê A[j]
6          j ‚Üê j - 1
7      A[j+1] ‚Üê key
```

**Otimiza√ß√µes Poss√≠veis:**
- **Binary Insertion Sort**: Usar busca bin√°ria para encontrar a posi√ß√£o de inser√ß√£o (reduz compara√ß√µes mas n√£o trocas)
- **Shell Sort**: Varia√ß√£o que compara elementos distantes primeiro

### 3. Selection Sort (`selectSort.c`)

#### Explica√ß√£o Acad√™mica

O **Selection Sort** √© um algoritmo de ordena√ß√£o por compara√ß√£o que divide o array em duas partes: uma sublista ordenada e uma sublista n√£o ordenada. A cada itera√ß√£o, o algoritmo **seleciona** o menor (ou maior) elemento da parte n√£o ordenada e o move para o final da parte ordenada.

**Princ√≠pio de Funcionamento:**
O algoritmo mant√©m um invariante: ap√≥s i itera√ß√µes, os i menores elementos est√£o em suas posi√ß√µes finais corretas. Para cada posi√ß√£o no array, o algoritmo procura o menor elemento na parte n√£o ordenada e o coloca na posi√ß√£o atual.

**An√°lise Matem√°tica da Complexidade:**
- **Todas as varia√ß√µes (melhor, m√©dio e pior caso): O(n¬≤)**
- **Compara√ß√µes**: Sempre realiza exatamente (n-1) + (n-2) + ... + 1 = n(n-1)/2 compara√ß√µes
- **Trocas**: Realiza no m√°ximo n-1 trocas (uma por itera√ß√£o)
- A complexidade √© sempre O(n¬≤), independente da configura√ß√£o inicial dos dados

**Caracter√≠sticas Distintivas:**
- **N√∫mero m√≠nimo de trocas**: Entre os algoritmos O(n¬≤), realiza o menor n√∫mero de opera√ß√µes de troca
- **N√£o adaptativo**: N√£o se beneficia de dados parcialmente ordenados
- **N√£o est√°vel**: Pode alterar a ordem relativa de elementos iguais (mas pode ser tornado est√°vel com modifica√ß√µes)

**Como funciona:**
- Encontra o menor elemento e o coloca na primeira posi√ß√£o
- Encontra o segundo menor e o coloca na segunda posi√ß√£o
- Repete at√© ordenar toda a lista
- Em cada itera√ß√£o i, apenas a posi√ß√£o i √© modificada (ap√≥s encontrar o m√≠nimo)

**Quando usar:**
- Quando o n√∫mero de trocas deve ser minimizado (importante em sistemas onde escrever √© custoso)
- Listas pequenas onde simplicidade √© importante
- Quando a mem√≥ria √© extremamente limitada (O(1) adicional)
- Em sistemas embarcados onde opera√ß√µes de escrita s√£o caras

**Exemplo de uso detalhado:**
```c
int arr[] = {64, 25, 12, 22, 11};
int n = 5;

// Estado inicial: [64, 25, 12, 22, 11]

// Itera√ß√£o 1: Encontrar m√≠nimo de posi√ß√£o 0 at√© 4
// M√≠nimo encontrado: 11 (posi√ß√£o 4)
// Trocar arr[0] com arr[4]
// Resultado: [11, 25, 12, 22, 64]
// Parte ordenada: [11] | N√£o ordenada: [25, 12, 22, 64]

// Itera√ß√£o 2: Encontrar m√≠nimo de posi√ß√£o 1 at√© 4
// M√≠nimo encontrado: 12 (posi√ß√£o 2)
// Trocar arr[1] com arr[2]
// Resultado: [11, 12, 25, 22, 64]
// Parte ordenada: [11, 12] | N√£o ordenada: [25, 22, 64]

// Itera√ß√£o 3: Encontrar m√≠nimo de posi√ß√£o 2 at√© 4
// M√≠nimo encontrado: 22 (posi√ß√£o 3)
// Trocar arr[2] com arr[3]
// Resultado: [11, 12, 22, 25, 64]
// Parte ordenada: [11, 12, 22] | N√£o ordenada: [25, 64]

// Itera√ß√£o 4: Encontrar m√≠nimo de posi√ß√£o 3 at√© 4
// M√≠nimo encontrado: 25 (posi√ß√£o 3)
// Sem troca necess√°ria (j√° est√° no lugar)
// Resultado: [11, 12, 22, 25, 64]
// Parte ordenada: [11, 12, 22, 25] | N√£o ordenada: [64]

// √öltimo elemento j√° est√° ordenado
// Resultado final: [11, 12, 22, 25, 64]

selectionSort(arr, n);
// Total de trocas: 3 (muito menos que Bubble Sort)
```

**Pseudoc√≥digo Formal:**
```
SELECTION-SORT(A, n)
1  for i ‚Üê 1 to n-1
2      min ‚Üê i
3      for j ‚Üê i+1 to n
4          if A[j] < A[min]
5              min ‚Üê j
6      if min ‚â† i
7          swap A[i] with A[min]
```

**Compara√ß√£o com outros algoritmos O(n¬≤):**
- **vs Bubble Sort**: Menos trocas, mas sempre O(n¬≤)
- **vs Insertion Sort**: N√£o se adapta a dados parcialmente ordenados
- **Vantagem √∫nica**: M√≠nimo n√∫mero de escritas na mem√≥ria

### 4. Quick Sort (`quickSort.c`)

#### Explica√ß√£o Acad√™mica

O **Quick Sort** √© um dos algoritmos de ordena√ß√£o mais eficientes e amplamente utilizados na pr√°tica. Desenvolvido por Tony Hoare em 1959, ele utiliza a estrat√©gia de **divis√£o e conquista** (divide-and-conquer) para alcan√ßar um desempenho m√©dio de O(n log n).

**Princ√≠pio de Funcionamento:**
O algoritmo seleciona um elemento como **piv√¥** e particiona o array de forma que:
1. Todos os elementos menores que o piv√¥ ficam √† sua esquerda
2. Todos os elementos maiores que o piv√¥ ficam √† sua direita
3. O piv√¥ est√° em sua posi√ß√£o final correta
4. O processo √© aplicado recursivamente √†s sublistas esquerda e direita

**An√°lise Matem√°tica da Complexidade:**

**Melhor e Caso M√©dio: O(n log n)**
- Ocorre quando o piv√¥ divide o array aproximadamente ao meio a cada n√≠vel
- Profundidade da √°rvore de recurs√£o: log‚ÇÇ(n)
- Trabalho em cada n√≠vel: O(n) para particionar
- Total: O(n) √ó log(n) = O(n log n)

**Pior Caso: O(n¬≤)**
- Ocorre quando o piv√¥ √© sempre o menor ou maior elemento
- Array j√° ordenado ou em ordem reversa (com piv√¥ simples)
- Profundidade da recurs√£o: n
- Total: n + (n-1) + (n-2) + ... + 1 = O(n¬≤)

**An√°lise de Recorr√™ncia:**
- Melhor caso: T(n) = 2T(n/2) + O(n) = O(n log n) (Teorema Mestre)
- Pior caso: T(n) = T(n-1) + O(n) = O(n¬≤)

**Por que √© r√°pido na pr√°tica?**
1. **Constantes pequenas**: O fator constante no O(n log n) √© pequeno
2. **Cache-friendly**: Boa localidade de refer√™ncia
3. **In-place**: N√£o requer mem√≥ria adicional significativa
4. **Piv√¥ aleat√≥rio**: Com piv√¥ aleat√≥rio, o pior caso √© muito raro

**Como funciona:**
- Escolhe um piv√¥ e particiona o array
- Elementos menores ficam √† esquerda, maiores √† direita
- Aplica recursivamente o processo nas parti√ß√µes
- Piv√¥ fica em sua posi√ß√£o final a cada parti√ß√£o

**Quando usar:**
- Listas grandes (a escolha padr√£o para ordena√ß√£o de uso geral)
- Quando velocidade m√©dia √© importante
- Implementa√ß√£o padr√£o em muitas bibliotecas (qsort em C)
- Quando mem√≥ria extra √© limitada

**Exemplo de uso detalhado:**
```c
int arr[] = {10, 7, 8, 9, 1, 5};
int n = 6;

// Estado inicial: [10, 7, 8, 9, 1, 5]
// Escolher piv√¥: 5 (√∫ltimo elemento)

// Parti√ß√£o 1:
// i = -1
// j=0: arr[0]=10 > 5, n√£o faz nada
// j=1: arr[1]=7 > 5, n√£o faz nada  
// j=2: arr[2]=8 > 5, n√£o faz nada
// j=3: arr[3]=9 > 5, n√£o faz nada
// j=4: arr[4]=1 < 5, i++, trocar arr[0] e arr[4]
// Array: [1, 7, 8, 9, 10, 5]
// Colocar piv√¥ na posi√ß√£o correta: trocar arr[1] e arr[5]
// Array: [1, 5, 8, 9, 10, 7]
// Piv√¥ 5 est√° na posi√ß√£o 1 (posi√ß√£o final)

// Recurs√£o esquerda: [1] (j√° ordenado)
// Recurs√£o direita: [8, 9, 10, 7]

// Parti√ß√£o da direita (escolher 7 como piv√¥):
// Array: [1, 5, 7, 9, 10, 8]
// Piv√¥ 7 na posi√ß√£o 2

// Recurs√£o: [8, 9, 10]
// Array: [1, 5, 7, 8, 9, 10]

quickSort(arr, 0, n - 1);
// Resultado final: {1, 5, 7, 8, 9, 10}
```

**Pseudoc√≥digo Formal:**
```
QUICKSORT(A, p, r)
1  if p < r
2      q ‚Üê PARTITION(A, p, r)
3      QUICKSORT(A, p, q-1)
4      QUICKSORT(A, q+1, r)

PARTITION(A, p, r)
1  pivot ‚Üê A[r]
2  i ‚Üê p - 1
3  for j ‚Üê p to r-1
4      if A[j] ‚â§ pivot
5          i ‚Üê i + 1
6          swap A[i] with A[j]
7  swap A[i+1] with A[r]
8  return i + 1
```

**Estrat√©gias de Escolha de Piv√¥:**
1. **√öltimo elemento**: Simples, mas pior caso para arrays ordenados
2. **Primeiro elemento**: Similar ao √∫ltimo
3. **Elemento aleat√≥rio**: Evita pior caso com alta probabilidade
4. **Mediana de tr√™s**: Escolhe a mediana entre primeiro, meio e √∫ltimo (boa na pr√°tica)
5. **Mediana das medianas**: Garante O(n log n) mas com overhead

**Otimiza√ß√µes Avan√ßadas:**
- **Cutoff para Insertion Sort**: Usar Insertion Sort para subarrays pequenos (< 10 elementos)
- **Tail recursion**: Eliminar uma chamada recursiva
- **3-way partitioning**: Lidar eficientemente com elementos duplicados

### 5. Merge Sort (`mergeSort.c`)

#### Explica√ß√£o Acad√™mica

O **Merge Sort** √© um algoritmo de ordena√ß√£o baseado no paradigma de **divis√£o e conquista**, desenvolvido por John von Neumann em 1945. √â not√°vel por sua **garantia de complexidade O(n log n)** em todos os casos e por ser um algoritmo **est√°vel**.

**Princ√≠pio de Funcionamento:**
O algoritmo divide recursivamente o array em duas metades at√© que cada subarray contenha apenas um elemento (que est√° trivialmente ordenado). Em seguida, combina (merge) esses subarrays de forma ordenada, construindo progressivamente arrays maiores ordenados at√© reconstruir o array completo.

**An√°lise Matem√°tica da Complexidade:**

A rela√ß√£o de recorr√™ncia do Merge Sort √©:
```
T(n) = 2T(n/2) + O(n)
```
Onde:
- `2T(n/2)`: Ordenar duas metades do array
- `O(n)`: Tempo para combinar (merge) as duas metades ordenadas

**Aplicando o Teorema Mestre:**
- a = 2 (n√∫mero de subproblemas)
- b = 2 (tamanho de cada subproblema)
- f(n) = O(n) (trabalho para combinar)
- log_b(a) = log_2(2) = 1

Como f(n) = Œò(n^log_b(a)), aplicamos o caso 2 do Teorema Mestre:
**T(n) = Œò(n log n)**

**Profundidade da Recurs√£o**: log‚ÇÇ(n) n√≠veis
**Trabalho por n√≠vel**: O(n) compara√ß√µes e c√≥pias
**Total**: O(n) √ó log(n) = **O(n log n)** em todos os casos

**Caracter√≠sticas √önicas:**
- **Garantia de performance**: Sempre O(n log n), mesmo no pior caso
- **Est√°vel**: Mant√©m ordem relativa de elementos iguais
- **N√£o in-place**: Requer O(n) mem√≥ria adicional
- **Paraleliz√°vel**: As duas metades podem ser ordenadas em paralelo

**Como funciona:**
- Divide o array recursivamente ao meio at√© ter subarrays de tamanho 1
- Combina (merge) pares de subarrays ordenados em arrays maiores ordenados
- Repete o processo at√© reconstruir o array completo ordenado
- A opera√ß√£o de merge √© fundamental: combina dois arrays ordenados em um

**Quando usar:**
- Quando garantia de O(n log n) √© essencial (sistemas cr√≠ticos)
- Quando estabilidade √© requerida
- Quando mem√≥ria extra est√° dispon√≠vel
- Ordena√ß√£o externa (arquivos muito grandes)
- Dados em listas encadeadas (n√£o requer acesso aleat√≥rio)

**Exemplo de uso detalhado:**
```c
int arr[] = {38, 27, 43, 3, 9, 82, 10};
int n = 7;

// Divis√£o (fase top-down):
//          [38, 27, 43, 3, 9, 82, 10]
//         /                           \
//    [38, 27, 43, 3]              [9, 82, 10]
//    /            \                /         \
// [38, 27]      [43, 3]        [9, 82]      [10]
//  /    \        /   \          /   \
// [38] [27]    [43] [3]       [9] [82]

// Conquista (fase bottom-up - merge):

// N√≠vel 1: Merge de pares individuais
// [38] + [27] ‚Üí [27, 38]
// [43] + [3]  ‚Üí [3, 43]
// [9] + [82]  ‚Üí [9, 82]
// [10] permanece

// N√≠vel 2: Merge de pares ordenados
// [27, 38] + [3, 43]  ‚Üí [3, 27, 38, 43]
//   Passo a passo:
//   Compare 27 e 3:  3 < 27  ‚Üí [3]
//   Compare 27 e 43: 27 < 43 ‚Üí [3, 27]
//   Compare 38 e 43: 38 < 43 ‚Üí [3, 27, 38]
//   Restou 43              ‚Üí [3, 27, 38, 43]

// [9, 82] + [10] ‚Üí [9, 10, 82]
//   Compare 9 e 10:  9 < 10  ‚Üí [9]
//   Compare 82 e 10: 10 < 82 ‚Üí [9, 10]
//   Restou 82              ‚Üí [9, 10, 82]

// N√≠vel 3: Merge final
// [3, 27, 38, 43] + [9, 10, 82] ‚Üí [3, 9, 10, 27, 38, 43, 82]
//   Compare 3 e 9:   3 < 9   ‚Üí [3]
//   Compare 27 e 9:  9 < 27  ‚Üí [3, 9]
//   Compare 27 e 10: 10 < 27 ‚Üí [3, 9, 10]
//   Compare 27 e 82: 27 < 82 ‚Üí [3, 9, 10, 27]
//   Compare 38 e 82: 38 < 82 ‚Üí [3, 9, 10, 27, 38]
//   Compare 43 e 82: 43 < 82 ‚Üí [3, 9, 10, 27, 38, 43]
//   Restou 82              ‚Üí [3, 9, 10, 27, 38, 43, 82]

mergeSort(arr, 0, n - 1);
// Resultado final: {3, 9, 10, 27, 38, 43, 82}
```

**Pseudoc√≥digo Formal:**
```
MERGE-SORT(A, p, r)
1  if p < r
2      q ‚Üê ‚åä(p + r) / 2‚åã
3      MERGE-SORT(A, p, q)
4      MERGE-SORT(A, q+1, r)
5      MERGE(A, p, q, r)

MERGE(A, p, q, r)
1  n1 ‚Üê q - p + 1
2  n2 ‚Üê r - q
3  create arrays L[1..n1] and R[1..n2]
4  for i ‚Üê 1 to n1
5      L[i] ‚Üê A[p + i - 1]
6  for j ‚Üê 1 to n2
7      R[j] ‚Üê A[q + j]
8  i ‚Üê 1, j ‚Üê 1, k ‚Üê p
9  while i ‚â§ n1 and j ‚â§ n2
10     if L[i] ‚â§ R[j]
11         A[k] ‚Üê L[i]
12         i ‚Üê i + 1
13     else
14         A[k] ‚Üê R[j]
15         j ‚Üê j + 1
16     k ‚Üê k + 1
17 while i ‚â§ n1
18     A[k] ‚Üê L[i]
19     i ‚Üê i + 1, k ‚Üê k + 1
20 while j ‚â§ n2
21     A[k] ‚Üê R[j]
22     j ‚Üê j + 1, k ‚Üê k + 1
```

**Varia√ß√µes e Otimiza√ß√µes:**

1. **Bottom-Up Merge Sort (iterativo)**:
```c
// Evita recurs√£o, √∫til em sistemas com stack limitado
void mergeSortBottomUp(int arr[], int n) {
    for (int size = 1; size < n; size *= 2) {
        for (int start = 0; start < n - size; start += 2 * size) {
            int mid = start + size - 1;
            int end = min(start + 2 * size - 1, n - 1);
            merge(arr, start, mid, end);
        }
    }
}
```

2. **Natural Merge Sort**:
   - Detecta runs (sequ√™ncias j√° ordenadas) naturalmente presentes nos dados
   - Base do Tim Sort usado no Python

3. **In-Place Merge Sort**:
   - Reduz uso de mem√≥ria para O(1), mas com complexidade maior
   - Mais complexo de implementar

**Aplica√ß√µes Especiais:**

- **Ordena√ß√£o Externa**: Para arquivos maiores que a RAM
  ```
  Exemplo: Ordenar arquivo de 100GB com 8GB RAM
  1. Divide arquivo em chunks de 8GB
  2. Ordena cada chunk com Quick Sort
  3. Faz merge externo dos chunks ordenados
  ```

- **Listas Encadeadas**: Merge Sort √© ideal (O(1) extra)
  ```c
  // N√£o precisa de array auxiliar!
  Node* mergeSortList(Node* head) {
      if (!head || !head->next) return head;
      Node* mid = getMiddle(head);
      Node* left = head;
      Node* right = mid->next;
      mid->next = NULL;
      return merge(mergeSortList(left), mergeSortList(right));
  }
  ```

**Compara√ß√£o: Merge Sort vs Quick Sort**

| Aspecto | Merge Sort | Quick Sort |
|---------|-----------|------------|
| Pior caso | O(n log n) ‚úÖ | O(n¬≤) ‚ùå |
| M√©dio caso | O(n log n) | O(n log n) |
| Mem√≥ria | O(n) ‚ùå | O(log n) ‚úÖ |
| Est√°vel | Sim ‚úÖ | N√£o ‚ùå |
| Cache | Menos eficiente | Mais eficiente ‚úÖ |
| Paraleliza√ß√£o | F√°cil ‚úÖ | Mais dif√≠cil |

### 6. Heap Sort (`heapSort.c`)

#### Explica√ß√£o Acad√™mica

O **Heap Sort** √© um algoritmo de ordena√ß√£o baseado na estrutura de dados **heap bin√°rio**. Desenvolvido por J. W. J. Williams em 1964, combina as melhores caracter√≠sticas de Merge Sort (garantia O(n log n)) e Insertion Sort (in-place, O(1) extra).

**Estrutura de Dados: Heap Bin√°rio**

Um **max-heap** √© uma √°rvore bin√°ria completa onde cada n√≥ √© maior ou igual a seus filhos:
```
        90
       /  \
     85    30
    /  \   /
   70  10 15

Propriedade: arr[i] ‚â• arr[2i+1] e arr[i] ‚â• arr[2i+2]
```

**Representa√ß√£o em Array:**
```c
arr[] = [90, 85, 30, 70, 10, 15]
√çndices dos filhos de arr[i]:
- Filho esquerdo: 2*i + 1
- Filho direito:  2*i + 2
- Pai de arr[i]: (i-1)/2
```

**Princ√≠pio de Funcionamento:**

1. **Construir heap**: Transforma o array em um max-heap (O(n))
2. **Extra√ß√£o iterativa**: Remove o m√°ximo (raiz) e reconstr√≥i heap (n √ó O(log n))

**An√°lise Matem√°tica:**

**Fase 1 - Build Heap: O(n)**
```
Surpreendentemente, construir heap √© O(n), n√£o O(n log n)!

An√°lise:
- Altura h = log n
- N√≥s na altura h: n/2^(h+1)
- Custo de heapify na altura h: O(h)
- Total: Œ£(h=0 to log n) [n/2^(h+1) √ó h] = O(n)
```

**Fase 2 - Ordena√ß√£o: O(n log n)**
```
- n itera√ß√µes (uma por elemento)
- Cada itera√ß√£o: heapify O(log n)
- Total: n √ó log n = O(n log n)
```

**Como funciona:**
- Constr√≥i um max-heap a partir do array
- Troca o maior elemento (raiz) com o √∫ltimo
- Reduz o tamanho do heap e reconstr√≥i (heapify)
- Repete at√© ordenar todo o array
- Elementos v√£o sendo colocados em ordem no final do array

**Quando usar:**
- Quando garantia de O(n log n) √© necess√°ria **e** mem√≥ria √© limitada
- Sistemas em tempo real com requisitos previs√≠veis
- Quando estabilidade n√£o √© importante
- Implementa√ß√£o de fila de prioridade com ordena√ß√£o

**Exemplo de uso detalhado:**
```c
int arr[] = {12, 11, 13, 5, 6, 7};
int n = 6;

// Fase 1: Construir Max-Heap
// Array original: [12, 11, 13, 5, 6, 7]

// Come√ßar do √∫ltimo n√≥ n√£o-folha: i = n/2 - 1 = 2
// √çndice 2 (valor 13): j√° satisfaz propriedade heap
//       12
//      /  \
//    11    13
//   /  \   /
//  5   6  7

// √çndice 1 (valor 11): comparar com filhos (5, 6)
// 11 > 6, ok
//       12
//      /  \
//    11    13
//   /  \   /
//  5   6  7

// √çndice 0 (valor 12): comparar com filhos (11, 13)
// 12 < 13, trocar!
//       13
//      /  \
//    11    12
//   /  \   /
//  5   6  7

// Array ap√≥s build-heap: [13, 11, 12, 5, 6, 7]

// Fase 2: Ordena√ß√£o (extrair m√°ximo repetidamente)

// Itera√ß√£o 1:
// Trocar raiz (13) com √∫ltimo elemento (7)
// [7, 11, 12, 5, 6, | 13]
// Heapify na raiz:
//       12
//      /  \
//    11    7
//   /  \
//  5   6
// Array: [12, 11, 7, 5, 6, | 13]

// Itera√ß√£o 2:
// Trocar raiz (12) com √∫ltimo n√£o-ordenado (6)
// [6, 11, 7, 5, | 12, 13]
// Heapify:
//       11
//      /  \
//    6     7
//   /
//  5
// Array: [11, 6, 7, 5, | 12, 13]

// Itera√ß√£o 3:
// [5, 6, 7, | 11, 12, 13]
// Heapify:
//       7
//      /  \
//    6     5
// Array: [7, 6, 5, | 11, 12, 13]

// Itera√ß√£o 4:
// [5, 6, | 7, 11, 12, 13]
// Heapify:
//       6
//      /
//    5
// Array: [6, 5, | 7, 11, 12, 13]

// Itera√ß√£o 5:
// [5, | 6, 7, 11, 12, 13]

// Resultado final: [5, 6, 7, 11, 12, 13]

heapSort(arr, n);
```

**Pseudoc√≥digo Formal:**
```
HEAP-SORT(A, n)
1  BUILD-MAX-HEAP(A, n)
2  for i ‚Üê n downto 2
3      swap A[1] with A[i]
4      heap-size ‚Üê heap-size - 1
5      MAX-HEAPIFY(A, 1)

BUILD-MAX-HEAP(A, n)
1  heap-size ‚Üê n
2  for i ‚Üê ‚åän/2‚åã downto 1
3      MAX-HEAPIFY(A, i)

MAX-HEAPIFY(A, i)
1  l ‚Üê LEFT(i)
2  r ‚Üê RIGHT(i)
3  if l ‚â§ heap-size and A[l] > A[i]
4      largest ‚Üê l
5  else largest ‚Üê i
6  if r ‚â§ heap-size and A[r] > A[largest]
7      largest ‚Üê r
8  if largest ‚â† i
9      swap A[i] with A[largest]
10     MAX-HEAPIFY(A, largest)
```

**Aplica√ß√µes do Heap:**
- **Ordena√ß√£o**: Heap Sort
- **Fila de prioridade**: Hospitais (triagem), SO (escalonamento)
- **Algoritmo de Dijkstra**: Caminho mais curto
- **Huffman coding**: Compress√£o de dados
- **K maiores elementos**: Heap de tamanho k

### 7. Shell Sort (`shellSort.c`)

#### Explica√ß√£o Acad√™mica

O **Shell Sort**, desenvolvido por Donald Shell em 1959, √© uma **generaliza√ß√£o sofisticada do Insertion Sort**. Ele supera a limita√ß√£o do Insertion Sort de comparar apenas elementos adjacentes, usando uma sequ√™ncia de "gaps" (intervalos) decrescentes.

**Princ√≠pio de Funcionamento:**

Em vez de comparar elementos adjacentes (gap = 1), o Shell Sort come√ßa comparando elementos distantes e gradualmente reduz o gap at√© chegar a 1 (Insertion Sort normal). Esta estrat√©gia move elementos para perto de suas posi√ß√µes finais mais rapidamente.

**Como funciona:**
- Generaliza√ß√£o do Insertion Sort com gaps decrescentes
- Come√ßa comparando elementos distantes (gap grande)
- Reduz o gap progressivamente
- Termina com gap = 1 (Insertion Sort cl√°ssico)
- Array fica "quase ordenado" antes do passo final

**An√°lise de Complexidade:**

A complexidade depende **crucialmente da sequ√™ncia de gaps escolhida**:

| Sequ√™ncia de Gap | Complexidade | Autor |
|------------------|--------------|-------|
| n/2, n/4, ..., 1 | O(n¬≤) | Shell (original) |
| 2^k - 1 | O(n^1.5) | Hibbard |
| 2^i √ó 3^j | O(n log¬≤ n) | Pratt |
| (9√ó4^i - 9√ó2^i + 1)/5 | O(n^1.3) | Sedgewick |
| Desconhecido | ? | Ciura (melhor na pr√°tica) |

**Sequ√™ncias de Gap Comuns:**

1. **Shell Original**: n/2, n/4, n/8, ..., 1
   ```c
   for (gap = n/2; gap > 0; gap /= 2)
   ```
   - Simples mas pior caso O(n¬≤)

2. **Knuth**: (3^k - 1)/2 = 1, 4, 13, 40, 121, ...
   ```c
   gap = 1;
   while (gap < n/3) gap = 3*gap + 1;
   for (; gap > 0; gap /= 3)
   ```
   - Complexidade O(n^1.5)
   - Popular e eficiente

3. **Ciura**: 1, 4, 10, 23, 57, 132, 301, 701, 1750, ...
   ```c
   int gaps[] = {701, 301, 132, 57, 23, 10, 4, 1};
   ```
   - Melhor desempenho pr√°tico
   - Empiricamente determinado

**Quando usar:**
- Arrays de tamanho m√©dio (1000-5000 elementos)
- Quando simplicidade de implementa√ß√£o √© importante
- Como alternativa ao Insertion Sort para arrays maiores
- Quando n√£o pode usar recurs√£o (sistemas embarcados)
- C√≥digo legado que precisa ser simples e eficiente

**Exemplo de uso detalhado:**
```c
int arr[] = {23, 29, 15, 19, 31, 7, 9, 5, 2};
int n = 9;

// Usando sequ√™ncia de Knuth: gaps = [4, 1]

// Gap = 4:
// Comparar elementos a dist√¢ncia 4
// Sublistas: 
//   [23, 31, 2] (√≠ndices 0, 4, 8)
//   [29, 7]     (√≠ndices 1, 5)
//   [15, 9]     (√≠ndices 2, 6)
//   [19, 5]     (√≠ndices 3, 7)

// Ordenar cada sublista com Insertion Sort:
// [23, 31, 2] ‚Üí [2, 23, 31]  arr: [2, 29, 15, 19, 31, 7, 9, 5, 23]
// [29, 7]     ‚Üí [7, 29]       arr: [2, 7, 15, 19, 31, 29, 9, 5, 23]
// [15, 9]     ‚Üí [9, 15]       arr: [2, 7, 9, 19, 31, 29, 15, 5, 23]
// [19, 5]     ‚Üí [5, 19]       arr: [2, 7, 9, 5, 31, 29, 15, 19, 23]

// Array ap√≥s gap=4: [2, 7, 9, 5, 31, 29, 15, 19, 23]
// Observe: n√£o est√° ordenado, mas elementos grandes moveram para direita

// Gap = 1 (Insertion Sort normal):
// [2, 7, 9, 5, 31, 29, 15, 19, 23]
// Inserir 5: [2, 5, 7, 9, 31, 29, 15, 19, 23]
// Inserir 31: j√° no lugar
// Inserir 29: [2, 5, 7, 9, 29, 31, 15, 19, 23]
// Inserir 15: [2, 5, 7, 9, 15, 29, 31, 19, 23]
// Inserir 19: [2, 5, 7, 9, 15, 19, 29, 31, 23]
// Inserir 23: [2, 5, 7, 9, 15, 19, 23, 29, 31]

shellSort(arr, n);
// Resultado final: {2, 5, 7, 9, 15, 19, 23, 29, 31}

// Vantagem: O passo final (gap=1) √© muito mais r√°pido porque
// o array j√° est√° "quase ordenado" pelos passos anteriores
```

**Pseudoc√≥digo Formal (Knuth):**
```
SHELL-SORT(A, n)
1  gap ‚Üê 1
2  while gap < n/3
3      gap ‚Üê 3 √ó gap + 1
4  while gap > 0
5      for i ‚Üê gap to n
6          temp ‚Üê A[i]
7          j ‚Üê i
8          while j ‚â• gap and A[j-gap] > temp
9              A[j] ‚Üê A[j-gap]
10             j ‚Üê j - gap
11         A[j] ‚Üê temp
12     gap ‚Üê gap / 3
```

**Por que Shell Sort funciona?**

**Intui√ß√£o**: Mover elementos para perto de suas posi√ß√µes finais rapidamente
```
Array inicial: [100, 90, 80, 70, ..., 3, 2, 1]

Insertion Sort normal (gap=1):
- 100 precisa mover 99 posi√ß√µes ‚Üí 99 trocas
- Total: O(n¬≤) movimenta√ß√µes

Shell Sort com gaps grandes:
- Gap=33: 100 move 3 posi√ß√µes ‚Üí 3 trocas
- Gap=11: Ajustes finos
- Gap=1:  Array j√° quase ordenado ‚Üí O(n)
```

**An√°lise Visual:**

```
Gap grande (h): "desentupir" invers√µes distantes
          ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄh‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
[9, 2, 8, 3, 7, 4, 6, 5, 1]
 ‚Üì              ‚Üì          ‚Üì
Compara elementos distantes

Gap pequeno: ajustes finos locais
    ‚ï≠‚îÄh‚îÄ‚ïÆ
[1, 3, 2, 5, 4, 7, 6, 9, 8]
```

**Compara√ß√£o com outros algoritmos:**

| Aspecto | Shell Sort | Insertion Sort | Quick Sort |
|---------|-----------|----------------|------------|
| Complexidade | O(n^1.3) * | O(n¬≤) | O(n log n) |
| Mem√≥ria | O(1) ‚úÖ | O(1) ‚úÖ | O(log n) |
| Est√°vel | N√£o ‚ùå | Sim ‚úÖ | N√£o ‚ùå |
| Adaptativo | Sim ‚úÖ | Sim ‚úÖ | N√£o ‚ùå |
| Recurs√£o | N√£o ‚úÖ | N√£o ‚úÖ | Sim ‚ùå |
| Implementa√ß√£o | Simples ‚úÖ | Muito simples | M√©dia |

*Depende da sequ√™ncia de gaps

**Quando N√ÉO usar Shell Sort:**
- Arrays muito grandes (> 100k): Quick/Merge Sort s√£o melhores
- Necessidade de estabilidade: Use Merge Sort
- Performance cr√≠tica: Quick Sort √© mais r√°pido
- Necessita garantia O(n log n): Merge/Heap Sort

**Exemplo de uso:**
```c
int arr[] = {23, 29, 15, 19, 31, 7, 9, 5, 2};
int n = 9;
shellSort(arr, n);
// Resultado: {2, 5, 7, 9, 15, 19, 23, 29, 31}
```

### 8. Bubble Sort Otimizado (`bubbleSortOptimized.c`)

**Como funciona:**
- Vers√£o melhorada do Bubble Sort
- Para quando nenhuma troca √© feita (array j√° ordenado)
- Reduz o melhor caso de O(n¬≤) para O(n)

**Quando usar:**
- Fins educacionais para mostrar otimiza√ß√µes
- Arrays pequenos que podem estar parcialmente ordenados

## üõ†Ô∏è Ferramentas Dispon√≠veis

### Compara√ß√£o de Performance (`comparacao.c`)

Ferramenta completa para benchmark dos algoritmos:
- Testa diferentes tipos de arrays (aleat√≥rio, ordenado, reverso)
- Mede tempo de execu√ß√£o
- Verifica corretude dos resultados
- Gera relat√≥rio comparativo

### Integra√ß√£o com Busca (`ordenacao_busca.c`)

Demonstra a rela√ß√£o entre ordena√ß√£o e algoritmos de busca:
- Compara busca linear vs. bin√°ria
- Mostra quando vale a pena ordenar antes de buscar
- Inclui busca interpolada
- An√°lise de trade-offs

## üöÄ Como Compilar e Executar

### Uso do Makefile (Recomendado)

Este diret√≥rio inclui um Makefile completo para facilitar a compila√ß√£o e teste:

```bash
# Compilar todos os algoritmos
make all

# Executar algoritmos b√°sicos
make run-all

# Executar algoritmos avan√ßados  
make run-advanced

# Executar benchmark de performance
make benchmark

# Testar se todos compilam
make test

# Ver ajuda completa
make help
```

### Compila√ß√£o Individual
```bash
gcc -Wall -Wextra -std=c99 -o bubbleSort bubbleSort.c
./bubbleSort
```

### Compila√ß√£o com Otimiza√ß√£o
```bash
# Debug
make debug

# Release (m√°xima otimiza√ß√£o)
make release
```

## üìä Compara√ß√£o de Desempenho

### Tabela Completa de Complexidade

| Algoritmo | Melhor Caso | Caso M√©dio | Pior Caso | Mem√≥ria | Est√°vel | M√©todo |
|-----------|-------------|------------|-----------|---------|---------|---------|
| **Bubble Sort** | O(n) | O(n¬≤) | O(n¬≤) | O(1) | ‚úÖ Sim | Troca |
| **Insertion Sort** | O(n) | O(n¬≤) | O(n¬≤) | O(1) | ‚úÖ Sim | Inser√ß√£o |
| **Selection Sort** | O(n¬≤) | O(n¬≤) | O(n¬≤) | O(1) | ‚ùå N√£o | Sele√ß√£o |
| **Shell Sort** | O(n log n) | O(n^1.3) | O(n¬≤) | O(1) | ‚ùå N√£o | Inser√ß√£o |
| **Quick Sort** | O(n log n) | O(n log n) | O(n¬≤) | O(log n) | ‚ùå N√£o | Parti√ß√£o |
| **Merge Sort** | O(n log n) | O(n log n) | O(n log n) | O(n) | ‚úÖ Sim | Divis√£o |
| **Heap Sort** | O(n log n) | O(n log n) | O(n log n) | O(1) | ‚ùå N√£o | Sele√ß√£o |

### An√°lise por Tamanho e Tipo de Dados

#### Para Arrays Pequenos (n < 50)

**Recomenda√ß√µes:**
1. **Insertion Sort** ‚≠ê - Melhor escolha geral
   - Overhead baixo: ~20 instru√ß√µes por elemento
   - Cache-friendly: acessa mem√≥ria sequencialmente
   - Adaptativo: O(n) se quase ordenado
   
2. **Selection Sort** - Quando trocas s√£o caras
   - Apenas n-1 trocas garantidas
   - √ötil em: EEPROM, Flash (escritas custosas)
   
3. **Bubble Sort** - Apenas educacional
   - O(n¬≤) sempre na pr√°tica
   - √ötil para ensinar conceitos

**Benchmark Real (n=50):**
```
Array Aleat√≥rio:
- Insertion Sort:  2.1 ¬µs
- Selection Sort:  3.5 ¬µs
- Shell Sort:      2.8 ¬µs
- Quick Sort:      4.2 ¬µs (overhead de recurs√£o)

Array 90% Ordenado:
- Insertion Sort:  0.5 ¬µs ‚≠ê (adaptativo)
- Selection Sort:  3.5 ¬µs (n√£o melhora)
- Quick Sort:      4.0 ¬µs
```

#### Para Arrays M√©dios (50 < n < 1000)

**Recomenda√ß√µes:**
1. **Quick Sort** ‚≠ê - Geralmente o mais r√°pido
   - Constantes pequenas no O(n log n)
   - Cache-friendly
   - Piv√¥ aleat√≥rio evita pior caso
   
2. **Merge Sort** - Quando estabilidade importa
   - Previs√≠vel: sempre O(n log n)
   - Est√°vel para ordena√ß√£o multi-campo
   - Requer O(n) mem√≥ria extra
   
3. **Shell Sort** - Compromisso interessante
   - Mais r√°pido que O(n¬≤) simples
   - In-place como Quick Sort
   - Mais simples (sem recurs√£o)

**Benchmark Real (n=1000):**
```
Array Aleat√≥rio:
- Quick Sort:     0.15 ms ‚≠ê
- Merge Sort:     0.25 ms
- Shell Sort:     0.40 ms
- Heap Sort:      0.50 ms
- Insertion Sort: 8.50 ms

Array Ordenado (pior caso para Quick Sort simples):
- Merge Sort:     0.25 ms ‚≠ê (consistente)
- Heap Sort:      0.50 ms
- Quick Sort:     25.0 ms ‚ùå (degradou para O(n¬≤))
- Insertion Sort: 0.02 ms (O(n) adaptativo!)

Array Reverso:
- Merge Sort:     0.25 ms ‚≠ê
- Heap Sort:      0.50 ms
- Quick Sort:     0.18 ms (com piv√¥ mediana-de-3)
- Insertion Sort: 15.0 ms
```

#### Para Arrays Grandes (n > 1000)

**Recomenda√ß√µes:**
1. **Quick Sort** ‚≠ê - Uso geral (com otimiza√ß√µes)
   - Com piv√¥ mediana-de-tr√™s
   - Cutoff para Insertion Sort (n < 10)
   - Usado em: C qsort(), C++ std::sort (Introsort)
   
2. **Merge Sort** - Garantias e estabilidade
   - Sempre O(n log n)
   - Est√°vel
   - Paraleliz√°vel
   - Usado em: Python sorted(), Java Arrays.sort() (objetos)
   
3. **Heap Sort** - Quando mem√≥ria √© cr√≠tica
   - O(n log n) garantido
   - O(1) mem√≥ria
   - Usado em: sistemas embarcados, kernel Linux
   
4. **Evitar completamente**:
   - Bubble Sort: O(n¬≤) = 1 trilh√£o de ops para n=1M
   - Selection Sort: O(n¬≤) sempre
   - Insertion Sort: O(n¬≤) para dados aleat√≥rios

**Benchmark Real (n=1,000,000):**
```
Array Aleat√≥rio (1 milh√£o de inteiros):
Hardware: CPU moderna 3.0 GHz

- Quick Sort (otimizado):   50 ms ‚≠ê‚≠ê‚≠ê
- Merge Sort:               85 ms ‚≠ê‚≠ê
- Heap Sort:               145 ms ‚≠ê
- Shell Sort:              310 ms
- Insertion Sort:      125,000 ms ‚ùå (~2 minutos!)
- Bubble Sort:         180,000 ms ‚ùå (~3 minutos!)

Mem√≥ria usada:
- Quick Sort:  ~8 KB (stack)
- Merge Sort:  ~4 MB (array auxiliar)
- Heap Sort:   ~100 bytes
```

### An√°lise por Tipo de Dados

#### Dados Quase Ordenados (< 10% invers√µes)

**Melhor escolha: Insertion Sort ou Tim Sort**

```
n=10,000, 5% desordenado:
- Insertion Sort:  0.8 ms ‚≠ê‚≠ê‚≠ê (O(n))
- Tim Sort:        1.2 ms ‚≠ê‚≠ê
- Quick Sort:      8.5 ms
- Merge Sort:      12.0 ms

Raz√£o: Pouqu√≠ssimas invers√µes para corrigir
```

#### Dados Completamente Aleat√≥rios

**Melhor escolha: Quick Sort (com otimiza√ß√µes)**

```
n=100,000, totalmente aleat√≥rio:
- Quick Sort:    5.2 ms ‚≠ê‚≠ê‚≠ê
- Merge Sort:    8.5 ms ‚≠ê‚≠ê
- Heap Sort:    14.2 ms ‚≠ê
- Shell Sort:   28.0 ms
```

#### Dados em Ordem Reversa

**Melhor escolha: Merge Sort ou Heap Sort**

```
n=50,000, ordem reversa:
- Merge Sort:   7.5 ms ‚≠ê‚≠ê‚≠ê (n√£o afetado)
- Heap Sort:   13.8 ms ‚≠ê‚≠ê
- Quick Sort:  15.2 ms ‚≠ê (com mediana-de-3)
- Quick Sort: 625.0 ms ‚ùå (piv√¥ simples = O(n¬≤))
```

#### Dados com Muitos Duplicados

**Melhor escolha: Quick Sort 3-way ou Merge Sort**

```
n=100,000, 90% duplicados:
- Quick Sort 3-way:  3.2 ms ‚≠ê‚≠ê‚≠ê (parti√ß√£o em 3)
- Merge Sort:        8.0 ms ‚≠ê‚≠ê
- Quick Sort 2-way: 12.5 ms ‚≠ê (muitas compara√ß√µes in√∫teis)
- Heap Sort:        14.0 ms
```

### An√°lise de Cache e Hardware Moderno

**Impacto da Hierarquia de Mem√≥ria:**

```
CPU moderna:
- L1 Cache: 32 KB, 1-2 ciclos
- L2 Cache: 256 KB, ~10 ciclos
- L3 Cache: 8 MB, ~40 ciclos
- RAM: GB+, ~200 ciclos
- Disco: TB+, ~10,000,000 ciclos

Implica√ß√µes:
1. Localidade espacial importa muito
2. Acesso sequencial >> acesso aleat√≥rio
3. Tamanho do working set afeta performance
```

**Cache Miss Rates (n=100,000):**

| Algoritmo | L1 Miss Rate | L2 Miss Rate | Performance |
|-----------|--------------|--------------|-------------|
| Insertion Sort | 2% | 0.1% | ‚≠ê‚≠ê‚≠ê Excelente |
| Quick Sort | 8% | 2% | ‚≠ê‚≠ê Bom |
| Merge Sort | 15% | 5% | ‚≠ê OK |
| Heap Sort | 25% | 15% | ‚ùå Ruim (random) |

**Explica√ß√£o:**
- **Insertion Sort**: Acessa dados sequencialmente (cache love it!)
- **Heap Sort**: Salta pelo array (heap property) = cache misses
- **Merge Sort**: Copia dados = mais tr√°fego de mem√≥ria

### Casos Especiais e Considera√ß√µes

#### Ordena√ß√£o de Strings

```c
// Strings longas: compara√ß√£o √© cara!
char* arr[] = {"longa_string_1", "longa_string_2", ...};

// Compara√ß√£o de string: O(m) onde m = comprimento
strcmp(s1, s2)  // Percorre at√© achar diferen√ßa

Impacto:
- Quick Sort: Muitas compara√ß√µes = caro
- Radix Sort: Melhor para strings! O(n√óm)
- Merge Sort: Menos compara√ß√µes = melhor
```

#### Ordena√ß√£o Est√°vel Necess√°ria

```c
// Multi-field sorting
struct Student {
    char name[50];
    int grade;
};

// Ordenar por grade, depois alfab√©tico
// 1. Ordenar por nome (alfab√©tico)
// 2. Ordenar por grade (DEVE ser est√°vel!)

Escolhas:
‚úÖ Merge Sort: Est√°vel + O(n log n)
‚úÖ Insertion Sort: Est√°vel mas O(n¬≤)
‚ùå Quick Sort: N√ÉO est√°vel
‚ùå Heap Sort: N√ÉO est√°vel
```

#### Ordena√ß√£o External (Arquivos Muito Grandes)

```
Problema: 1 TB de dados, 16 GB RAM

Solu√ß√£o: External Merge Sort
1. Divide em 64 chunks de 16GB
2. Ordena cada chunk (cabe na RAM)
3. K-way merge (k=64)

Por que n√£o Quick Sort?
- Requer acesso aleat√≥rio
- Disco: random access 100x mais lento
- Merge: leitura/escrita sequencial
```

### Decis√£o R√°pida - Fluxograma

```
                    [Precisa ordenar?]
                           |
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    |             |
                n < 50?        n >= 50?
                    |             |
              Insertion Sort     |
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            |         |
                     Est√°vel?    N√£o est√°vel?
                            |         |
                      Merge Sort  Quick Sort
                                      |
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              |                |
                      Mem√≥ria OK?      Mem√≥ria cr√≠tica?
                              |                |
                        Quick Sort        Heap Sort
```

### Resumo - Regras de Ouro

1. **n < 50**: Insertion Sort (simples e r√°pido)
2. **50 < n < 10,000**: Quick Sort (r√°pido na pr√°tica)
3. **n > 10,000**: 
   - **Velocidade**: Quick Sort otimizado
   - **Garantias**: Merge Sort ou Heap Sort
   - **Estabilidade**: Merge Sort
   - **Mem√≥ria limitada**: Heap Sort
4. **Dados quase ordenados**: Insertion Sort ou Tim Sort
5. **Strings longas**: Radix Sort ou Merge Sort
6. **Arquivos gigantes**: External Merge Sort

### Para Arrays Pequenos (n < 50)
1. **Insertion Sort** - Melhor para arrays quase ordenados
2. **Selection Sort** - Menor n√∫mero de trocas
3. **Bubble Sort** - Apenas para fins educacionais

### Para Arrays M√©dios (50 < n < 1000)
1. **Quick Sort** - Geralmente o mais r√°pido
2. **Merge Sort** - Consistente, est√°vel
3. **Insertion Sort** - Para arrays quase ordenados

### Para Arrays Grandes (n > 1000)
1. **Merge Sort** - Consistente O(n log n)
2. **Quick Sort** - R√°pido em m√©dia, mas O(n¬≤) no pior caso
3. **Evitar** algoritmos O(n¬≤)

## üõ†Ô∏è Otimiza√ß√µes Poss√≠veis

### Bubble Sort Otimizado
- Parar quando nenhuma troca for feita
- Reduzir o alcance a cada passagem

### Quick Sort Otimizado
- Escolha inteligente do piv√¥ (mediana de tr√™s)
- Alternar para Insertion Sort em arrays pequenos
- Implementa√ß√£o iterativa para evitar stack overflow

### Merge Sort Otimizado
- Usar arrays pr√©-alocados para merge
- Alternar para Insertion Sort em subarrays pequenos

## üß™ Casos de Teste Recomendados

### Casos B√°sicos
```c
// Array vazio
int arr[] = {};
int n = 0;

// Array com um elemento
int arr[] = {42};
int n = 1;

// Array j√° ordenado
int arr[] = {1, 2, 3, 4, 5};
int n = 5;

// Array em ordem inversa
int arr[] = {5, 4, 3, 2, 1};
int n = 5;

// Array com elementos duplicados
int arr[] = {3, 1, 4, 1, 5, 9, 2, 6, 5};
int n = 9;
```

## üìö Refer√™ncias

- Donald E. Knuth. *The Art of Computer Programming, Volume 3: Sorting and Searching*
- Robert Sedgewick. *Algorithms in C*
- Thomas H. Cormen et al. *Introduction to Algorithms* (CLRS)

## ü§î Quest√µes para Reflex√£o (com Respostas Detalhadas)

### Quest√£o 1: Estabilidade em Algoritmos de Ordena√ß√£o

**Pergunta**: Por que a estabilidade √© importante em algoritmos de ordena√ß√£o? D√™ um exemplo pr√°tico onde isso seria relevante.

**Resposta Detalhada**:

A **estabilidade** √© a propriedade de um algoritmo de ordena√ß√£o que garante que elementos com chaves iguais mantenham sua ordem relativa original ap√≥s a ordena√ß√£o. 

**Por que √© importante?**

1. **Ordena√ß√£o em m√∫ltiplas etapas**: Quando queremos ordenar por m√∫ltiplos crit√©rios sequencialmente
2. **Preserva√ß√£o de ordem anterior**: Quando dados j√° possuem alguma ordena√ß√£o significativa
3. **Consist√™ncia de resultados**: Garante comportamento previs√≠vel e reproduz√≠vel

**Exemplo Pr√°tico Detalhado**:

Imagine uma tabela de alunos com nome e nota:
```
Original:
[("Maria", 85), ("Jo√£o", 90), ("Ana", 85), ("Pedro", 90)]
```

Se ordenarmos primeiro por nome (alfabeticamente):
```
[("Ana", 85), ("Jo√£o", 90), ("Maria", 85), ("Pedro", 90)]
```

Agora, ordenando por nota de forma **est√°vel**:
```
[("Ana", 85), ("Maria", 85), ("Jo√£o", 90), ("Pedro", 90)]
```
Note que Ana continua antes de Maria (ambas com 85) e Jo√£o antes de Pedro (ambos com 90), mantendo a ordem alfab√©tica.

Se us√°ssemos um algoritmo **inst√°vel** (como Quick Sort padr√£o):
```
[("Maria", 85), ("Ana", 85), ("Pedro", 90), ("Jo√£o", 90)]
```
A ordem alfab√©tica foi perdida para alunos com a mesma nota.

**Aplica√ß√µes Reais**:
- **Banco de dados**: Consultas com ORDER BY m√∫ltiplo (ORDER BY departamento, nome)
- **Sistemas de arquivos**: Ordena√ß√£o por tipo e depois por data
- **E-commerce**: Ordenar produtos por categoria, depois por pre√ßo
- **Processamento de logs**: Ordenar por timestamp mantendo ordem de eventos simult√¢neos

**Algoritmos Est√°veis vs Inst√°veis**:
- ‚úÖ **Est√°veis**: Merge Sort, Insertion Sort, Bubble Sort, Counting Sort
- ‚ùå **Inst√°veis**: Quick Sort, Heap Sort, Selection Sort, Shell Sort

### Quest√£o 2: Quick Sort - Paradoxo da Complexidade

**Pergunta**: Explique por que Quick Sort tem complexidade O(n¬≤) no pior caso, mas ainda √© considerado um dos melhores algoritmos na pr√°tica.

**Resposta Detalhada**:

**Por que O(n¬≤) no pior caso?**

O pior caso ocorre quando o piv√¥ escolhido √© sempre o menor ou maior elemento, criando parti√ß√µes extremamente desbalanceadas:

```
Array: [1, 2, 3, 4, 5]
Escolhendo √∫ltimo elemento como piv√¥:

N√≠vel 1: piv√¥=5, particiona em [1,2,3,4] e []  - n compara√ß√µes
N√≠vel 2: piv√¥=4, particiona em [1,2,3] e []    - (n-1) compara√ß√µes  
N√≠vel 3: piv√¥=3, particiona em [1,2] e []      - (n-2) compara√ß√µes
...
Total: n + (n-1) + (n-2) + ... + 1 = n(n+1)/2 = O(n¬≤)
```

**Por que ainda √© o melhor na pr√°tica?**

1. **Caso M√©dio Dominante**: 
   - O(n log n) ocorre em ~99.99% dos casos com dados reais
   - Pior caso O(n¬≤) √© extremamente raro com piv√¥ aleat√≥rio
   - Probabilidade de pior caso com piv√¥ aleat√≥rio: < 1/(n!)

2. **Constantes Pequenas**:
   ```
   Quick Sort: ~1.4 √ó n log n compara√ß√µes (m√©dia)
   Merge Sort: ~1.0 √ó n log n compara√ß√µes, mas mais movimenta√ß√µes
   Heap Sort: ~2.0 √ó n log n compara√ß√µes
   ```

3. **Cache Efficiency**:
   - Quick Sort trabalha in-place com boa localidade de refer√™ncia
   - Acessa dados sequencialmente (friendly para cache L1/L2)
   - Merge Sort requer mem√≥ria adicional e mais cache misses

4. **Otimiza√ß√µes Pr√°ticas**:
   - **Mediana de tr√™s**: Escolhe piv√¥ melhor que primeiro/√∫ltimo
   - **Introsort**: Detecta recurs√£o profunda e muda para Heap Sort
   - **Cutoff**: Usa Insertion Sort para subarrays pequenos (< 10)

5. **Compara√ß√£o Real-World** (array de 1 milh√£o de elementos):
   ```
   Quick Sort (otimizado):  ~50ms
   Merge Sort:              ~80ms  (est√°vel, mas mais lento)
   Heap Sort:               ~120ms (garantia O(n log n), mas lento)
   ```

**Conclus√£o**: Na pr√°tica, Quick Sort combina velocidade m√©dia excepcional com baixo uso de mem√≥ria, superando as garantias te√≥ricas de pior caso atrav√©s de otimiza√ß√µes inteligentes.

### Quest√£o 3: Escolha de Algoritmo para Dados Parcialmente Ordenados

**Pergunta**: Para um array de 1 milh√£o de elementos j√° parcialmente ordenado, qual algoritmo voc√™ escolheria e por qu√™?

**Resposta Detalhada**:

**Resposta curta**: **Insertion Sort** ou **Tim Sort** (h√≠brido).

**An√°lise Completa**:

**Insertion Sort** seria surpreendentemente a melhor escolha! Aqui est√° o porqu√™:

1. **Adaptatividade**:
   - Em arrays parcialmente ordenados, muitos elementos j√° est√£o pr√≥ximos de suas posi√ß√µes finais
   - Insertion Sort requer apenas O(1) compara√ß√£o por elemento j√° posicionado
   - Complexidade: O(n + d) onde d = n√∫mero de invers√µes

2. **An√°lise Quantitativa**:
   ```
   Array 90% ordenado (1M elementos):
   - Insertion Sort: ~0.1n compara√ß√µes = 100k compara√ß√µes
   - Quick Sort: ~1.4n log n = 28M compara√ß√µes
   - Merge Sort: ~1.0n log n = 20M compara√ß√µes
   ```

3. **Exemplo Num√©rico**:
   ```
   Array: [1,2,3,4,5,100,7,8,9,10]
   
   Insertion Sort:
   - Elementos 1-5: J√° ordenados, 1 compara√ß√£o cada
   - Elemento 100: 1 compara√ß√£o (100 > 5)
   - Elemento 7: 2 compara√ß√µes (move 100)
   - Elementos 8-10: 1 compara√ß√£o cada
   Total: ~12 compara√ß√µes
   
   Quick Sort:
   - Deve processar todo array recursivamente
   - N√£o se beneficia da ordem parcial
   Total: ~30+ compara√ß√µes
   ```

**Tim Sort - A Solu√ß√£o Industrial**:

O algoritmo usado no Python e Java combina o melhor dos dois mundos:
```python
def timsort(array):
    # 1. Detecta "runs" (sequ√™ncias ordenadas)
    runs = find_runs(array)  # Encontra subsequ√™ncias ordenadas
    
    # 2. Estende runs curtos com Insertion Sort
    for run in runs:
        if len(run) < MIN_MERGE:
            insertion_sort(run)
    
    # 3. Merge runs usando Merge Sort
    while len(runs) > 1:
        merge_runs(runs)
```

**Caracter√≠sticas do Tim Sort**:
- Detecta e aproveita ordem parcial existente
- Est√°vel
- O(n) no melhor caso, O(n log n) no pior
- Usado em: Python's sorted(), Java's Arrays.sort(), Android

**Quando usar cada um**:
- **70%+ ordenado**: Insertion Sort puro
- **Dados mistos**: Tim Sort
- **Sem informa√ß√£o**: Quick Sort ou Merge Sort

**Benchmark Real** (1M elementos, 80% ordenados):
```
Insertion Sort: ~15ms
Tim Sort:       ~20ms
Quick Sort:     ~80ms
Merge Sort:     ~100ms
```

### Quest√£o 4: Otimiza√ß√£o do Bubble Sort

**Pergunta**: Como o Bubble Sort otimizado consegue atingir O(n) no melhor caso?

**Resposta Detalhada**:

**Mecanismo da Otimiza√ß√£o**:

O Bubble Sort otimizado usa uma **flag booleana** para detectar quando o array j√° est√° ordenado:

```c
void bubbleSortOptimized(int arr[], int n) {
    for (int i = 0; i < n - 1; i++) {
        int swapped = 0;  // Flag: assumindo que n√£o h√° trocas
        
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
                swapped = 1;  // Marca que houve troca
            }
        }
        
        // Se n√£o houve troca, array est√° ordenado
        if (swapped == 0) {
            break;  // Termina o algoritmo
        }
    }
}
```

**An√°lise do Melhor Caso**:

Para um array **j√° ordenado** [1, 2, 3, 4, 5]:

```
Passagem 1:
- Compara 1 e 2: 1 < 2, sem troca
- Compara 2 e 3: 2 < 3, sem troca
- Compara 3 e 4: 3 < 4, sem troca
- Compara 4 e 5: 4 < 5, sem troca
- swapped = 0 (nenhuma troca feita)
- BREAK - algoritmo termina!

Total: n-1 compara√ß√µes = O(n)
```

**Sem otimiza√ß√£o**:
```
Passagem 1: (n-1) compara√ß√µes
Passagem 2: (n-2) compara√ß√µes
Passagem 3: (n-3) compara√ß√µes
...
Total: (n-1) + (n-2) + ... + 1 = O(n¬≤)
```

**Otimiza√ß√µes Adicionais**:

1. **Cocktail Sort** (Bubble Sort bidirecional):
```c
void cocktailSort(int arr[], int n) {
    int swapped = 1;
    int start = 0, end = n - 1;
    
    while (swapped) {
        swapped = 0;
        
        // Passagem da esquerda para direita
        for (int i = start; i < end; i++) {
            if (arr[i] > arr[i + 1]) {
                swap(&arr[i], &arr[i + 1]);
                swapped = 1;
            }
        }
        
        if (!swapped) break;
        
        end--;
        swapped = 0;
        
        // Passagem da direita para esquerda
        for (int i = end - 1; i >= start; i--) {
            if (arr[i] > arr[i + 1]) {
                swap(&arr[i], &arr[i + 1]);
                swapped = 1;
            }
        }
        
        start++;
    }
}
```
**Benef√≠cio**: Elementos pequenos no final "descem" mais r√°pido.

2. **Redu√ß√£o de range**:
```c
// Memoriza a √∫ltima posi√ß√£o de troca
int lastSwap = n - 1;
for (int i = 0; i < n - 1; i++) {
    int newLastSwap = 0;
    for (int j = 0; j < lastSwap; j++) {
        if (arr[j] > arr[j + 1]) {
            swap(&arr[j], &arr[j + 1]);
            newLastSwap = j;
        }
    }
    if (newLastSwap == 0) break;
    lastSwap = newLastSwap;
}
```

**Quando a Otimiza√ß√£o Realmente Ajuda**:
- Arrays j√° ordenados: O(n¬≤) ‚Üí O(n)
- Arrays quase ordenados: Reduz itera√ß√µes significativamente
- Arrays aleat√≥rios: Pouca melhora (ainda O(n¬≤))

### Quest√£o 5: Insertion Sort vs Quick Sort - Quando Usar?

**Pergunta**: Em que situa√ß√µes espec√≠ficas voc√™ usaria Insertion Sort em vez de Quick Sort?

**Resposta Detalhada**:

**Situa√ß√µes Favor√°veis ao Insertion Sort**:

1. **Arrays Pequenos (n < 10-50)**:
```
Benchmark (milissegundos):
n=10:  Insertion Sort: 0.001ms, Quick Sort: 0.002ms
n=20:  Insertion Sort: 0.003ms, Quick Sort: 0.005ms
n=50:  Insertion Sort: 0.015ms, Quick Sort: 0.025ms

Motivo: Overhead de recurs√£o do Quick Sort supera o benef√≠cio
```

2. **Arrays Quase Ordenados**:
```c
// Array 95% ordenado
int arr[] = {1,2,3,4,5,100,7,8,9,10,11,12};

Insertion Sort: O(n + d) onde d = invers√µes
- Apenas ~7 invers√µes para corrigir
- Tempo: ~O(n)

Quick Sort: O(n log n)
- N√£o detecta ordem existente
- Sempre divide e conquista
```

3. **Ordena√ß√£o Online (streaming)**:
```c
// Recebendo dados em tempo real
void processNewData(int value) {
    addToArray(value);
    insertionSort(array, size);  // Incrementalmente mant√©m ordenado
}

// Insertion Sort insere novo elemento em O(n)
// Quick Sort precisaria reordenar tudo em O(n log n)
```

4. **Estabilidade Requerida com Mem√≥ria Limitada**:
```
Requisitos:
- Deve ser est√°vel: ‚úì Insertion Sort, ‚úó Quick Sort
- Deve ser in-place: ‚úì Ambos
- Mem√≥ria O(1): ‚úì Insertion Sort O(1), Quick Sort O(log n) pela pilha

Escolha: Insertion Sort
```

5. **Sistemas Embarcados com Restri√ß√µes**:
```c
// Microcontrolador com 4KB RAM, processando 20 sensores
struct SensorData sensors[20];

// Insertion Sort:
// - C√≥digo simples: ~30 linhas
// - Sem recurs√£o: stack pequeno
// - Previs√≠vel: sempre n¬≤ no pior caso

// Quick Sort:
// - Mais complexo: ~100 linhas  
// - Recurs√£o: pode estourar stack
// - Imprevis√≠vel: n¬≤ no pior caso inesperado
```

6. **Quando Simplicidade √© Cr√≠tica**:
```c
// Insertion Sort - cristalino
void insertionSort(int arr[], int n) {
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}
// 9 linhas, f√°cil de auditar e provar correto

// Quick Sort - mais complexo
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
// Requer fun√ß√£o partition adicional, recurs√£o, mais dif√≠cil provar
```

**Tabela de Decis√£o Pr√°tica**:

| Cen√°rio | Escolha | Raz√£o |
|---------|---------|-------|
| n < 50 | Insertion Sort | Menos overhead |
| 90%+ ordenado | Insertion Sort | O(n) adaptativo |
| Dados aleat√≥rios grandes | Quick Sort | O(n log n) m√©dio |
| Streaming/Online | Insertion Sort | Insere incrementalmente |
| Est√°vel + In-place | Insertion Sort | Quick Sort n√£o √© est√°vel |
| Embarcado/Cr√≠tico | Insertion Sort | Sem recurs√£o, simples |
| Performance m√°xima | Tim Sort/Introsort | H√≠brido = melhor dos 2 |

**Solu√ß√£o Industrial - Algoritmos H√≠bridos**:

A maioria das bibliotecas modernas usa uma combina√ß√£o:

```c
void hybridSort(int arr[], int low, int high) {
    int size = high - low + 1;
    
    // Arrays pequenos: Insertion Sort
    if (size < CUTOFF) {  // CUTOFF = 10-20
        insertionSort(arr, low, high);
        return;
    }
    
    // Arrays grandes: Quick Sort
    int pi = partition(arr, low, high);
    hybridSort(arr, low, pi - 1);
    hybridSort(arr, pi + 1, high);
}
```

**Exemplos Reais**:
- **C++ std::sort**: Introsort (Quick + Heap + Insertion)
- **Python sorted()**: Tim Sort (Merge + Insertion)
- **Java Arrays.sort()**: Dual-Pivot Quick + Insertion
- **Linux kernel**: Heap Sort (garantias em kernel space)

**Conclus√£o**: Insertion Sort domina em pequenas escalas e dados parcialmente ordenados. Quick Sort domina em grandes volumes de dados aleat√≥rios. Algoritmos modernos combinam ambos para obter o melhor resultado.

## ‚ö†Ô∏è Armadilhas Comuns e Boas Pr√°ticas

### Erro 1: Ignorar o Tamanho da Entrada

**Armadilha:**
```c
void sort(int arr[], int n) {
    bubbleSort(arr, n);  // Sempre usa Bubble Sort!
}
```

**Por que √© ruim:**
- Para n=10: OK (~100 opera√ß√µes)
- Para n=1000: Lento (~1 milh√£o de opera√ß√µes)
- Para n=100,000: Impratic√°vel (~10 bilh√µes de opera√ß√µes)

**Melhor pr√°tica:**
```c
void sortAdaptive(int arr[], int n) {
    if (n < 50) {
        insertionSort(arr, n);    // O(n¬≤) OK para pequenos
    } else if (n < 100000) {
        quickSort(arr, 0, n-1);   // O(n log n) para m√©dios
    } else {
        mergeSort(arr, 0, n-1);   // Garantia para grandes
    }
}
```

### Erro 2: Quick Sort Sem Prote√ß√£o Contra Pior Caso

**Armadilha:**
```c
// Piv√¥ sempre no final
int partition(int arr[], int low, int high) {
    int pivot = arr[high];  // ‚ùå Pior caso para dados ordenados!
    // ...
}
```

**Impacto:**
```
Array ordenado [1,2,3,...,n]:
- Parti√ß√µes: [vazio] e [n-1 elementos]
- Recurs√£o: n n√≠veis
- Complexidade: O(n¬≤) ‚ùå
- Para n=100,000: ~10 bilh√µes de opera√ß√µes
- Stack overflow poss√≠vel!
```

**Melhor pr√°tica:**
```c
// Mediana de tr√™s elementos
int medianOfThree(int arr[], int low, int high) {
    int mid = low + (high - low) / 2;
    
    // Ordena arr[low], arr[mid], arr[high]
    if (arr[mid] < arr[low])
        swap(&arr[low], &arr[mid]);
    if (arr[high] < arr[low])
        swap(&arr[low], &arr[high]);
    if (arr[high] < arr[mid])
        swap(&arr[mid], &arr[high]);
    
    // Coloca mediana no high-1
    swap(&arr[mid], &arr[high-1]);
    return arr[high-1];
}

// Ou ainda melhor: piv√¥ aleat√≥rio
int randomPivot(int arr[], int low, int high) {
    int randomIndex = low + rand() % (high - low + 1);
    swap(&arr[randomIndex], &arr[high]);
    return arr[high];
}
```

### Erro 3: N√£o Verificar Casos Limites

**Armadilha:**
```c
void insertionSort(int arr[], int n) {
    for (int i = 1; i < n; i++) {  // ‚ùå E se n=0 ou n=1?
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}

// Testes que deveriam passar:
insertionSort(NULL, 0);           // ‚ùå Segfault!
insertionSort(arr, 0);            // ‚úì OK (loop n√£o executa)
insertionSort(singleElement, 1);  // ‚úì OK (loop n√£o executa)
```

**Melhor pr√°tica:**
```c
void insertionSortSafe(int arr[], int n) {
    // Valida√ß√£o de entrada
    if (arr == NULL || n <= 1) {
        return;  // Nada a fazer
    }
    
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}

// Testes abrangentes:
void testEdgeCases() {
    // Array vazio
    insertionSortSafe(NULL, 0);
    
    // Array de 1 elemento
    int single[] = {42};
    insertionSortSafe(single, 1);
    assert(single[0] == 42);
    
    // Array de 2 elementos
    int two[] = {2, 1};
    insertionSortSafe(two, 2);
    assert(two[0] == 1 && two[1] == 2);
    
    // Todos iguais
    int equal[] = {5, 5, 5, 5};
    insertionSortSafe(equal, 4);
    
    // J√° ordenado
    int sorted[] = {1, 2, 3, 4};
    insertionSortSafe(sorted, 4);
}
```

### Erro 4: Overflow em C√°lculo de Meio

**Armadilha:**
```c
void mergeSort(int arr[], int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;  // ‚ùå Overflow!
        // Se left=2,000,000,000 e right=2,100,000,000
        // left + right = 4,100,000,000 > INT_MAX (overflow)
        // mid fica negativo!
    }
}
```

**Melhor pr√°tica:**
```c
void mergeSortSafe(int arr[], int left, int right) {
    if (left < right) {
        // Evita overflow
        int mid = left + (right - left) / 2;  // ‚úÖ Seguro
        
        mergeSortSafe(arr, left, mid);
        mergeSortSafe(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}
```

### Erro 5: Compara√ß√£o Inst√°vel por Engano

**Armadilha:**
```c
// Tentativa de tornar Quick Sort est√°vel
int partition(int arr[], int low, int high) {
    int pivot = arr[high];
    int i = low - 1;
    
    for (int j = low; j < high; j++) {
        if (arr[j] <= pivot) {  // ‚ùå "<=" quebra estabilidade
            i++;
            swap(&arr[i], &arr[j]);
        }
    }
    swap(&arr[i + 1], &arr[high]);
    return i + 1;
}

// Exemplo:
// arr = [{3,'a'}, {3,'b'}, {1,'c'}]
// Ap√≥s ordena√ß√£o: [{1,'c'}, {3,'b'}, {3,'a'}]
// Ordem de 'a' e 'b' foi invertida!
```

**Melhor pr√°tica:**
```c
// Para estabilidade, use algoritmo inerentemente est√°vel
// Merge Sort, Insertion Sort, Bubble Sort

// Ou adicione √≠ndice original como crit√©rio de desempate
struct Element {
    int value;
    int originalIndex;
};

int compareStable(const void* a, const void* b) {
    Element* e1 = (Element*)a;
    Element* e2 = (Element*)b;
    
    if (e1->value != e2->value) {
        return e1->value - e2->value;
    }
    // Desempate: preserva ordem original
    return e1->originalIndex - e2->originalIndex;
}
```

### Erro 6: Vazamento de Mem√≥ria em Merge Sort

**Armadilha:**
```c
void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    int* L = (int*)malloc(n1 * sizeof(int));  // Aloca
    int* R = (int*)malloc(n2 * sizeof(int));  // Aloca
    
    // ... copia e merge ...
    
    // ‚ùå Esqueceu de liberar!
    // free(L);
    // free(R);
}

// Impacto:
// Para n=1M: log‚ÇÇ(1M) = ~20 n√≠veis
// Cada n√≠vel aloca O(n) mem√≥ria
// Vazamento total: ~20n = 80MB n√£o liberados!
```

**Melhor pr√°tica:**
```c
void mergeSafe(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    int* L = (int*)malloc(n1 * sizeof(int));
    int* R = (int*)malloc(n2 * sizeof(int));
    
    if (L == NULL || R == NULL) {
        // Trata erro de aloca√ß√£o
        free(L);  // free(NULL) √© seguro
        free(R);
        fprintf(stderr, "Erro: mem√≥ria insuficiente\n");
        exit(1);
    }
    
    // ... copia e merge ...
    
    // ‚úÖ SEMPRE libera
    free(L);
    free(R);
}

// Ou melhor ainda: aloca uma vez e reutiliza
void mergeSortWithBuffer(int arr[], int temp[], int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        mergeSortWithBuffer(arr, temp, left, mid);
        mergeSortWithBuffer(arr, temp, mid + 1, right);
        mergeWithBuffer(arr, temp, left, mid, right);
    }
}

void sortWrapper(int arr[], int n) {
    int* temp = (int*)malloc(n * sizeof(int));
    if (temp == NULL) {
        fprintf(stderr, "Erro: mem√≥ria insuficiente\n");
        exit(1);
    }
    
    mergeSortWithBuffer(arr, temp, 0, n - 1);
    
    free(temp);  // Libera uma √∫nica vez
}
```

### Erro 7: N√£o Considerar Tipos de Dados Diferentes

**Armadilha:**
```c
// Fun√ß√£o s√≥ funciona com int
void sort(int arr[], int n) {
    // ...
}

// E se eu quiser ordenar doubles? Strings? Structs?
```

**Melhor pr√°tica:**
```c
// Usar comparador gen√©rico
typedef int (*CompareFunc)(const void*, const void*);

void sortGeneric(void* arr, int n, size_t size, CompareFunc cmp) {
    char* bytes = (char*)arr;
    
    for (int i = 1; i < n; i++) {
        // Copia elemento (gen√©rico)
        char key[size];
        memcpy(key, bytes + i * size, size);
        
        int j = i - 1;
        while (j >= 0 && cmp(bytes + j * size, key) > 0) {
            memcpy(bytes + (j + 1) * size, bytes + j * size, size);
            j--;
        }
        memcpy(bytes + (j + 1) * size, key, size);
    }
}

// Comparadores espec√≠ficos
int compareInt(const void* a, const void* b) {
    return (*(int*)a - *(int*)b);
}

int compareDouble(const void* a, const void* b) {
    double diff = *(double*)a - *(double*)b;
    return (diff > 0) - (diff < 0);  // Evita problemas de precis√£o
}

int compareString(const void* a, const void* b) {
    return strcmp(*(char**)a, *(char**)b);
}

// Uso:
int nums[] = {3, 1, 4, 1, 5};
sortGeneric(nums, 5, sizeof(int), compareInt);

double values[] = {3.14, 1.41, 2.71};
sortGeneric(values, 3, sizeof(double), compareDouble);
```

### Erro 8: Recurs√£o Sem Limite de Profundidade

**Armadilha:**
```c
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);      // ‚ùå Pode estourar stack
        quickSort(arr, pi + 1, high);
    }
}

// Para array ordenado com piv√¥ simples:
// - n=10,000: 10,000 n√≠veis de recurs√£o
// - Stack t√≠pico: 1-8 MB
// - Cada frame: ~32 bytes
// - Necess√°rio: 10,000 √ó 32 = 320 KB (OK)
// - n=100,000: 3.2 MB (perigoso!)
// - n=1,000,000: 32 MB (CRASH!)
```

**Melhor pr√°tica:**
```c
// Introsort: detecta recurs√£o profunda e muda algoritmo
void introsort(int arr[], int low, int high, int maxDepth) {
    int size = high - low + 1;
    
    // Arrays pequenos: Insertion Sort
    if (size < 16) {
        insertionSort(arr + low, size);
        return;
    }
    
    // Recurs√£o muito profunda: Heap Sort
    if (maxDepth == 0) {
        heapSort(arr + low, size);
        return;
    }
    
    // Quick Sort normal
    int pi = partition(arr, low, high);
    introsort(arr, low, pi - 1, maxDepth - 1);
    introsort(arr, pi + 1, high, maxDepth - 1);
}

void sortSafe(int arr[], int n) {
    int maxDepth = 2 * log2(n);  // Limite inteligente
    introsort(arr, 0, n - 1, maxDepth);
}

// Ou: tail call optimization
void quickSortIterative(int arr[], int low, int high) {
    while (low < high) {
        int pi = partition(arr, low, high);
        
        // Recurs√£o na parte menor (garante O(log n) stack)
        if (pi - low < high - pi) {
            quickSortIterative(arr, low, pi - 1);
            low = pi + 1;  // Itera na parte maior
        } else {
            quickSortIterative(arr, pi + 1, high);
            high = pi - 1;
        }
    }
}
```

### Boas Pr√°ticas Gerais

**1. Sempre me√ßa antes de otimizar:**
```c
#include <time.h>

double measureSort(void (*sortFunc)(int*, int), int arr[], int n) {
    clock_t start = clock();
    sortFunc(arr, n);
    clock_t end = clock();
    return (double)(end - start) / CLOCKS_PER_SEC;
}

// Teste com dados reais
int data[1000];
// ... preenche com dados reais do sistema ...

printf("Insertion: %.3f ms\n", measureSort(insertionSort, data, 1000) * 1000);
printf("Quick:     %.3f ms\n", measureSort(quickSort, data, 1000) * 1000);
```

**2. Documente complexidade e limita√ß√µes:**
```c
/**
 * Ordena array de inteiros usando Merge Sort.
 * 
 * Complexidade:
 *   - Tempo: O(n log n) em todos os casos
 *   - Espa√ßo: O(n) para array auxiliar
 * 
 * Caracter√≠sticas:
 *   - Est√°vel: Sim
 *   - In-place: N√£o
 *   - Adaptativo: N√£o
 * 
 * Limita√ß√µes:
 *   - Requer O(n) mem√≥ria extra
 *   - Pode falhar se malloc() falhar
 * 
 * @param arr Array a ser ordenado
 * @param n N√∫mero de elementos
 * @return 0 se sucesso, -1 se erro de mem√≥ria
 */
int mergeSort(int arr[], int n);
```

**3. Use biblioteca padr√£o quando poss√≠vel:**
```c
#include <stdlib.h>

// qsort() √© otimizado e testado
int compare(const void* a, const void* b) {
    return (*(int*)a - *(int*)b);
}

qsort(arr, n, sizeof(int), compare);

// S√≥ implemente seu pr√≥prio quando:
// - Necessita caracter√≠sticas espec√≠ficas (ex: estabilidade)
// - Tem informa√ß√µes especiais sobre dados
// - √â exerc√≠cio acad√™mico
```

**4. Teste exaustivamente:**
```c
void testSortingAlgorithm(void (*sort)(int*, int)) {
    // Caso 1: Array vazio
    sort(NULL, 0);
    
    // Caso 2: Um elemento
    int one[] = {42};
    sort(one, 1);
    assert(one[0] == 42);
    
    // Caso 3: J√° ordenado
    int sorted[] = {1, 2, 3, 4, 5};
    sort(sorted, 5);
    assert(isSorted(sorted, 5));
    
    // Caso 4: Ordem reversa
    int reversed[] = {5, 4, 3, 2, 1};
    sort(reversed, 5);
    assert(isSorted(reversed, 5));
    
    // Caso 5: Duplicados
    int dups[] = {3, 1, 4, 1, 5, 9, 2, 6, 5};
    sort(dups, 9);
    assert(isSorted(dups, 9));
    
    // Caso 6: Todos iguais
    int equal[] = {7, 7, 7, 7, 7};
    sort(equal, 5);
    assert(isSorted(equal, 5));
    
    // Caso 7: Grande aleat√≥rio
    int large[10000];
    fillRandom(large, 10000);
    sort(large, 10000);
    assert(isSorted(large, 10000));
}
```

**Conclus√£o**: Escrever algoritmos de ordena√ß√£o corretos e eficientes requer aten√ß√£o a detalhes, valida√ß√£o cuidadosa e compreens√£o profunda dos trade-offs. Sempre teste casos limites, considere as caracter√≠sticas dos seus dados, e me√ßa performance antes de otimizar.

### Quest√£o 6: Quando usar Merge Sort ao inv√©s de Quick Sort?

**Pergunta**: Quais s√£o os cen√°rios espec√≠ficos onde Merge Sort √© superior ao Quick Sort, apesar de ser geralmente mais lento?

**Resposta Detalhada**:

**Cen√°rios Favor√°veis ao Merge Sort:**

1. **Necessidade de Garantia Te√≥rica**:
```
Sistema cr√≠tico: Controle de tr√°fego a√©reo
- Requer tempo m√°ximo garantido
- Merge Sort: SEMPRE O(n log n) ‚úÖ
- Quick Sort: Pode ser O(n¬≤) no pior caso ‚ùå

Impacto:
- Merge: 1M elementos = m√°ximo 20M opera√ß√µes
- Quick: 1M elementos = at√© 1T opera√ß√µes (pior caso)
```

2. **Estabilidade Requerida**:
```c
// Banco de dados: Ordenar por m√∫ltiplos campos
struct Transaction {
    char date[11];
    char type[20];
    double amount;
};

// Primeiro ordena por tipo (cr√©dito, d√©bito)
// Depois ordena por data, mantendo ordem dentro de cada tipo
// Merge Sort preserva isso, Quick Sort N√ÉO
```

3. **Listas Encadeadas**:
```c
// Merge Sort √© O(1) extra para listas, Quick Sort √© dif√≠cil

Node* mergeSortList(Node* head) {
    // Vantagens:
    // 1. N√£o precisa acesso aleat√≥rio (array[i])
    // 2. N√£o precisa mem√≥ria extra para merge
    // 3. Apenas manipula ponteiros
    if (!head || !head->next) return head;
    
    Node* mid = getMiddle(head);
    Node* left = head;
    Node* right = mid->next;
    mid->next = NULL;
    
    return merge(mergeSortList(left), mergeSortList(right));
}

// Quick Sort em lista √© complexo e ineficiente
```

4. **Ordena√ß√£o Externa (Arquivos Grandes)**:
```
Problema: Ordenar arquivo de 100GB com 8GB de RAM

Merge Sort:
1. Divide em chunks de 8GB
2. Ordena cada chunk (cabe na RAM)
3. Faz k-way merge dos chunks
4. Leitura sequencial eficiente do disco

Quick Sort:
- Requer acesso aleat√≥rio
- Muitas seeks no disco (lento)
- Dif√≠cil particionar em arquivo
```

5. **Paraleliza√ß√£o Eficiente**:
```c
// Merge Sort paraleliza naturalmente
void mergeSortParallel(int arr[], int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        
        #pragma omp parallel sections
        {
            #pragma omp section
            mergeSortParallel(arr, left, mid);
            
            #pragma omp section
            mergeSortParallel(arr, mid+1, right);
        }
        
        merge(arr, left, mid, right);
    }
}

// As duas metades s√£o independentes!
// Quick Sort: parti√ß√µes desbalanceadas dificultam paraleliza√ß√£o
```

6. **Dados Sens√≠veis a Cache Misses**:
```
Quando dados n√£o cabem em cache:
- Merge Sort: Acesso sequencial previs√≠vel
- Quick Sort: Padr√£o de acesso irregular

Em SSDs/HDDs:
- Leitura sequencial: 500 MB/s
- Leitura aleat√≥ria: 50 MB/s (10x mais lento)
```

**Compara√ß√£o Direta:**

| Crit√©rio | Merge Sort | Quick Sort | Vencedor |
|----------|-----------|------------|----------|
| Pior caso | O(n log n) | O(n¬≤) | Merge ‚úÖ |
| Mem√≥ria | O(n) | O(log n) | Quick ‚úÖ |
| Estabilidade | Sim | N√£o | Merge ‚úÖ |
| Cache | Menos eficiente | Mais eficiente | Quick ‚úÖ |
| Listas encadeadas | Excelente | Ruim | Merge ‚úÖ |
| Paraleliza√ß√£o | F√°cil | Dif√≠cil | Merge ‚úÖ |
| Velocidade pr√°tica | ~80ms | ~50ms | Quick ‚úÖ |
| Previsibilidade | Total | Baixa | Merge ‚úÖ |

**Exemplo Real - Sistemas Cr√≠ticos:**

```c
// Sistema de controle de voo
void sortFlightPriorities(Flight* flights, int n) {
    // NUNCA usar Quick Sort aqui!
    // Pior caso pode atrasar decis√µes cr√≠ticas
    
    mergeSort(flights, n);  // Garantia O(n log n)
    
    // Alternativa: Heap Sort (tamb√©m O(n log n) garantido)
}
```

**Conclus√£o**: Use Merge Sort quando:
- Garantia de performance √© cr√≠tica
- Estabilidade √© necess√°ria
- Trabalha com listas encadeadas
- Ordena√ß√£o externa (arquivos)
- Paraleliza√ß√£o √© importante
- Pode alocar O(n) mem√≥ria extra

Use Quick Sort quando:
- Velocidade m√©dia √© prioridade
- Mem√≥ria √© limitada
- Dados em arrays
- N√£o precisa de estabilidade

### Quest√£o 7: O que s√£o invers√µes e como impactam algoritmos de ordena√ß√£o?

**Pergunta**: Explique o conceito de invers√µes em um array e como isso afeta a performance de diferentes algoritmos de ordena√ß√£o.

**Resposta Detalhada**:

**Defini√ß√£o de Invers√£o:**

Uma **invers√£o** √© um par de √≠ndices (i, j) onde i < j mas arr[i] > arr[j]. Em outras palavras, dois elementos que est√£o "fora de ordem".

**Exemplos:**

```c
// Array: [3, 1, 2]
// Invers√µes: (3,1), (3,2) = 2 invers√µes

// Array: [5, 4, 3, 2, 1] (ordem reversa)
// Invers√µes: (5,4), (5,3), (5,2), (5,1),
//            (4,3), (4,2), (4,1),
//            (3,2), (3,1),
//            (2,1)
// Total: 4+3+2+1 = 10 invers√µes = n(n-1)/2

// Array: [1, 2, 3, 4, 5] (j√° ordenado)
// Invers√µes: 0
```

**Contando Invers√µes:**

```c
int countInversions(int arr[], int n) {
    int count = 0;
    for (int i = 0; i < n - 1; i++) {
        for (int j = i + 1; j < n; j++) {
            if (arr[i] > arr[j]) {
                count++;
            }
        }
    }
    return count;
}

// Complexidade: O(n¬≤)
// Pode ser feito em O(n log n) com Merge Sort modificado
```

**Impacto por Algoritmo:**

**1. Insertion Sort - Diretamente Proporcional**
```c
// Complexidade: O(n + d) onde d = n√∫mero de invers√µes

Array: [5, 1, 4, 2, 3]
Invers√µes: (5,1), (5,4), (5,2), (5,3), (4,2), (4,3) = 6

// Cada invers√£o requer exatamente 1 deslocamento
Inserir 1: move 5 (1 opera√ß√£o)
Inserir 4: move 5 (1 opera√ß√£o)
Inserir 2: move 5, 4 (2 opera√ß√µes)
Inserir 3: move 5, 4 (2 opera√ß√µes)

Total: 6 opera√ß√µes = n√∫mero de invers√µes

// Array 90% ordenado: ~0.1n invers√µes = O(n)
// Array reverso: n(n-1)/2 invers√µes = O(n¬≤)
```

**2. Bubble Sort - Remove 1 Invers√£o por Troca**
```c
// Cada troca remove EXATAMENTE 1 invers√£o
// N√∫mero de trocas = n√∫mero de invers√µes

Array: [3, 1, 2] (2 invers√µes)
Pass 1: [1, 3, 2] - Remove invers√£o (3,1)
Pass 2: [1, 2, 3] - Remove invers√£o (3,2)

Total: 2 trocas = 2 invers√µes

// Pior caso (reverso): n(n-1)/2 trocas = O(n¬≤)
```

**3. Selection Sort - Ignora Invers√µes**
```c
// SEMPRE faz exatamente n-1 compara√ß√µes
// N√£o se adapta ao n√∫mero de invers√µes

Array ordenado:     O(n¬≤) compara√ß√µes
Array reverso:      O(n¬≤) compara√ß√µes
Array aleat√≥rio:    O(n¬≤) compara√ß√µes

// Vantagem: n√∫mero m√≠nimo de TROCAS (n-1)
```

**4. Merge Sort - Conta Invers√µes Eficientemente**
```c
// Pode contar invers√µes em O(n log n)
int mergeSortCountInv(int arr[], int temp[], int left, int right) {
    int inv_count = 0;
    if (left < right) {
        int mid = (left + right) / 2;
        
        inv_count += mergeSortCountInv(arr, temp, left, mid);
        inv_count += mergeSortCountInv(arr, temp, mid+1, right);
        inv_count += mergeCountInv(arr, temp, left, mid, right);
    }
    return inv_count;
}

// Durante merge, quando arr[i] > arr[j]:
// Existem (mid - i) invers√µes (todos elementos restantes da esquerda)
```

**5. Quick Sort - Performance Varia**
```c
// N√∫mero de invers√µes afeta escolha do piv√¥

Array quase ordenado (poucas invers√µes):
- Piv√¥ = √∫ltimo elemento ‚Üí parti√ß√µes desbalanceadas
- Performance: O(n¬≤)

Array muito embaralhado (muitas invers√µes):
- Piv√¥ tende a dividir melhor
- Performance: O(n log n)

// Ironia: Quick Sort √© PIOR quando h√° menos invers√µes!
```

**Aplica√ß√µes Pr√°ticas de Invers√µes:**

**1. Medida de "Desordem":**
```c
// Qu√£o diferente √© o ranking de dois ju√≠zes?
int judge1[] = {1, 2, 3, 4, 5};  // Ranking do juiz 1
int judge2[] = {2, 1, 5, 3, 4};  // Ranking do juiz 2

// Invers√µes entre rankings = medida de discord√¢ncia
// Usado em: Recomenda√ß√µes, an√°lise de dados, ML
```

**2. Detec√ß√£o de Padr√µes:**
```c
// E-commerce: Detectar comportamento an√¥malo
int normalOrder[] = {1, 2, 3, 4, 5};    // Ordem normal de compra
int userOrder[]   = {5, 4, 3, 2, 1};    // Ordem do usu√°rio

// Muitas invers√µes = comportamento suspeito (bot?)
```

**3. Otimiza√ß√£o de Algoritmos:**
```c
void adaptiveSort(int arr[], int n) {
    int inversions = countInversionsQuick(arr, n);
    double disorder = (double)inversions / (n * (n-1) / 2);
    
    if (disorder < 0.1) {
        // Menos de 10% desordenado
        insertionSort(arr, n);  // O(n)
    } else {
        quickSort(arr, 0, n-1);  // O(n log n)
    }
}
```

**Teorema Importante:**

```
Qualquer algoritmo baseado em COMPARA√á√ïES que ordena
permuta√ß√µes de n elementos precisa fazer pelo menos
Œ©(n log n) compara√ß√µes no pior caso.

Prova: √Årvore de decis√£o tem n! folhas
Altura m√≠nima = log‚ÇÇ(n!) = Œò(n log n)
```

**Conclus√£o**: Invers√µes s√£o uma medida fundamental da desordem em um array. Algoritmos adaptativos como Insertion Sort aproveitam arrays com poucas invers√µes, enquanto algoritmos como Selection Sort ignoram completamente essa informa√ß√£o.

### Quest√£o 8: Como funciona a mem√≥ria em algoritmos de ordena√ß√£o?

**Pergunta**: Explique o uso de mem√≥ria (complexidade espacial) nos diferentes algoritmos e o conceito de ordena√ß√£o "in-place".

**Resposta Detalhada**:

**Classifica√ß√£o por Uso de Mem√≥ria:**

**1. In-Place Verdadeiro: O(1) mem√≥ria extra**

```c
// Bubble Sort - apenas vari√°veis tempor√°rias
void bubbleSort(int arr[], int n) {
    int temp;  // O(1) mem√≥ria
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];       // Troca in-place
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }
    }
}
// Mem√≥ria total: Array original + O(1) = Œò(n)
```

**Algoritmos In-Place O(1):**
- Bubble Sort
- Insertion Sort
- Selection Sort
- Heap Sort
- Shell Sort

**2. In-Place com Stack de Recurs√£o: O(log n)**

```c
// Quick Sort - mem√≥ria na pilha de chamadas
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);  // O(1) local
        quickSort(arr, low, pi - 1);         // Recurs√£o
        quickSort(arr, pi + 1, high);        // Recurs√£o
    }
}

// Profundidade da recurs√£o:
// Melhor caso: log‚ÇÇ(n) n√≠veis ‚Üí O(log n) mem√≥ria
// Pior caso: n n√≠veis ‚Üí O(n) mem√≥ria (stack overflow!)

// Cada chamada recursiva usa ~O(1) mem√≥ria local
// Total: O(log n) no caso m√©dio
```

**3. N√£o In-Place: O(n) mem√≥ria extra**

```c
// Merge Sort - requer array auxiliar
void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    // Arrays tempor√°rios - O(n) mem√≥ria!
    int L[n1], R[n2];
    
    // Copia dados
    for (int i = 0; i < n1; i++)
        L[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[mid + 1 + j];
    
    // Merge de volta em arr[]
    // ...
}

// Cada n√≠vel de recurs√£o aloca O(n) total
// Mem√≥ria total: O(n) auxiliar + O(log n) recurs√£o
// Dominante: O(n)
```

**An√°lise Detalhada da Mem√≥ria:**

**Layout de Mem√≥ria - Bubble Sort:**
```
Stack:              Heap:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Array original (tamanho n)
‚îÇ int i        ‚îÇ    [5][3][8][2][9][1][4]
‚îÇ int j        ‚îÇ     ‚Üë Modificado in-place
‚îÇ int temp     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Total: 3 ints = 12 bytes (constante)
```

**Layout de Mem√≥ria - Quick Sort:**
```
Stack (recurs√£o):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ quickSort(0, 6)  ‚îÇ  ‚Üê Primeiro n√≠vel
‚îÇ  low=0, high=6   ‚îÇ
‚îÇ  pi=3            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ quickSort(0, 2)  ‚îÇ  ‚Üê Segundo n√≠vel
‚îÇ  low=0, high=2   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ quickSort(0, 1)  ‚îÇ  ‚Üê Terceiro n√≠vel
‚îÇ  low=0, high=1   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Profundidade: log‚ÇÇ(n) n√≠veis (m√©dia)
Mem√≥ria por n√≠vel: ~24 bytes
Total stack: 24 √ó log‚ÇÇ(n) bytes

Heap:
Array original (modificado in-place)
```

**Layout de Mem√≥ria - Merge Sort:**
```
Stack (recurs√£o):
Similar ao Quick Sort: O(log n)

Heap:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Array original [n elementos] ‚îÇ  ‚Üê n elementos
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Array auxiliar L [n/2]       ‚îÇ  ‚Üê n/2 elementos
‚îÇ Array auxiliar R [n/2]       ‚îÇ  ‚Üê n/2 elementos
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Em cada n√≠vel de recurs√£o, total de O(n) elementos
s√£o alocados nos arrays tempor√°rios

Total heap: n + n = 2n elementos = O(n)
```

**Otimiza√ß√µes de Mem√≥ria:**

**1. Quick Sort com Tail Call Optimization:**
```c
void quickSortOptimized(int arr[], int low, int high) {
    while (low < high) {
        int pi = partition(arr, low, high);
        
        // Recurs√£o na parti√ß√£o menor (garante O(log n) mem√≥ria)
        if (pi - low < high - pi) {
            quickSortOptimized(arr, low, pi - 1);
            low = pi + 1;  // Itera√ß√£o para parti√ß√£o maior
        } else {
            quickSortOptimized(arr, pi + 1, high);
            high = pi - 1;  // Itera√ß√£o para parti√ß√£o maior
        }
    }
}
// Garante stack de no m√°ximo O(log n)
```

**2. Merge Sort In-Place (complexo):**
```c
// Poss√≠vel mas MUITO mais lento (O(n log¬≤ n))
void mergeSortInPlace(int arr[], int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSortInPlace(arr, left, mid);
        mergeSortInPlace(arr, mid + 1, right);
        
        // Merge in-place - complexo!
        // Requer rota√ß√µes O(n) por merge
        mergeInPlace(arr, left, mid, right);
    }
}
// Trade-off: O(1) mem√≥ria mas tempo pior
```

**3. Heap Sort - In-Place Puro:**
```c
// Usa o pr√≥prio array como heap - zero mem√≥ria extra!
void heapSort(int arr[], int n) {
    // Build heap: reorganiza array in-place
    for (int i = n / 2 - 1; i >= 0; i--)
        heapify(arr, n, i);
    
    // Extrai elementos um por um
    for (int i = n - 1; i > 0; i--) {
        swap(&arr[0], &arr[i]);
        heapify(arr, i, 0);
    }
}
// Mem√≥ria: apenas vari√°veis tempor√°rias = O(1)
```

**Problemas Reais de Mem√≥ria:**

**1. Stack Overflow em Quick Sort:**
```c
// Array j√° ordenado com piv√¥ simples
int arr[1000000];  // 1 milh√£o de elementos
for (int i = 0; i < 1000000; i++) arr[i] = i;

quickSort(arr, 0, 999999);
// Pior caso: 1 milh√£o de n√≠veis de recurs√£o
// Stack t√≠pico: 1-8 MB
// CRASH! Stack overflow
```

**2. Merge Sort com Arquivos Grandes:**
```
Problema: Ordenar 100GB de dados com 8GB RAM

Abordagem Ing√™nua (falha):
- Tentar alocar 100GB na RAM
- Merge Sort tradicional
- ‚ùå Out of Memory!

Abordagem Correta (External Merge Sort):
1. Divide arquivo em chunks de 8GB
2. Ordena cada chunk (cabe na RAM)
3. K-way merge com buffer limitado
4. Usa disco como "mem√≥ria virtual"
```

**Tabela Comparativa de Mem√≥ria:**

| Algoritmo | Mem√≥ria Auxiliar | Stack | Total | In-Place? |
|-----------|------------------|-------|-------|-----------|
| Bubble | O(1) | O(1) | O(1) | ‚úÖ Sim |
| Insertion | O(1) | O(1) | O(1) | ‚úÖ Sim |
| Selection | O(1) | O(1) | O(1) | ‚úÖ Sim |
| Shell | O(1) | O(1) | O(1) | ‚úÖ Sim |
| Heap | O(1) | O(1) | O(1) | ‚úÖ Sim |
| Quick | O(1) | O(log n)* | O(log n) | ‚úÖ Quase |
| Merge | O(n) | O(log n) | O(n) | ‚ùå N√£o |

*O(n) no pior caso sem otimiza√ß√£o

**Trade-offs na Pr√°tica:**

```c
// Escolha baseada em restri√ß√µes de mem√≥ria

// Sistema embarcado (4KB RAM):
bubbleSort(arr, n);  // Simples, O(1) mem√≥ria

// Servidor (128GB RAM):
mergeSort(arr, n);   // O(n) mem√≥ria OK, est√°vel

// Desktop gamer (32GB RAM):
quickSort(arr, n);   // O(log n), r√°pido na pr√°tica

// Sistema cr√≠tico (garantias):
heapSort(arr, n);    // O(1) mem√≥ria + O(n log n) garantido
```

**Conclus√£o**: A complexidade espacial √© t√£o importante quanto a temporal. Algoritmos in-place (O(1)) s√£o essenciais para sistemas com mem√≥ria limitada, enquanto algoritmos com O(n) extra podem ser aceit√°veis quando performance e estabilidade s√£o prioridades.

## üìã Exerc√≠cios Pr√°ticos

### N√≠vel B√°sico

**1. Bubble Sort com Contador de Trocas**

Implemente uma vers√£o do Bubble Sort que conte o n√∫mero de trocas realizadas.

*Objetivo*: Entender a rela√ß√£o entre n√∫mero de invers√µes e trocas.

*Dica*: Adicione uma vari√°vel contador que incremente a cada swap().

*Solu√ß√£o esperada*:
```c
int bubbleSortCount(int arr[], int n) {
    int swaps = 0;
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
                swaps++;
            }
        }
    }
    return swaps;
}

// Teste: Array reverso de tamanho n tem n(n-1)/2 invers√µes
// Para [5,4,3,2,1]: espera 10 trocas
```

**2. Selection Sort Bidirecional**

Modifique o Selection Sort para encontrar simultaneamente o maior e menor elemento.

*Objetivo*: Reduzir o n√∫mero de passagens pela metade.

*Dica*: Em cada itera√ß√£o, encontre tanto o m√≠nimo quanto o m√°ximo e coloque-os nas extremidades.

*An√°lise*: Isso melhora a constante mas n√£o muda a complexidade O(n¬≤).

**3. Insertion Sort Decrescente**

Crie uma vers√£o do Insertion Sort que ordene em ordem decrescente.

*Objetivo*: Entender a l√≥gica de compara√ß√£o.

*Dica*: Inverta a condi√ß√£o de compara√ß√£o de `arr[j] > key` para `arr[j] < key`.

*Teste*: [1,5,3,2,4] deve resultar em [5,4,3,2,1].

### N√≠vel Intermedi√°rio

**4. Algoritmo H√≠brido (Quick + Insertion)**

Implemente uma vers√£o h√≠brida que use Insertion Sort para subarrays pequenos (< 10 elementos) e Quick Sort para arrays maiores.

*Objetivo*: Combinar efici√™ncia de Quick Sort com simplicidade de Insertion Sort.

*Conceito*: Quick Sort tem overhead que n√£o compensa para arrays pequenos.

*Implementa√ß√£o*:
```c
void hybridSort(int arr[], int low, int high) {
    if (high - low + 1 < 10) {
        // Subarray pequeno: Insertion Sort
        insertionSortRange(arr, low, high);
    } else if (low < high) {
        // Subarray grande: Quick Sort
        int pi = partition(arr, low, high);
        hybridSort(arr, low, pi - 1);
        hybridSort(arr, pi + 1, high);
    }
}
```

*Desafio*: Experimente diferentes valores de threshold (5, 10, 20, 50) e me√ßa o impacto na performance.

**5. Seletor Autom√°tico de Algoritmo**

Desenvolva uma fun√ß√£o que determine automaticamente o melhor algoritmo baseado no tamanho e caracter√≠sticas do array.

*Objetivo*: Criar uma fun√ß√£o de ordena√ß√£o "inteligente".

*Caracter√≠sticas a detectar*:
- Tamanho do array
- Grau de ordena√ß√£o (contar invers√µes aproximadamente)
- Presen√ßa de duplicados

*Estrutura*:
```c
void smartSort(int arr[], int n) {
    // Amostragem para detectar caracter√≠sticas
    int sampleSize = min(100, n/10);
    int inversions = countInversionsSample(arr, n, sampleSize);
    double disorder = (double)inversions / (sampleSize * (sampleSize-1) / 2);
    
    if (n < 50) {
        insertionSort(arr, n);
    } else if (disorder < 0.1) {
        // < 10% desordenado
        insertionSort(arr, n);
    } else if (n < 100000) {
        quickSort(arr, 0, n-1);
    } else {
        mergeSort(arr, 0, n-1);
    }
}
```

**6. Merge Sort Iterativo (Bottom-Up)**

Crie um Merge Sort iterativo (bottom-up) em vez da vers√£o recursiva.

*Objetivo*: Eliminar overhead de recurs√£o e stack.

*Conceito*: Comece mesclando pares individuais, depois pares de pares, etc.

*Pseudoc√≥digo*:
```
para cada tamanho = 1, 2, 4, 8, ..., n:
    para cada in√≠cio = 0, 2*tamanho, 4*tamanho, ...:
        fim = min(in√≠cio + 2*tamanho - 1, n-1)
        meio = in√≠cio + tamanho - 1
        merge(arr, in√≠cio, meio, fim)
```

*Vantagem*: Sem risco de stack overflow, mais cache-friendly.

### N√≠vel Avan√ßado

**7. Introsort (Quick Sort + Heap Sort)**

Implemente o algoritmo Introsort (Quick Sort com fallback para Heap Sort).

*Objetivo*: Garantir O(n log n) no pior caso mantendo velocidade m√©dia do Quick Sort.

*Estrat√©gia*:
1. Come√ßa com Quick Sort
2. Monitora profundidade de recurs√£o
3. Se exceder 2√ólog(n), muda para Heap Sort

*Implementa√ß√£o chave*:
```c
void introsort(int arr[], int low, int high, int maxDepth) {
    int n = high - low + 1;
    
    if (n <= 16) {
        insertionSort(arr + low, n);
        return;
    }
    
    if (maxDepth == 0) {
        // Atingiu limite: usa Heap Sort
        heapSort(arr + low, n);
        return;
    }
    
    int pi = partition(arr, low, high);
    introsort(arr, low, pi - 1, maxDepth - 1);
    introsort(arr, pi + 1, high, maxDepth - 1);
}

void sort(int arr[], int n) {
    int maxDepth = 2 * log2(n);
    introsort(arr, 0, n - 1, maxDepth);
}
```

*Teste*: Use arrays que causam pior caso no Quick Sort normal (j√° ordenados) e verifique que mant√©m performance.

**8. Merge Sort Paralelo**

Desenvolva uma vers√£o paralela do Merge Sort usando threads (pthreads ou OpenMP).

*Objetivo*: Aproveitar m√∫ltiplos cores para acelerar ordena√ß√£o.

*Conceito*: As duas metades podem ser ordenadas independentemente em paralelo.

*Implementa√ß√£o com OpenMP*:
```c
void mergeSortParallel(int arr[], int left, int right, int depth) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        
        // Apenas paraleliza nos primeiros n√≠veis
        if (depth > 0) {
            #pragma omp parallel sections
            {
                #pragma omp section
                mergeSortParallel(arr, left, mid, depth - 1);
                
                #pragma omp section
                mergeSortParallel(arr, mid + 1, right, depth - 1);
            }
        } else {
            // Sequencial para subproblemas pequenos
            mergeSortParallel(arr, left, mid, 0);
            mergeSortParallel(arr, mid + 1, right, 0);
        }
        
        merge(arr, left, mid, right);
    }
}

void sortParallel(int arr[], int n) {
    int numThreads = omp_get_max_threads();
    int depth = log2(numThreads);
    mergeSortParallel(arr, 0, n - 1, depth);
}
```

*Desafio*: Me√ßa speedup e efici√™ncia. Para n=1M, quantos cores voc√™ precisa para dobrar a velocidade?

**9. Algoritmo de Ordena√ß√£o Adaptativo**

Crie um algoritmo de ordena√ß√£o adaptativo que detecte padr√µes nos dados.

*Objetivo*: Criar um algoritmo que se adapta automaticamente aos dados.

*Padr√µes a detectar*:
- Sequ√™ncias j√° ordenadas (runs)
- Padr√µes c√≠clicos
- Distribui√ß√£o uniforme vs. concentrada

*Base do Tim Sort*:
```c
void adaptiveSort(int arr[], int n) {
    // 1. Encontra runs naturais (sequ√™ncias ordenadas)
    Run runs[MAX_RUNS];
    int numRuns = findRuns(arr, n, runs);
    
    // 2. Estende runs curtos com Insertion Sort
    for (int i = 0; i < numRuns; i++) {
        if (runs[i].length < MIN_RUN) {
            insertionSortRun(arr, runs[i]);
        }
    }
    
    // 3. Merge runs de forma inteligente (merge stack)
    while (numRuns > 1) {
        mergeOptimal(runs, &numRuns);
    }
}

Run* findRuns(int arr[], int n, Run runs[]) {
    int numRuns = 0;
    int i = 0;
    
    while (i < n) {
        int start = i;
        
        // Detecta run crescente ou decrescente
        if (i + 1 < n && arr[i] <= arr[i + 1]) {
            // Run crescente
            while (i + 1 < n && arr[i] <= arr[i + 1]) {
                i++;
            }
        } else {
            // Run decrescente (reverter)
            while (i + 1 < n && arr[i] > arr[i + 1]) {
                i++;
            }
            reverse(arr, start, i);
        }
        
        runs[numRuns++] = (Run){start, i - start + 1};
        i++;
    }
    
    return runs;
}
```

### Desafios

**10. Radix Sort para N√∫meros Negativos**

Implemente Radix Sort que funcione com n√∫meros negativos.

*Desafio*: Radix Sort padr√£o assume n√∫meros n√£o-negativos.

*Abordagem 1*: Separar positivos e negativos
```c
void radixSortSigned(int arr[], int n) {
    // 1. Particiona: negativos √† esquerda, positivos √† direita
    int partition = partitionBySign(arr, n);
    
    // 2. Ordena negativos (ordem reversa por magnitude)
    if (partition > 0) {
        radixSortNegative(arr, partition);
    }
    
    // 3. Ordena positivos normalmente
    if (partition < n) {
        radixSort(arr + partition, n - partition);
    }
}
```

*Abordagem 2*: Offset para tornar todos positivos
```c
void radixSortSignedOffset(int arr[], int n) {
    int min = findMin(arr, n);
    int offset = -min;  // Tornar todos n√£o-negativos
    
    for (int i = 0; i < n; i++) {
        arr[i] += offset;
    }
    
    radixSort(arr, n);
    
    for (int i = 0; i < n; i++) {
        arr[i] -= offset;
    }
}
```

**11. Ordena√ß√£o Externa para Arquivos Grandes**

Desenvolva um algoritmo de ordena√ß√£o externo para arquivos que n√£o cabem na mem√≥ria.

*Cen√°rio*: Ordenar arquivo de 100 GB com apenas 1 GB de RAM.

*Algoritmo (External Merge Sort)*:
```c
void externalSort(const char* inputFile, const char* outputFile, 
                  size_t availableMemory) {
    // Fase 1: Criar runs ordenados
    size_t runSize = availableMemory / sizeof(int);
    int numRuns = createSortedRuns(inputFile, "temp_run_", runSize);
    
    // Fase 2: K-way merge
    int k = availableMemory / (runSize * sizeof(int));
    kWayMerge("temp_run_", numRuns, outputFile, k);
}

int createSortedRuns(const char* inputFile, const char* runPrefix, 
                     size_t runSize) {
    FILE* input = fopen(inputFile, "rb");
    int* buffer = malloc(runSize * sizeof(int));
    int runNumber = 0;
    
    size_t read;
    while ((read = fread(buffer, sizeof(int), runSize, input)) > 0) {
        // Ordena run na mem√≥ria (Quick Sort)
        qsort(buffer, read, sizeof(int), compareInt);
        
        // Escreve run em arquivo tempor√°rio
        char filename[256];
        sprintf(filename, "%s%d.dat", runPrefix, runNumber++);
        FILE* output = fopen(filename, "wb");
        fwrite(buffer, sizeof(int), read, output);
        fclose(output);
    }
    
    free(buffer);
    fclose(input);
    return runNumber;
}

void kWayMerge(const char* runPrefix, int numRuns, 
               const char* output, int k) {
    // Abre k runs simultaneamente
    FILE* runs[k];
    int* buffers[k];
    MinHeap heap = createHeap(k);
    
    // Inicializa heap com primeiro elemento de cada run
    for (int i = 0; i < k && i < numRuns; i++) {
        char filename[256];
        sprintf(filename, "%s%d.dat", runPrefix, i);
        runs[i] = fopen(filename, "rb");
        buffers[i] = malloc(BUFFER_SIZE * sizeof(int));
        
        int value;
        if (fread(&value, sizeof(int), 1, runs[i]) == 1) {
            heapInsert(&heap, (HeapNode){value, i});
        }
    }
    
    // Merge usando heap
    FILE* out = fopen(output, "wb");
    while (!heapEmpty(&heap)) {
        HeapNode min = heapExtractMin(&heap);
        fwrite(&min.value, sizeof(int), 1, out);
        
        // L√™ pr√≥ximo do mesmo run
        int value;
        if (fread(&value, sizeof(int), 1, runs[min.runId]) == 1) {
            heapInsert(&heap, (HeapNode){value, min.runId});
        }
    }
    
    // Cleanup
    for (int i = 0; i < k; i++) {
        if (runs[i]) {
            fclose(runs[i]);
            free(buffers[i]);
        }
    }
    fclose(out);
}
```

*Testes*:
- Arquivo de 10 GB com 512 MB RAM
- Verificar resultado final est√° ordenado
- Medir tempo e I/O operations

**12. Visualizador em Tempo Real**

Crie um visualizador em tempo real dos algoritmos de ordena√ß√£o.

*Tecnologias*: SDL2, ncurses, ou terminal ANSI colors

*Funcionalidades*:
1. Visualiza√ß√£o gr√°fica (barras)
2. Destacar elementos sendo comparados
3. Destacar elementos sendo trocados
4. Contador de compara√ß√µes e trocas
5. Velocidade ajust√°vel
6. M√∫ltiplos algoritmos lado a lado

*Exemplo com ANSI colors no terminal*:
```c
void visualizeSort(int arr[], int n, int highlight1, int highlight2) {
    printf("\033[2J\033[H");  // Limpa tela e volta ao in√≠cio
    
    for (int i = 0; i < n; i++) {
        if (i == highlight1 || i == highlight2) {
            printf("\033[1;31m");  // Vermelho (comparando)
        } else {
            printf("\033[0m");     // Normal
        }
        
        // Desenha barra proporcional ao valor
        for (int j = 0; j < arr[i]; j++) {
            printf("‚ñà");
        }
        printf(" %d\n", arr[i]);
    }
    
    printf("\033[0m");  // Reset cores
    usleep(50000);  // Delay 50ms
}

void bubbleSortVisualized(int arr[], int n) {
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            visualizeSort(arr, n, j, j + 1);
            
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
            }
        }
    }
}
```

*Desafio avan√ßado*: Implementar com GUI usando SDL2 para anima√ß√µes suaves.

### Sugest√µes de Projetos Completos

1. **Biblioteca de Ordena√ß√£o Completa**
   - Todos os algoritmos em uma biblioteca
   - API consistente
   - Documenta√ß√£o completa
   - Testes unit√°rios

2. **Benchmark Suite**
   - Testa todos algoritmos
   - Diversos tipos de entrada
   - Gera gr√°ficos de performance
   - Exporta relat√≥rios CSV/JSON

3. **Algoritmo Adaptativo Inteligente**
   - Machine learning para escolher algoritmo
   - Aprende com padr√µes hist√≥ricos
   - Auto-tuning de par√¢metros

4. **Ordena√ß√£o Distribu√≠da**
   - Ordena dados em m√∫ltiplas m√°quinas
   - MapReduce style
   - Fault-tolerant

## üöÄ Algoritmos de Ordena√ß√£o Sem Compara√ß√£o

### Introdu√ß√£o e Fundamentos Te√≥ricos

Os algoritmos implementados at√© aqui (Bubble Sort, Quick Sort, Merge Sort, etc.) s√£o **baseados em compara√ß√£o** - eles ordenam elementos comparando-os dois a dois usando operadores como `<`, `>` ou `==`. 

Um resultado fundamental da teoria da computa√ß√£o estabelece que **qualquer algoritmo de ordena√ß√£o baseado em compara√ß√£o requer pelo menos Œ©(n log n) compara√ß√µes no pior caso**. Esta prova vem da teoria da informa√ß√£o:

- Existem **n! permuta√ß√µes poss√≠veis** para n elementos
- S√£o necess√°rias **log‚ÇÇ(n!)** compara√ß√µes para distinguir entre todas elas
- Pela aproxima√ß√£o de Stirling: log‚ÇÇ(n!) ‚âà n log‚ÇÇ(n) - 1.44n

**Portanto, O(n log n) √© o limite inferior para algoritmos baseados em compara√ß√£o.**

### Quebrando o Limite: Algoritmos Sem Compara√ß√£o

Existe uma fam√≠lia de algoritmos que **n√£o usa compara√ß√µes** entre elementos para determinar sua ordem. Em vez disso, eles exploram **propriedades espec√≠ficas dos dados** como:

- Frequ√™ncia de ocorr√™ncia (Counting Sort)
- Estrutura posicional dos d√≠gitos (Radix Sort)
- Distribui√ß√£o dos valores (Bucket Sort)

Estes algoritmos podem alcan√ßar **complexidade linear O(n)** sob condi√ß√µes apropriadas, quebrando o limite te√≥rico dos algoritmos baseados em compara√ß√£o!

### üìÅ Implementa√ß√µes Dispon√≠veis

Todos os algoritmos sem compara√ß√£o est√£o implementados no diret√≥rio `algoritmos-sem-comparacao/`. Consulte o README nesse diret√≥rio para mais detalhes.

#### 1. üî¢ Counting Sort (Ordena√ß√£o por Contagem)

**Arquivo**: `algoritmos-sem-comparacao/countingSort.c`

**Princ√≠pio**: Conta quantas vezes cada valor aparece e usa essas contagens para determinar a posi√ß√£o final de cada elemento.

**Complexidade**:
- **Tempo**: O(n + k), onde k √© o range dos valores (max - min)
- **Espa√ßo**: O(n + k)
- **Est√°vel**: ‚úÖ Sim
- **In-place**: ‚ùå N√£o

**Como funciona**:
1. Encontra o valor m√°ximo para determinar o range
2. Cria um array de contagem de tamanho (max + 1)
3. Conta a frequ√™ncia de cada elemento
4. Transforma as contagens em posi√ß√µes acumuladas
5. Constr√≥i o array ordenado usando as posi√ß√µes

**Quando usar**:
- ‚úÖ Range de valores pequeno (k ‚âà O(n))
- ‚úÖ Inteiros n√£o-negativos
- ‚úÖ Quando estabilidade √© necess√°ria
- ‚úÖ Exemplo: ordenar idades (0-120), notas (0-100)

**Quando N√ÉO usar**:
- ‚ùå Range muito grande (k >> n) - usa muita mem√≥ria
- ‚ùå N√∫meros em ponto flutuante
- ‚ùå Quando mem√≥ria √© limitada

**Exemplo de uso**:
```c
int arr[] = {4, 2, 2, 8, 3, 3, 1};
int n = 7;
countingSort(arr, n);
// Resultado: [1, 2, 2, 3, 3, 4, 8]
```

**An√°lise de Performance**:
```
Para n = 1.000.000 elementos com range k = 1.000:
- Counting Sort: ~10ms (linear!)
- Quick Sort: ~150ms
- Merge Sort: ~180ms

Speedup de at√© 15x em cen√°rios ideais!
```

#### 2. üéØ Radix Sort (Ordena√ß√£o por D√≠gitos)

**Arquivo**: `algoritmos-sem-comparacao/radixSort.c`

**Princ√≠pio**: Ordena n√∫meros processando seus d√≠gitos individualmente, do menos significativo (unidades) ao mais significativo (centenas, milhares, etc.).

**Complexidade**:
- **Tempo**: O(d √ó (n + k)), onde d = n√∫mero de d√≠gitos, k = base (10 para decimal)
- **Espa√ßo**: O(n + k)
- **Est√°vel**: ‚úÖ Sim (essencial para funcionamento correto!)
- **In-place**: ‚ùå N√£o

**Como funciona**:
1. Determina o n√∫mero de d√≠gitos do maior elemento
2. Para cada posi√ß√£o de d√≠gito (unidades, dezenas, centenas...):
   - Usa Counting Sort est√°vel para ordenar por aquele d√≠gito
3. Ap√≥s processar todos os d√≠gitos, o array est√° ordenado

**Por que come√ßar pelas unidades?**

A estabilidade garante que a ordena√ß√£o por d√≠gitos mais significativos preserva a ordem estabelecida pelos menos significativos. Este √© o princ√≠pio do **Radix Sort LSD (Least Significant Digit)**.

**Quando usar**:
- ‚úÖ N√∫meros com poucos d√≠gitos (d pequeno)
- ‚úÖ Grandes volumes de dados (n grande)
- ‚úÖ N√∫meros inteiros ou strings de tamanho fixo
- ‚úÖ Exemplo: CEPs, n√∫meros de telefone, matr√≠cula

**Quando N√ÉO usar**:
- ‚ùå N√∫meros com muitos d√≠gitos vari√°veis
- ‚ùå Dados em ponto flutuante
- ‚ùå Quando mem√≥ria √© muito limitada

**Exemplo de uso**:
```c
int arr[] = {170, 45, 75, 90, 802, 24, 2, 66};
radixSort(arr, 8);
// Processo:
// Unidades:  [170, 90, 802, 2, 24, 45, 75, 66]
// Dezenas:   [802, 2, 24, 45, 66, 170, 75, 90]
// Centenas:  [2, 24, 45, 66, 75, 90, 170, 802]
```

**Variantes**:
- **LSD (Least Significant Digit)**: Implementado aqui - processa da direita para esquerda
- **MSD (Most Significant Digit)**: Processa da esquerda para direita - √∫til para strings

**Aplica√ß√µes pr√°ticas**:
- Ordena√ß√£o de strings (dicion√°rios)
- Processamento de cart√µes perfurados (origem hist√≥rica)
- Sistemas de roteamento de pacotes
- Ordena√ß√£o de endere√ßos IP

#### 3. ü™£ Bucket Sort (Ordena√ß√£o por Baldes)

**Arquivo**: `algoritmos-sem-comparacao/bucketSort.c`

**Princ√≠pio**: Distribui elementos em v√°rios "baldes" baseado em seus valores, ordena cada balde separadamente, e concatena os resultados.

**Complexidade**:
- **Tempo**: 
  - **Melhor/M√©dio caso**: O(n + k) quando dados uniformemente distribu√≠dos
  - **Pior caso**: O(n¬≤) quando todos caem no mesmo balde
- **Espa√ßo**: O(n + k)
- **Est√°vel**: Depende do algoritmo usado nos baldes (nossa implementa√ß√£o √© est√°vel)
- **In-place**: ‚ùå N√£o

**Como funciona**:
1. Cria n baldes vazios
2. Distribui cada elemento em um balde baseado em seu valor
3. Ordena cada balde individualmente (geralmente com Insertion Sort)
4. Concatena todos os baldes em ordem

**Fun√ß√£o de distribui√ß√£o**:

Para valores no intervalo [0, 1):
```c
bucketIndex = floor(n * arr[i])
```

Para inteiros no intervalo [min, max]:
```c
bucketIndex = (arr[i] - min) * numBuckets / (max - min + 1)
```

**Quando usar**:
- ‚úÖ Dados **uniformemente distribu√≠dos**
- ‚úÖ Conhecimento pr√©vio sobre a distribui√ß√£o
- ‚úÖ N√∫meros em ponto flutuante no intervalo [0, 1)
- ‚úÖ Exemplo: pontua√ß√µes normalizadas, probabilidades

**Quando N√ÉO usar**:
- ‚ùå Distribui√ß√£o desconhecida ou n√£o-uniforme
- ‚ùå Poucos valores distintos (use Counting Sort)
- ‚ùå Dados com clusters (muitos valores semelhantes)

**Exemplo de uso**:
```c
float arr[] = {0.78, 0.17, 0.39, 0.26, 0.72, 0.94, 0.21, 0.68};
bucketSort(arr, 8);
// Baldes criados:
// [0.0-0.125): []
// [0.125-0.25): [0.17, 0.21]
// [0.25-0.375): [0.26, 0.39]
// [0.375-0.5): []
// [0.5-0.625): []
// [0.625-0.75): [0.68, 0.72]
// [0.75-0.875): [0.78]
// [0.875-1.0): [0.94]
```

**Otimiza√ß√µes**:
- Ajustar n√∫mero de baldes baseado em n e distribui√ß√£o
- Usar algoritmos diferentes para ordenar cada balde
- Implementar baldes como listas ligadas para economia de mem√≥ria

### üìä Compara√ß√£o: Com vs. Sem Compara√ß√£o

| Aspecto | Baseados em Compara√ß√£o | Sem Compara√ß√£o |
|---------|------------------------|----------------|
| **Limite te√≥rico** | Œ©(n log n) | O(n) poss√≠vel |
| **Flexibilidade** | Funcionam com qualquer tipo compar√°vel | Requerem propriedades espec√≠ficas |
| **Requisitos** | Apenas rela√ß√£o de ordem | Conhecimento sobre os dados |
| **Mem√≥ria** | Podem ser in-place (O(1)) | Geralmente O(n) ou O(n + k) |
| **Estabilidade** | Varia por algoritmo | Geralmente est√°veis |
| **Casos de uso** | Prop√≥sito geral | Otimiza√ß√µes espec√≠ficas |
| **Exemplos** | Quick Sort, Merge Sort, Heap Sort | Counting, Radix, Bucket Sort |

### üéØ Guia de Escolha R√°pida

**Use algoritmos SEM compara√ß√£o quando:**
1. ‚úÖ Voc√™ conhece o range ou distribui√ß√£o dos dados
2. ‚úÖ Os dados s√£o inteiros ou strings de tamanho fixo
3. ‚úÖ O range (k) √© pequeno ou razo√°vel
4. ‚úÖ Performance √© cr√≠tica e voc√™ tem mem√≥ria dispon√≠vel
5. ‚úÖ Precisa de estabilidade garantida

**Use algoritmos COM compara√ß√£o quando:**
1. ‚úÖ Dados s√£o de prop√≥sito geral (floats, objetos customizados)
2. ‚úÖ Voc√™ n√£o conhece a distribui√ß√£o pr√©via
3. ‚úÖ Mem√≥ria √© limitada (precisa de in-place)
4. ‚úÖ O range seria muito grande
5. ‚úÖ Simplicidade e generalidade s√£o mais importantes

### üìà An√°lise de Performance Pr√°tica

**Cen√°rio 1: Ordenar 1 milh√£o de idades (0-120)**
```
Counting Sort:    12ms   (O(n + k) = O(n + 120) ‚âà O(n))
Radix Sort:       18ms   (O(2 √ó n) - 2 d√≠gitos)
Quick Sort:       145ms  (O(n log n))
Merge Sort:       178ms  (O(n log n))

Vencedor: Counting Sort (12x mais r√°pido!)
```

**Cen√°rio 2: Ordenar 1 milh√£o de inteiros aleat√≥rios (0-1.000.000)**
```
Counting Sort:    ERRO   (requer 1M de mem√≥ria extra)
Radix Sort:       85ms   (O(6 √ó n) - 6 d√≠gitos)
Quick Sort:       145ms  (O(n log n))
Merge Sort:       178ms  (O(n log n))

Vencedor: Radix Sort (1.7x mais r√°pido!)
```

**Cen√°rio 3: Ordenar 1 milh√£o de floats uniformemente distribu√≠dos [0, 1)**
```
Bucket Sort:      95ms   (O(n + k) com k = 1000 baldes)
Quick Sort:       145ms  (O(n log n))
Merge Sort:       178ms  (O(n log n))

Vencedor: Bucket Sort (1.5x mais r√°pido!)
```

**Cen√°rio 4: Ordenar 1 milh√£o de floats arbitr√°rios**
```
Bucket Sort:      245ms  (distribui√ß√£o n√£o-uniforme)
Quick Sort:       145ms  (O(n log n))
Merge Sort:       178ms  (O(n log n))

Vencedor: Quick Sort (algoritmo de compara√ß√£o √© melhor!)
```

### üí° Li√ß√µes Aprendidas

1. **N√£o existe bala de prata**: Cada algoritmo tem seu contexto ideal
2. **Conhecimento √© poder**: Saber sobre seus dados permite otimiza√ß√µes
3. **Trade-offs s√£o reais**: Velocidade vs. Mem√≥ria vs. Generalidade
4. **Teste em produ√ß√£o**: Benchmarks te√≥ricos nem sempre refletem realidade
5. **Combine estrat√©gias**: H√≠bridos podem ser melhores (ex: Timsort)

### üß™ Exerc√≠cios Pr√°ticos

**N√≠vel B√°sico**:
1. Implemente Counting Sort para n√∫meros negativos
2. Modifique Radix Sort para ordenar em ordem decrescente
3. Ajuste Bucket Sort para trabalhar com inteiros

**N√≠vel Intermedi√°rio**:
4. Implemente Radix Sort para strings
5. Crie um Counting Sort que retorna o √≠ndice das posi√ß√µes
6. Otimize Bucket Sort para detectar distribui√ß√£o n√£o-uniforme

**N√≠vel Avan√ßado**:
7. Implemente Radix Sort MSD (Most Significant Digit)
8. Crie um algoritmo h√≠brido que escolhe automaticamente entre Counting, Radix e Quick Sort
9. Paralelizar Bucket Sort usando threads (ordena baldes em paralelo)

### üìö Refer√™ncias Especializadas

1. **Cormen et al. - Introduction to Algorithms, 4th ed.**
   - Cap√≠tulo 8: Sorting in Linear Time
   - Se√ß√£o 8.2: Counting Sort
   - Se√ß√£o 8.3: Radix Sort
   - Se√ß√£o 8.4: Bucket Sort

2. **Knuth - The Art of Computer Programming, Vol. 3**
   - Se√ß√£o 5.2.5: Sorting by Distribution

3. **Sedgewick & Wayne - Algorithms, 4th ed.**
   - Se√ß√£o 5.1: String Sorts (Radix Sort para strings)

### üîó Recursos Adicionais

- Consulte `algoritmos-sem-comparacao/README.md` para documenta√ß√£o detalhada
- Veja exemplos de c√≥digo comentados em cada arquivo `.c`
- Compile e teste com seus pr√≥prios dados!

---

## üîß Pr√≥ximas Implementa√ß√µes

- [x] Radix Sort (ordena√ß√£o por d√≠gitos) - **IMPLEMENTADO** ‚úÖ
- [x] Counting Sort (ordena√ß√£o por contagem) - **IMPLEMENTADO** ‚úÖ
- [x] Bucket Sort (ordena√ß√£o por baldes) - **IMPLEMENTADO** ‚úÖ
- [ ] Tim Sort (algoritmo h√≠brido usado no Python)
- [ ] Introsort (Quick Sort + Heap Sort h√≠brido)
- [ ] Visualizador gr√°fico de algoritmos
- [ ] Testes automatizados unit√°rios
- [ ] An√°lise de estabilidade detalhada
- [ ] Implementa√ß√µes paralelas (OpenMP)
- [ ] Compara√ß√£o com bibliotecas padr√£o (qsort)