# Algoritmos de Pesquisa em C

## üìã Vis√£o Geral

Os algoritmos de pesquisa s√£o fundamentais em ci√™ncia da computa√ß√£o e constituem uma das opera√ß√µes mais executadas em sistemas computacionais modernos. Pesquisar, no contexto computacional, significa **localizar um elemento espec√≠fico** dentro de uma estrutura de dados, verificando sua exist√™ncia e, caso presente, determinando sua posi√ß√£o ou recuperando informa√ß√µes associadas.

### Import√¢ncia e Aplica√ß√µes

A opera√ß√£o de busca est√° presente em praticamente todos os sistemas computacionais:

- **Sistemas de Gerenciamento de Banco de Dados (SGBD)**: Consultas SQL dependem de algoritmos de busca eficientes para localizar registros em tabelas com milh√µes de entradas
- **Motores de Busca Web**: Google, Bing e outros utilizam algoritmos sofisticados de busca em estruturas de dados distribu√≠das
- **Sistemas Operacionais**: Localiza√ß√£o de arquivos, processos e gerenciamento de mem√≥ria
- **Compiladores e Interpretadores**: Busca de s√≠mbolos em tabelas de s√≠mbolos
- **Intelig√™ncia Artificial**: Algoritmos de busca em √°rvores de decis√£o e espa√ßos de estados
- **Bioinform√°tica**: Busca de padr√µes em sequ√™ncias de DNA e prote√≠nas
- **Sistemas de Recomenda√ß√£o**: Localiza√ß√£o de itens similares em grandes cat√°logos

### Fundamenta√ß√£o Te√≥rica

Do ponto de vista da teoria da computa√ß√£o, os algoritmos de busca representam um problema fundamental que pode ser analisado sob diferentes modelos computacionais. No **modelo de compara√ß√£o**, onde elementos s√£o acessados apenas atrav√©s de opera√ß√µes de compara√ß√£o, podemos estabelecer limites te√≥ricos inferiores e superiores para a efici√™ncia desses algoritmos.

Este m√≥dulo apresenta os principais algoritmos de pesquisa implementados em C, desde a busca linear b√°sica at√© t√©cnicas mais avan√ßadas como busca bin√°ria e interpolada, com an√°lise detalhada de suas complexidades, fundamentos matem√°ticos e aplica√ß√µes pr√°ticas.

## üîç Algoritmos Implementados

### Busca Linear (Sequential Search)

#### Descri√ß√£o Acad√™mica
A busca linear, tamb√©m conhecida como busca sequencial, √© o algoritmo de busca mais simples e fundamental. Proposto inicialmente nos prim√≥rdios da computa√ß√£o, este algoritmo percorre sequencialmente cada elemento da estrutura de dados, comparando-o com o valor procurado at√© encontr√°-lo ou esgotar todas as possibilidades.

#### Caracter√≠sticas T√©cnicas
- **Arquivo**: `buscaLinear.c`
- **Complexidade Temporal**: 
  - Melhor caso: O(1) - elemento na primeira posi√ß√£o
  - Caso m√©dio: O(n/2) ‚âà O(n) - elemento no meio
  - Pior caso: O(n) - elemento na √∫ltima posi√ß√£o ou ausente
- **Complexidade Espacial**: O(1) - apenas vari√°veis auxiliares
- **Aplica√ß√£o**: Dados n√£o ordenados, arrays pequenos
- **Requisitos**: Nenhum pr√©-requisito nos dados

#### Fundamenta√ß√£o Te√≥rica
No modelo de compara√ß√£o, a busca linear √© **√≥tima para dados n√£o ordenados**, pois qualquer algoritmo que busque em dados n√£o ordenados deve, no pior caso, examinar todos os elementos. Isto √© demonstrado atrav√©s de **argumentos de advers√°rio** na teoria da complexidade.

#### Quando Utilizar
- Conjuntos de dados pequenos (n < 100)
- Dados n√£o ordenados onde ordenar seria mais custoso
- Busca √∫nica ou poucas opera√ß√µes de busca
- Quando a simplicidade e facilidade de implementa√ß√£o s√£o priorit√°rias
- Estruturas de dados sem acesso aleat√≥rio (listas encadeadas)

---

### Busca Linear em Matriz

#### Descri√ß√£o Acad√™mica
Extens√£o da busca linear para estruturas bidimensionais. O algoritmo percorre a matriz linha por linha (ou coluna por coluna), aplicando busca sequencial em cada dimens√£o.

#### Caracter√≠sticas T√©cnicas
- **Arquivo**: `buscaLinearMatriz.c`
- **Complexidade Temporal**: O(m √ó n) onde m = linhas, n = colunas
- **Complexidade Espacial**: O(1)
- **Aplica√ß√£o**: Matrizes n√£o ordenadas, busca em dados tabulares
- **Caracter√≠sticas**: Busca elemento por elemento, ordem lexicogr√°fica

#### An√°lise de Performance
Para uma matriz de dimens√µes m √ó n:
- Total de compara√ß√µes no pior caso: m √ó n
- N√∫mero m√©dio de compara√ß√µes: (m √ó n)/2
- Se m = n, temos O(n¬≤) compara√ß√µes

#### Otimiza√ß√µes Poss√≠veis
1. **Interrup√ß√£o antecipada**: Retornar imediatamente ao encontrar
2. **Busca em espiral**: Come√ßar pelo centro (√∫til se elementos frequentes est√£o centralizados)
3. **Paraleliza√ß√£o**: Dividir linhas entre threads diferentes

---

### Busca Bin√°ria (Binary Search)

#### Descri√ß√£o Acad√™mica
A busca bin√°ria √© um algoritmo de **dividir para conquistar** (divide-and-conquer) que opera sobre dados ordenados. Proposta por John Mauchly em 1946 e publicada formalmente em 1962, representa um dos exemplos mais elegantes de efici√™ncia algor√≠tmica atrav√©s da redu√ß√£o sistem√°tica do espa√ßo de busca.

#### Fundamento Matem√°tico
O algoritmo baseia-se no princ√≠pio da **dicotomia**: a cada itera√ß√£o, o espa√ßo de busca √© dividido pela metade, eliminando metade dos elementos candidatos. Esta estrat√©gia resulta em complexidade logar√≠tmica.

**Recorr√™ncia**:
```
T(n) = T(n/2) + O(1)
T(n) = O(log‚ÇÇ n)
```

Pelo **Teorema Mestre**: T(n) ‚àà Œò(log n)

#### Caracter√≠sticas T√©cnicas
- **Arquivo**: `buscaBinaria.c`
- **Complexidade Temporal**: 
  - Melhor caso: O(1) - elemento no meio
  - Caso m√©dio: O(log n)
  - Pior caso: O(log n)
- **Complexidade Espacial**: 
  - Iterativa: O(1)
  - Recursiva: O(log n) - pilha de recurs√£o
- **Requisitos Essenciais**: 
  - Dados **obrigatoriamente ordenados**
  - Acesso aleat√≥rio em O(1)
  - Operador de compara√ß√£o definido

#### Prova de Corre√ß√£o
A corre√ß√£o da busca bin√°ria pode ser demonstrada por **invariante de loop**:
- **Invariante**: Se o elemento procurado existe, ele est√° no intervalo [esquerda, direita]
- **Inicializa√ß√£o**: Verdadeiro no in√≠cio (elemento pode estar em qualquer posi√ß√£o)
- **Manuten√ß√£o**: Ap√≥s cada itera√ß√£o, o invariante √© preservado
- **T√©rmino**: Quando esquerda > direita, o elemento n√£o existe; caso contr√°rio, foi encontrado

#### An√°lise de Complexidade de Informa√ß√£o
Do ponto de vista da **teoria da informa√ß√£o**, buscar em n elementos ordenados requer pelo menos ‚åàlog‚ÇÇ(n+1)‚åâ compara√ß√µes no pior caso. A busca bin√°ria atinge este limite inferior, sendo **assintoticamente √≥tima** para o modelo de compara√ß√£o.

#### Quando Utilizar
- Dados ordenados (ou quando vale a pena ordenar primeiro)
- M√∫ltiplas opera√ß√µes de busca no mesmo conjunto
- Conjuntos grandes (n > 1000)
- Mem√≥ria limitada (complexidade espacial constante na vers√£o iterativa)
- Necessidade de performance previs√≠vel e consistente

---

### Busca Bin√°ria em Matriz

#### Descri√ß√£o Acad√™mica
Adapta√ß√£o do algoritmo de busca bin√°ria para matrizes com propriedades especiais de ordena√ß√£o. Em matrizes onde cada linha est√° ordenada e a primeira coluna tamb√©m est√° ordenada, pode-se aplicar estrat√©gias mais eficientes que a busca linear.

#### Caracter√≠sticas T√©cnicas
- **Arquivo**: `buscaBinariaMatriz.c`
- **Complexidade Temporal**: O(m + n) usando busca escalonada ou O(log(m√ón)) tratando como vetor
- **Complexidade Espacial**: O(1)
- **Aplica√ß√£o**: Matrizes com ordena√ß√£o por linha e coluna
- **Caracter√≠sticas**: Aproveita propriedades de ordena√ß√£o 2D

#### Estrat√©gias de Implementa√ß√£o

**1. Tratamento como Vetor Unidimensional**:
- Converte √≠ndices 2D em 1D: `√≠ndice_1D = linha * n_colunas + coluna`
- Complexidade: O(log(m √ó n))

**2. Busca Escalonada (Staircase Search)**:
- Inicia no canto superior direito (ou inferior esquerdo)
- Move-se estrategicamente eliminando linhas ou colunas
- Complexidade: O(m + n)

**3. Busca Bin√°ria Dupla**:
- Aplica busca bin√°ria nas linhas, depois nas colunas
- Complexidade: O(log m + log n) = O(log(m √ó n))

---

### Busca Interpolada (Interpolation Search)

#### Descri√ß√£o Acad√™mica
Proposta por W. W. Peterson em 1957, a busca interpolada √© uma melhoria da busca bin√°ria para dados **uniformemente distribu√≠dos**. Em vez de sempre dividir o espa√ßo ao meio, o algoritmo estima a posi√ß√£o prov√°vel do elemento usando **interpola√ß√£o linear**, similar √† forma como humanos buscam em uma lista telef√¥nica.

#### Fundamento Matem√°tico
A posi√ß√£o estimada √© calculada por:

```
pos = esquerda + [(valor - array[esquerda]) √ó (direita - esquerda)] / (array[direita] - array[esquerda])
```

Esta f√≥rmula realiza uma **interpola√ß√£o linear** assumindo distribui√ß√£o uniforme dos valores.

#### An√°lise de Complexidade
- **Melhor caso**: O(1) - acerto na primeira tentativa
- **Caso m√©dio (dados uniformes)**: O(log log n) - demonstrado por Perl, Itai e Avni (1978)
- **Pior caso (dados n√£o uniformes)**: O(n) - degenera para busca linear

#### Caracter√≠sticas T√©cnicas
- **Arquivo**: `buscaInterpolada.c`
- **Complexidade Temporal M√©dia**: O(log log n) para dados uniformemente distribu√≠dos
- **Complexidade Espacial**: O(1)
- **Requisitos**: 
  - Dados ordenados
  - Distribui√ß√£o aproximadamente uniforme
  - Valores num√©ricos (para interpola√ß√£o)
- **Aplica√ß√£o**: Grandes conjuntos de dados num√©ricos com distribui√ß√£o uniforme

#### An√°lise Comparativa com Busca Bin√°ria

Para n = 1.000.000:
- Busca Bin√°ria: log‚ÇÇ(1.000.000) ‚âà 20 compara√ß√µes
- Busca Interpolada: log‚ÇÇ(log‚ÇÇ(1.000.000)) ‚âà 4,3 compara√ß√µes (caso ideal)

**Ganho te√≥rico**: ~4-5√ó mais r√°pida em condi√ß√µes ideais

#### Quando Utilizar
- Conjuntos muito grandes (n > 100.000)
- Dados num√©ricos com distribui√ß√£o aproximadamente uniforme
- Performance cr√≠tica e dados adequados ao algoritmo
- Situa√ß√µes onde o custo adicional de interpola√ß√£o √© justific√°vel

#### Cuidados e Limita√ß√µes
- **Sens√≠vel √† distribui√ß√£o**: Performance degrada drasticamente com dados n√£o uniformes
- **Overflow**: Cuidado com c√°lculos que podem exceder limites de inteiros
- **Dados n√£o num√©ricos**: Dif√≠cil aplica√ß√£o para strings ou tipos complexos

## üìä Compara√ß√£o de Performance

| Algoritmo | Melhor Caso | Caso M√©dio | Pior Caso | Espa√ßo | Pr√©-requisito |
|-----------|-------------|------------|-----------|---------|---------------|
| Linear | O(1) | O(n) | O(n) | O(1) | Nenhum |
| Linear Matriz | O(1) | O(m√ón) | O(m√ón) | O(1) | Nenhum |
| Bin√°ria | O(1) | O(log n) | O(log n) | O(1) iterativa<br>O(log n) recursiva | Dados ordenados |
| Bin√°ria Matriz | O(1) | O(log(m√ón)) | O(log(m√ón)) | O(1) | Matriz ordenada |
| Interpolada | O(1) | O(log log n) | O(n) | O(1) | Ordenado + uniforme |

### An√°lise Comparativa Detalhada

#### N√∫mero de Compara√ß√µes para Diferentes Tamanhos

| Tamanho (n) | Linear | Bin√°ria | Interpolada (ideal) |
|-------------|--------|---------|---------------------|
| 100 | 50 | 7 | 3 |
| 1.000 | 500 | 10 | 3,3 |
| 10.000 | 5.000 | 14 | 3,8 |
| 100.000 | 50.000 | 17 | 4,1 |
| 1.000.000 | 500.000 | 20 | 4,3 |
| 10.000.000 | 5.000.000 | 24 | 4,6 |

**Observa√ß√£o**: Os valores s√£o aproximados e representam o caso m√©dio.

---

## ‚ö° An√°lise de Complexidade Computacional Detalhada

### O que √© Complexidade Computacional?

A **complexidade computacional** √© uma medida formal da efici√™ncia de um algoritmo, expressa em termos de recursos necess√°rios (tempo e espa√ßo) em fun√ß√£o do tamanho da entrada. Esta an√°lise √© fundamental para:

1. **Prever o comportamento** do algoritmo com entradas grandes
2. **Comparar algoritmos** objetivamente
3. **Escolher a solu√ß√£o mais adequada** para cada problema
4. **Identificar gargalos** de performance
5. **Estabelecer limites te√≥ricos** do que √© computacionalmente poss√≠vel

### Nota√ß√£o Assint√≥tica - Big O, Œ© e Œò

#### Big O - Limite Superior (O)
Define o **pior caso** ou limite superior do crescimento. Um algoritmo √© O(f(n)) se existe uma constante c e n‚ÇÄ tal que:
```
T(n) ‚â§ c √ó f(n) para todo n ‚â• n‚ÇÄ
```

**Exemplo**: Se um algoritmo executa no m√°ximo 5n + 10 opera√ß√µes, dizemos que √© O(n).

#### Big Omega - Limite Inferior (Œ©)
Define o **melhor caso** ou limite inferior. Um algoritmo √© Œ©(f(n)) se existe uma constante c e n‚ÇÄ tal que:
```
T(n) ‚â• c √ó f(n) para todo n ‚â• n‚ÇÄ
```

**Exemplo**: A busca em array n√£o ordenado √© Œ©(1) no melhor caso e Œ©(n) no pior caso.

#### Big Theta - Limite Justo (Œò)
Define quando o algoritmo tem **mesma ordem de crescimento** no melhor e pior caso. Um algoritmo √© Œò(f(n)) se √© tanto O(f(n)) quanto Œ©(f(n)).

**Exemplo**: Percorrer um array sempre executa n opera√ß√µes, ent√£o √© Œò(n).

### Classes de Complexidade dos Algoritmos de Busca

#### 1. O(1) - Constante
- **Caracter√≠stica**: Tempo independe do tamanho da entrada
- **Busca**: Acesso direto via √≠ndice, busca em hash table (caso m√©dio)
- **Exemplo em busca**: Verificar se o elemento do meio √© o procurado
```c
return array[n/2] == valor; // Uma compara√ß√£o, O(1)
```

#### 2. O(log n) - Logar√≠tmica
- **Caracter√≠stica**: Crescimento muito lento, dobrar n adiciona apenas uma opera√ß√£o
- **Busca**: Busca bin√°ria em dados ordenados
- **An√°lise**: A cada passo, elimina metade dos candidatos
```
Itera√ß√µes para encontrar em n elementos:
log‚ÇÇ(16) = 4 itera√ß√µes
log‚ÇÇ(1024) = 10 itera√ß√µes
log‚ÇÇ(1.048.576) = 20 itera√ß√µes
```

**Prova de Complexidade da Busca Bin√°ria**:
```
T(n) = T(n/2) + c  (onde c √© tempo da compara√ß√£o)
T(n) = T(n/4) + c + c
T(n) = T(n/8) + c + c + c
...
T(n) = T(1) + c √ó log‚ÇÇ(n)
T(n) = O(log n)
```

#### 3. O(log log n) - Duplamente Logar√≠tmica
- **Caracter√≠stica**: Crescimento extremamente lento
- **Busca**: Busca interpolada em dados uniformemente distribu√≠dos
- **Compara√ß√£o**:
```
n = 1.000.000
log‚ÇÇ(n) = 20
log‚ÇÇ(log‚ÇÇ(n)) ‚âà 4,3
```

**Por que log log n?**
Na busca interpolada com dados uniformes, a cada passo n√£o eliminamos metade, mas uma fra√ß√£o muito maior, resultando em:
```
T(n) = T(‚àön) + O(1)
T(n) = O(log log n)  [provado por Perl, Itai e Avni, 1978]
```

#### 4. O(n) - Linear
- **Caracter√≠stica**: Tempo proporcional ao tamanho
- **Busca**: Busca linear/sequencial
- **An√°lise**: No pior caso, verifica todos os elementos
```c
for (int i = 0; i < n; i++) {
    if (array[i] == valor) return i;  // n compara√ß√µes no pior caso
}
```

**Caso m√©dio da busca linear**:
- Se elemento est√° presente: (n+1)/2 compara√ß√µes em m√©dia
- Se elemento n√£o est√° presente: n compara√ß√µes

#### 5. O(n log n) - Linear√≠tmica
- **Caracter√≠stica**: Quase linear, mas com fator logar√≠tmico
- **Busca**: N√£o diretamente, mas ordenar antes de buscar
- **Trade-off**: Se vamos fazer k buscas:
  - Linear: O(k √ó n)
  - Ordenar + Bin√°ria: O(n log n + k √ó log n)
  - Vantagem da bin√°ria quando: k > (n log n)/(n - log n) ‚âà log n

### An√°lise de Complexidade de Espa√ßo

#### Espa√ßo Auxiliar
Mem√≥ria adicional usada al√©m da entrada:

| Algoritmo | Espa√ßo Auxiliar | Justificativa |
|-----------|-----------------|---------------|
| Busca Linear | O(1) | Apenas vari√°veis de controle |
| Busca Bin√°ria Iterativa | O(1) | Apenas vari√°veis √≠ndice |
| Busca Bin√°ria Recursiva | O(log n) | Pilha de recurs√£o com log n chamadas |
| Busca Interpolada | O(1) | Apenas c√°lculos intermedi√°rios |

**Impacto Pr√°tico**:
Para n = 1.000.000, busca bin√°ria recursiva usa ~20 frames na pilha. Em sistemas embarcados com pilha limitada, vers√£o iterativa √© prefer√≠vel.

### Limites Inferiores Te√≥ricos

#### Teorema do Limite Inferior para Busca por Compara√ß√£o

**Teorema**: Qualquer algoritmo baseado em compara√ß√µes para buscar em n elementos ordenados requer Œ©(log n) compara√ß√µes no pior caso.

**Prova (via √Årvore de Decis√£o)**:
1. Cada compara√ß√£o divide o problema em no m√°ximo 2 subproblemas
2. Precisamos de pelo menos n folhas (uma para cada poss√≠vel posi√ß√£o)
3. Uma √°rvore bin√°ria com n folhas tem altura m√≠nima h = ‚åàlog‚ÇÇ n‚åâ
4. Logo, precisamos de pelo menos log‚ÇÇ n compara√ß√µes

**Conclus√£o**: A busca bin√°ria √© **assintoticamente √≥tima** no modelo de compara√ß√£o.

#### Quebrando o Limite: Busca sem Compara√ß√£o

Alguns algoritmos podem ser mais r√°pidos que O(log n) usando outras opera√ß√µes:
- **Hash Tables**: O(1) esperado, usando fun√ß√µes hash
- **Van Emde Boas Trees**: O(log log U) onde U √© o universo de chaves
- **Busca em arrays de bits**: O(1) usando instru√ß√µes de hardware

### An√°lise Amortizada

Para estruturas din√¢micas que realizam buscas repetidas:

**Exemplo - Array Din√¢mico com Reorganiza√ß√£o**:
- Mover elementos frequentemente acessados para o in√≠cio
- Custo individual de busca: O(n)
- Custo amortizado ap√≥s m buscas com padr√£o: O(1) a O(log n)

### Constantes Ocultas e An√°lise Pr√°tica

A nota√ß√£o Big O esconde constantes que podem ser importantes na pr√°tica:

#### Busca Linear vs Bin√°ria para n pequeno

```c
// Busca Linear: ~3 opera√ß√µes por itera√ß√£o
for (int i = 0; i < n; i++) {           // 1: compara√ß√£o i < n
    if (array[i] == valor) return i;    // 2: acesso + 3: compara√ß√£o
}

// Busca Bin√°ria: ~5 opera√ß√µes por itera√ß√£o
while (esq <= dir) {                    // 1: compara√ß√£o
    int meio = esq + (dir - esq) / 2;  // 2: subtra√ß√£o + 3: divis√£o + 4: adi√ß√£o
    if (array[meio] == valor)           // 5: acesso + 6: compara√ß√£o
        return meio;
    // ...
}
```

**Break-even point**: Para n < 32, busca linear pode ser mais r√°pida devido a:
- Constantes menores
- Melhor uso de cache (acesso sequencial)
- Menos branches (predi√ß√£o de branch mais eficiente)

### Complexidade em Diferentes Modelos de Mem√≥ria

#### Modelo de Acesso Uniforme (RAM)
Assume que todo acesso √† mem√≥ria custa O(1). Usado na an√°lise tradicional.

#### Modelo de Cache-Oblivious
Considera hierarquia de mem√≥ria (cache L1, L2, L3, RAM):
- **Busca Linear**: √ìtimo uso de cache (acesso sequencial)
- **Busca Bin√°ria**: Pior uso de cache (acessos aleat√≥rios)
- **Cache misses**: Bin√°ria pode ter log n cache misses vs poucos na linear

**Resultado Pr√°tico**: Para arrays grandes que n√£o cabem em cache, busca linear pode ser competitiva at√© n ‚âà 10.000 devido a localidade espacial.

### Tabela de Decis√£o Pr√°tica

| Tamanho | Ordenado? | M√∫ltiplas Buscas? | Distribui√ß√£o | Algoritmo Recomendado |
|---------|-----------|-------------------|--------------|----------------------|
| < 32 | N√£o | - | - | Linear |
| < 32 | Sim | - | - | Linear ou Bin√°ria |
| 32-1000 | N√£o | N√£o | - | Linear |
| 32-1000 | N√£o | Sim (>10) | - | Ordenar + Bin√°ria |
| 32-1000 | Sim | - | - | Bin√°ria |
| > 1000 | N√£o | N√£o | - | Linear |
| > 1000 | N√£o | Sim | - | Hash Table ou Ordenar + Bin√°ria |
| > 1000 | Sim | - | Qualquer | Bin√°ria |
| > 100.000 | Sim | - | Uniforme | Interpolada |
| Qualquer | - | Muitas | - | Hash Table (O(1) esperado) |

### Benchmarks Reais (Tempo em microssegundos)

**Hardware**: CPU moderna 3.0 GHz, cache L1 32KB, L2 256KB, L3 8MB

| n | Linear | Bin√°ria | Interpolada | Hash |
|---|--------|---------|-------------|------|
| 100 | 0.3 | 0.4 | 0.5 | 0.1 |
| 1.000 | 3 | 0.5 | 0.6 | 0.1 |
| 10.000 | 30 | 0.7 | 0.7 | 0.1 |
| 100.000 | 300 | 0.9 | 0.8 | 0.15 |
| 1.000.000 | 3.000 | 1.1 | 0.9 | 0.2 |

**Observa√ß√µes**:
- Hash domina para buscas repetidas
- Interpolada s√≥ compensa para n muito grande
- Linear competitiva at√© ~1000 elementos devido a cache

## üõ†Ô∏è Como Executar

### Compila√ß√£o
```bash
gcc -o busca_linear buscaLinear.c
gcc -o busca_binaria buscaBinaria.c
gcc -o busca_interpolada buscaInterpolada.c
```

### Execu√ß√£o
```bash
./busca_linear
./busca_binaria
./busca_interpolada
```

## üìö Conceitos Fundamentais

### Modelo de Computa√ß√£o e An√°lise de Algoritmos

#### Modelo RAM (Random Access Machine)
A an√°lise de algoritmos de busca geralmente assume o modelo RAM, onde:
- Cada opera√ß√£o b√°sica (compara√ß√£o, atribui√ß√£o, aritm√©tica) custa tempo constante O(1)
- Acesso a qualquer posi√ß√£o da mem√≥ria custa O(1)
- Mem√≥ria infinita dispon√≠vel
- Opera√ß√µes executadas sequencialmente

**Limita√ß√µes do Modelo**: Na pr√°tica, hierarquia de cache e lat√™ncia de mem√≥ria podem afetar a performance real.

### Pr√©-requisitos para Busca Bin√°ria

#### 1. Dados Ordenados (Requisito Fundamental)
A busca bin√°ria **requer absolutamente** que os dados estejam ordenados, pois:
- A decis√£o de ir para esquerda ou direita baseia-se na compara√ß√£o
- Se dados n√£o ordenados, a elimina√ß√£o de metade pode descartar o elemento procurado
- **Contra-exemplo**: Array [5, 2, 8, 1, 9], buscar 1
  - Meio = 8, 1 < 8, vai para esquerda [5, 2]
  - Descarta [1, 9] incorretamente!

**Custo de Ordena√ß√£o**:
- Merge Sort ou Quick Sort: O(n log n)
- Vale ordenar se: n√∫mero de buscas k > (n log n) / (n - log n) ‚âà log n

#### 2. Acesso Aleat√≥rio (Random Access)
√â necess√°rio acessar qualquer elemento em O(1):
- **Adequado**: Arrays, vetores
- **Inadequado**: Listas encadeadas simples (acesso O(n))
- **Solu√ß√£o para listas**: Usar estruturas auxiliares ou algoritmos diferentes

#### 3. Elementos Compar√°veis
Deve existir uma rela√ß√£o de ordem total:
- **Reflexiva**: a ‚â§ a
- **Antissim√©trica**: se a ‚â§ b e b ‚â§ a, ent√£o a = b
- **Transitiva**: se a ‚â§ b e b ‚â§ c, ent√£o a ‚â§ c
- **Total**: para quaisquer a, b: a ‚â§ b ou b ‚â§ a

### Invariantes de Loop e Corre√ß√£o de Algoritmos

#### Invariante da Busca Bin√°ria
**Propriedade mantida antes e depois de cada itera√ß√£o**:
```
Se o elemento x existe no array, ent√£o x est√° no intervalo [esquerda, direita]
```

**Prova de Corre√ß√£o por Indu√ß√£o**:

1. **Inicializa√ß√£o** (Base):
   - esquerda = 0, direita = n-1
   - Invariante verdadeiro: elemento pode estar em qualquer posi√ß√£o

2. **Manuten√ß√£o** (Passo Indutivo):
   - Se x == array[meio]: encontrado, algoritmo termina corretamente
   - Se x < array[meio]: x n√£o pode estar em [meio, direita], atualiza direita = meio - 1
   - Se x > array[meio]: x n√£o pode estar em [esquerda, meio], atualiza esquerda = meio + 1
   - Em ambos casos, invariante preservado

3. **T√©rmino**:
   - Loop termina quando esquerda > direita
   - Se elemento existisse, invariante garantiria sua presen√ßa no intervalo
   - Como intervalo est√° vazio, elemento n√£o existe

**Conclus√£o**: Algoritmo est√° correto e sempre termina em O(log n) itera√ß√µes.

### Quando Usar Cada Algoritmo

#### Busca Linear - Situa√ß√µes Ideais

1. **Dados Pequenos** (n < 32-64):
   ```
   Raz√£o: Overhead da busca bin√°ria n√£o compensa
   Exemplo: Menu com 10 op√ß√µes, lista de 20 contatos
   ```

2. **Dados N√£o Ordenados** onde ordenar √© custoso:
   ```
   Se apenas 1 busca: O(n) linear < O(n log n + log n) ordenar+bin√°ria
   Break-even: ~log n buscas
   ```

3. **Busca com Crit√©rio Complexo**:
   ```c
   // Predicate n√£o baseado em ordem simples
   for (int i = 0; i < n; i++) {
       if (satisfaz_condicao_complexa(array[i]))
           return i;
   }
   ```

4. **Estruturas sem Acesso Aleat√≥rio**:
   - Listas encadeadas simples
   - Streams de dados
   - Fitas magn√©ticas (antiquado, mas did√°tico)

5. **Dados com Localidade**:
   - Se elemento geralmente est√° no in√≠cio
   - Move-to-front heuristic pode reduzir para O(1) amortizado

#### Busca Bin√°ria - Situa√ß√µes Ideais

1. **Dados J√° Ordenados**:
   ```
   N√£o h√° custo de ordena√ß√£o, apenas O(log n) por busca
   ```

2. **M√∫ltiplas Buscas** (k buscas):
   ```
   Custo Total Linear: k √ó O(n)
   Custo Total Bin√°ria: O(n log n) + k √ó O(log n)
   Vantagem quando: k > log n
   ```

3. **Conjuntos Grandes** (n > 1000):
   ```
   n = 1.000.000
   Linear: 500.000 compara√ß√µes m√©dias
   Bin√°ria: 20 compara√ß√µes
   Speedup: 25.000√ó
   ```

4. **Mem√≥ria Limitada**:
   - Vers√£o iterativa usa O(1) espa√ßo
   - Ideal para sistemas embarcados

5. **Garantia de Performance**:
   - Pior caso = caso m√©dio = O(log n)
   - Performance previs√≠vel e consistente

#### Busca Interpolada - Situa√ß√µes Ideais

1. **Dados Muito Grandes** (n > 100.000):
   ```
   Vantagem sobre bin√°ria come√ßa a aparecer
   ```

2. **Distribui√ß√£o Uniforme**:
   ```c
   // Exemplos de dados adequados:
   int ids_sequenciais[1000000];  // 1, 2, 3, ..., 1000000
   double timestamps[100000];      // timestamps uniformemente espa√ßados
   ```

3. **Dados Num√©ricos**:
   - Necess√°rio para c√°lculo de interpola√ß√£o
   - Dif√≠cil aplicar em strings

4. **Performance Cr√≠tica** com dados adequados:
   ```
   n = 10.000.000
   Bin√°ria: 24 compara√ß√µes
   Interpolada: 5 compara√ß√µes (caso ideal)
   ```

#### Quando N√ÉO Usar Cada Algoritmo

| Algoritmo | Evite Quando | Raz√£o |
|-----------|--------------|-------|
| Linear | n > 10.000 e m√∫ltiplas buscas | O(n) fica muito lento |
| Linear | Dados ordenados dispon√≠veis | Desperdi√ßa vantagem de ordena√ß√£o |
| Bin√°ria | Dados n√£o ordenados, √∫nica busca | Custo O(n log n) de ordenar n√£o compensa |
| Bin√°ria | Listas encadeadas | Acesso O(n) elimina vantagem |
| Interpolada | Dados n√£o uniformes | Degenera para O(n) |
| Interpolada | Dados pequenos (n < 100k) | Overhead n√£o compensa |

### Estruturas de Dados Auxiliares

#### Skip Lists - Alternativa √†s √Årvores
- Busca, inser√ß√£o e remo√ß√£o em O(log n) esperado
- Mais simples de implementar que √°rvores balanceadas
- Uso: Redis, LevelDB

#### √Årvores de Busca Bin√°ria (BST)
- Busca O(log n) se balanceada
- Permite inser√ß√£o e remo√ß√£o eficientes
- Varia√ß√µes: AVL, Red-Black, B-Trees

#### Hash Tables
- Busca O(1) esperada
- Melhor performance para buscas exatas
- Limita√ß√£o: n√£o suporta buscas por intervalo

### Otimiza√ß√µes de Baixo N√≠vel

#### 1. Preven√ß√£o de Overflow
```c
// ‚ùå ERRADO - pode causar overflow
int meio = (esquerda + direita) / 2;

// ‚úÖ CORRETO
int meio = esquerda + (direita - esquerda) / 2;
```

**An√°lise**: Se esquerda e direita s√£o grandes, soma pode exceder INT_MAX.

#### 2. Busca Bin√°ria sem Branches (Branchless)
```c
// Vers√£o tradicional (com branches)
if (array[meio] < valor)
    esquerda = meio + 1;
else
    direita = meio - 1;

// Vers√£o branchless (mais r√°pida em CPUs modernas)
int flag = (array[meio] < valor);
esquerda = flag * (meio + 1) + (1 - flag) * esquerda;
direita = (1 - flag) * (meio - 1) + flag * direita;
```

**Vantagem**: Evita misprediction de branches, 10-40% mais r√°pido em arrays grandes.

#### 3. Otimiza√ß√£o SIMD (Busca Paralela)
```c
// Busca em 4 elementos simultaneamente usando instru√ß√µes vetoriais
__m128i vetor_busca = _mm_set1_epi32(valor);
for (int i = 0; i < n; i += 4) {
    __m128i vetor_array = _mm_loadu_si128((__m128i*)&array[i]);
    __m128i resultado = _mm_cmpeq_epi32(vetor_busca, vetor_array);
    int mask = _mm_movemask_epi8(resultado);
    if (mask) return i + (__builtin_ctz(mask) >> 2);
}
```

**Speedup**: 3-4√ó em busca linear para dados em cache.

### Trade-offs e Decis√µes de Projeto

#### Espa√ßo vs Tempo
| Estrat√©gia | Espa√ßo | Tempo de Busca | Quando Usar |
|------------|--------|----------------|-------------|
| Array ordenado + busca bin√°ria | O(n) | O(log n) | Poucas modifica√ß√µes |
| Hash table | O(n) | O(1) esperado | Muitas buscas, bom hash |
| BST balanceada | O(n) | O(log n) | Buscas + modifica√ß√µes frequentes |
| Array + √≠ndice | O(n + m) | O(1) a O(log m) | Espa√ßo dispon√≠vel, queries r√°pidas |

#### Ordena√ß√£o Pr√©via vs Busca Linear
```
Cen√°rio: n elementos, k buscas
Op√ß√£o 1: k buscas lineares = O(k √ó n)
Op√ß√£o 2: Ordenar + k buscas bin√°rias = O(n log n + k √ó log n)

Break-even quando: k √ó n = n log n + k √ó log n
                    k(n - log n) = n log n
                    k = (n log n) / (n - log n)

Para n grande: k ‚âà log n
```

**Conclus√£o**: Se k > log n, vale ordenar primeiro.

### Problemas Relacionados e Varia√ß√µes

#### 1. Busca da Primeira/√öltima Ocorr√™ncia
Para elementos duplicados:
```c
// Busca primeira ocorr√™ncia
int busca_primeira(int arr[], int n, int x) {
    int esq = 0, dir = n-1, resultado = -1;
    while (esq <= dir) {
        int meio = esq + (dir - esq) / 2;
        if (arr[meio] == x) {
            resultado = meio;
            dir = meio - 1;  // continua buscando √† esquerda
        } else if (arr[meio] < x) {
            esq = meio + 1;
        } else {
            dir = meio - 1;
        }
    }
    return resultado;
}
```

#### 2. Busca por Intervalo (Range Search)
Encontrar todos os elementos em [a, b]:
- Busca bin√°ria para limite inferior: O(log n)
- Busca bin√°ria para limite superior: O(log n)
- Retorna elementos no intervalo: O(k) onde k √© n√∫mero de elementos
- **Total**: O(log n + k)

#### 3. K-√©simo Menor Elemento
Usando busca bin√°ria em espa√ßo de valores:
- Complexidade: O(n log(max - min))
- √ötil quando k √© pr√≥ximo de n/2

#### 4. Busca em Array Rotacionado
Array ordenado rotacionado k posi√ß√µes:
```
Original: [1,2,3,4,5,6,7]
Rotacionado: [4,5,6,7,1,2,3]
```
- Modifica√ß√£o da busca bin√°ria: O(log n)
- Identifica qual metade est√° ordenada

## üîß Otimiza√ß√µes Implementadas

### Busca Bin√°ria Otimizada
- Verifica√ß√£o de limites
- Preven√ß√£o de overflow em √≠ndices
- Tratamento de casos especiais

### Busca em Matriz
- Aproveitamento da estrutura 2D
- Redu√ß√£o do espa√ßo de busca
- Otimiza√ß√£o de cache

## üßÆ An√°lise Matem√°tica

### Busca Bin√°ria
A cada itera√ß√£o, o espa√ßo de busca √© dividido pela metade:
```
T(n) = T(n/2) + c
T(n) = O(log‚ÇÇ n)
```

### Busca Interpolada
Para dados uniformemente distribu√≠dos:
```
T(n) = T(n^(1/2)) + c
T(n) = O(log log n)
```

## ü§î Quest√µes para Reflex√£o e Respostas Completas

### 1. Por que a busca bin√°ria requer dados ordenados? O que acontece se aplicarmos em dados desordenados?

**Resposta Detalhada**:

A busca bin√°ria fundamenta-se no princ√≠pio de **elimina√ß√£o por compara√ß√£o**: ao comparar o elemento do meio com o valor procurado, o algoritmo decide em qual metade continuar a busca. Esta decis√£o s√≥ √© v√°lida se os dados estiverem ordenados.

**Funcionamento com dados ordenados**:
```
Array ordenado: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
Buscar: 15

Itera√ß√£o 1: meio = 9, array[9] = 11, 15 > 11 ‚Üí vai para direita [13,15,17,19]
Itera√ß√£o 2: meio = 15, array[15] = 15 ‚Üí ENCONTRADO ‚úì
```

**Funcionamento com dados desordenados**:
```
Array desordenado: [15, 3, 7, 1, 19, 5, 13, 9, 11, 17]
Buscar: 7

Itera√ß√£o 1: meio = 4, array[4] = 19, 7 < 19 ‚Üí vai para esquerda [15,3,7,1]
Itera√ß√£o 2: meio = 1, array[1] = 3, 7 > 3 ‚Üí vai para direita (vazia)
Resultado: N√ÉO ENCONTRADO ‚úó (mas 7 existe na posi√ß√£o 2!)
```

**Raz√£o Matem√°tica**: 
A propriedade essencial da busca bin√°ria √©:
```
Se array[meio] < valor, ent√£o valor n√£o pode estar em array[0..meio]
```
Esta implica√ß√£o s√≥ √© verdadeira se o array est√° ordenado. Em arrays desordenados, elementos menores podem estar em qualquer posi√ß√£o, invalidando a elimina√ß√£o de metades.

**Consequ√™ncias**:
- **Resultado incorreto**: Pode n√£o encontrar elemento presente
- **Comportamento imprevis√≠vel**: Dependendo dos dados, pode encontrar ou n√£o
- **Viola√ß√£o do invariante**: A garantia "se existe, est√° no intervalo [esq, dir]" √© quebrada

---

### 2. Em que situa√ß√µes a busca linear pode ser mais eficiente que a busca bin√°ria?

**Resposta Detalhada**:

Existem v√°rias situa√ß√µes onde a busca linear supera a busca bin√°ria:

#### Situa√ß√£o 1: Arrays Pequenos (n < 32-64)
```c
// Para n = 10
Busca Linear: ~5 compara√ß√µes m√©dias (10/2)
Busca Bin√°ria: ~3 compara√ß√µes + overhead de c√°lculos

Overhead da bin√°ria:
- C√°lculo de meio: esq + (dir - esq) / 2
- Atualiza√ß√µes de √≠ndices
- Branches mais complexos
```

**Resultado**: Para n < 32, constantes ocultas favorecem a linear.

#### Situa√ß√£o 2: Elemento no In√≠cio
```c
Array: [5, 10, 15, 20, 25, 30, ... ] (1000 elementos)
Buscar: 5

Linear: 1 compara√ß√£o
Bin√°ria: ~10 compara√ß√µes (log‚ÇÇ 1000)

Se houver vi√©s de acesso (elementos no in√≠cio mais acessados),
linear pode ser muito mais eficiente na pr√°tica.
```

#### Situa√ß√£o 3: Localidade de Cache
```c
// Array grande n√£o ordenado
int array[1000000];

// Busca Linear: acesso sequencial
// - √ìtimo uso de cache (prefetching)
// - Todos os elementos pr√≥ximos j√° em cache
// - Poucos cache misses

// Busca Bin√°ria em array n√£o ordenado:
// - Precisaria ordenar primeiro: O(n log n)
// - Total: O(n log n + log n) > O(n) para √∫nica busca
```

#### Situa√ß√£o 4: Dados N√£o Ordenados, √önica Busca
```
Cen√°rio: Array com 10.000 elementos n√£o ordenados, 1 busca apenas

Op√ß√£o 1: Busca Linear direta
Custo: O(n) = 10.000 opera√ß√µes

Op√ß√£o 2: Ordenar + Busca Bin√°ria
Custo: O(n log n) + O(log n) = ~130.000 + 13 ‚âà 130.000 opera√ß√µes

Conclus√£o: Linear √© ~13√ó mais eficiente
```

#### Situa√ß√£o 5: Predicate Complexo
```c
// Busca com crit√©rio n√£o baseado em ordem
struct Pessoa {
    char nome[50];
    int idade;
    char cidade[50];
};

// Buscar primeira pessoa de "S√£o Paulo" com idade > 25
// N√£o h√° como usar busca bin√°ria (crit√©rio complexo multi-atributo)
for (int i = 0; i < n; i++) {
    if (strcmp(pessoas[i].cidade, "S√£o Paulo") == 0 && 
        pessoas[i].idade > 25) {
        return i;
    }
}
```

#### Situa√ß√£o 6: Estruturas sem Acesso Aleat√≥rio
```c
// Lista encadeada simples
struct Node {
    int valor;
    struct Node* proximo;
};

// Busca Linear: O(n) navegando ponteiros
// Busca Bin√°ria: O(n log n) - precisa acessar elemento m√©dio em O(n)!
// Linear √© melhor: menos overhead
```

**Benchmark Real**:
```
CPU: Intel i7 3.0 GHz, array em cache L1

n=16:   Linear: 12ns,  Bin√°ria: 18ns   ‚Üí Linear 1.5√ó mais r√°pida
n=32:   Linear: 24ns,  Bin√°ria: 28ns   ‚Üí Linear 1.2√ó mais r√°pida
n=64:   Linear: 48ns,  Bin√°ria: 35ns   ‚Üí Bin√°ria 1.4√ó mais r√°pida
n=1000: Linear: 750ns, Bin√°ria: 52ns   ‚Üí Bin√°ria 14√ó mais r√°pida
```

---

### 3. Como modificar a busca bin√°ria para encontrar a primeira ocorr√™ncia de um elemento repetido?

**Resposta Detalhada**:

**Problema**: Busca bin√°ria padr√£o para quando encontra qualquer ocorr√™ncia, mas em arrays com duplicatas, pode encontrar qualquer das ocorr√™ncias.

```c
Array: [1, 2, 3, 3, 3, 3, 3, 4, 5]
Buscar: 3
Posi√ß√µes de 3: 2, 3, 4, 5, 6

Busca bin√°ria padr√£o pode retornar qualquer posi√ß√£o entre 2-6
```

**Solu√ß√£o - Busca Bin√°ria Modificada**:

```c
int busca_primeira_ocorrencia(int arr[], int n, int valor) {
    int esquerda = 0, direita = n - 1;
    int resultado = -1;  // Guarda a posi√ß√£o mais √† esquerda encontrada
    
    while (esquerda <= direita) {
        int meio = esquerda + (direita - esquerda) / 2;
        
        if (arr[meio] == valor) {
            resultado = meio;        // Encontrou, mas pode n√£o ser a primeira
            direita = meio - 1;      // Continua buscando √† ESQUERDA
        }
        else if (arr[meio] < valor) {
            esquerda = meio + 1;
        }
        else {
            direita = meio - 1;
        }
    }
    
    return resultado;
}
```

**An√°lise da Modifica√ß√£o**:

1. **Diferen√ßa Chave**: Quando encontra o valor, n√£o para imediatamente
2. **Continua buscando**: Move `direita = meio - 1` para verificar se h√° ocorr√™ncias anteriores
3. **Guarda resultado**: Mant√©m a menor posi√ß√£o encontrada
4. **Complexidade**: Ainda O(log n) - n√£o degenera para linear

**Prova de Corre√ß√£o**:
- **Invariante**: `resultado` sempre cont√©m a primeira ocorr√™ncia conhecida at√© o momento (ou -1)
- **Ao final**: Todas as posi√ß√µes √† esquerda de `resultado` foram verificadas
- **Logo**: `resultado` √© a primeira ocorr√™ncia ou -1 se n√£o existe

**Exemplo de Execu√ß√£o**:
```
Array: [1, 3, 3, 3, 3, 5, 7], buscar 3

Itera√ß√£o 1: meio=3, arr[3]=3, encontrou! resultado=3, vai esquerda [0..2]
Itera√ß√£o 2: meio=1, arr[1]=3, encontrou! resultado=1, vai esquerda [0..0]
Itera√ß√£o 3: meio=0, arr[0]=1 < 3, vai direita (loop termina)
Resultado: 1 (primeira ocorr√™ncia) ‚úì
```

**Varia√ß√£o - √öltima Ocorr√™ncia**:
```c
int busca_ultima_ocorrencia(int arr[], int n, int valor) {
    int esquerda = 0, direita = n - 1;
    int resultado = -1;
    
    while (esquerda <= direita) {
        int meio = esquerda + (direita - esquerda) / 2;
        
        if (arr[meio] == valor) {
            resultado = meio;
            esquerda = meio + 1;  // Mudan√ßa: busca √† DIREITA
        }
        else if (arr[meio] < valor) {
            esquerda = meio + 1;
        }
        else {
            direita = meio - 1;
        }
    }
    
    return resultado;
}
```

**Aplica√ß√£o - Contar Ocorr√™ncias**:
```c
int contar_ocorrencias(int arr[], int n, int valor) {
    int primeira = busca_primeira_ocorrencia(arr, n, valor);
    if (primeira == -1) return 0;
    
    int ultima = busca_ultima_ocorrencia(arr, n, valor);
    return ultima - primeira + 1;
}
// Complexidade: O(log n) + O(log n) = O(log n)
```

---

### 4. Qual seria o impacto de usar busca interpolada em dados n√£o uniformemente distribu√≠dos?

**Resposta Detalhada**:

A busca interpolada pode **degenerar de O(log log n) para O(n)** em dados n√£o uniformes, tornando-se pior que a busca bin√°ria.

#### Exemplo de Degenera√ß√£o:

**Caso 1: Dados Exponenciais**
```c
Array: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]
Buscar: 512

C√°lculo de interpola√ß√£o:
pos = 0 + (512-1)/(1024-1) * 10 = 4.99 ‚âà 5
arr[5] = 32 (muito longe de 512!)

Pr√≥xima itera√ß√£o:
pos = 5 + (512-32)/(1024-32) * 5 = 7.42 ‚âà 7
arr[7] = 128 (ainda longe)

Continua fazendo pequenos avan√ßos... O(n) no pior caso!
```

**Caso 2: Dados com Clusters**
```c
Array: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1000, 2000, 3000]
Buscar: 10

Interpola√ß√£o assume distribui√ß√£o uniforme:
pos = 0 + (10-1)/(3000-1) * 12 = 0.036 ‚âà 0
arr[0] = 1

Vai avan√ßar lentamente 1, 2, 3... at√© encontrar 10
Comportamento similar √† busca linear!
```

#### An√°lise Matem√°tica do Pior Caso:

Na busca interpolada, assumimos:
```
arr[i] ‚âà arr[0] + (arr[n-1] - arr[0]) √ó (i/n)
```

**Se esta suposi√ß√£o √© violada**, a estimativa de posi√ß√£o √© ruim.

**Pior caso constru√≠do adversarialmente**:
```c
// Array especialmente constru√≠do para quebrar interpola√ß√£o
arr[i] = i^2  // Crescimento quadr√°tico

Para buscar arr[n-1] = n^2:
- Primeira tentativa: pos ‚âà n/2
- arr[n/2] = (n/2)^2 = n^2/4
- Elimina apenas 1/4 do espa√ßo (vs 1/2 na bin√°ria)
- Pr√≥xima: elimina 1/16...
- Total: O(n) itera√ß√µes no pior caso
```

#### Compara√ß√£o Pr√°tica:

**Dados Uniformes** [0, 10, 20, 30, ..., 990, 1000]:
```
Busca Bin√°ria: 10 compara√ß√µes
Busca Interpolada: 3 compara√ß√µes
Speedup: 3.3√ó
```

**Dados N√£o-Uniformes** [1, 2, 3, 4, 5, ..., 100, 10000]:
```
Busca Bin√°ria: 10 compara√ß√µes
Busca Interpolada: 45 compara√ß√µes (degenera√ß√£o!)
Slowdown: 4.5√ó
```

#### Quando a Degenera√ß√£o Ocorre:

1. **Distribui√ß√£o Exponencial/Pot√™ncia**: Valores crescem exponencialmente
2. **Dados com Outliers**: Poucos valores muito grandes/pequenos
3. **Distribui√ß√£o em Clusters**: Grupos densos separados por gaps
4. **Distribui√ß√£o Assim√©trica**: Skewed distribution

#### Solu√ß√£o: Busca Interpolada H√≠brida

```c
int busca_interpolada_hibrida(int arr[], int n, int valor) {
    int esq = 0, dir = n - 1;
    int tentativas = 0;
    const int MAX_TENTATIVAS = (int)(log(n) / log(2)) + 1;
    
    while (esq <= dir && tentativas < MAX_TENTATIVAS) {
        // Tenta interpola√ß√£o
        int pos = esq + ((valor - arr[esq]) * (dir - esq)) / 
                         (arr[dir] - arr[esq]);
        
        if (arr[pos] == valor) return pos;
        if (arr[pos] < valor) esq = pos + 1;
        else dir = pos - 1;
        
        tentativas++;
    }
    
    // Se excedeu tentativas, cai para busca bin√°ria
    return busca_binaria(arr, esq, dir, valor);
}
```

**Garantia**: Nunca pior que O(log n) da busca bin√°ria, mant√©m O(log log n) quando aplic√°vel.

#### Detec√ß√£o de Adequa√ß√£o:

```c
// Verifica se dados s√£o adequados para busca interpolada
bool dados_adequados_interpolacao(int arr[], int n) {
    if (n < 1000) return false;  // N√£o vale para arrays pequenos
    
    // Verifica uniformidade: diferen√ßas devem ser similares
    double diff_media = (arr[n-1] - arr[0]) / (double)n;
    int violacoes = 0;
    
    for (int i = 1; i < n; i++) {
        double diff_local = arr[i] - arr[i-1];
        // Se diferen√ßa local > 3√ó m√©dia, n√£o √© uniforme
        if (diff_local > 3 * diff_media) {
            violacoes++;
        }
    }
    
    // Se mais de 5% s√£o outliers, n√£o usar interpola√ß√£o
    return (violacoes < n * 0.05);
}
```

---

### 5. Projete um sistema de busca que combine m√∫ltiplos algoritmos baseado no tamanho e caracter√≠sticas dos dados.

**Resposta Detalhada**:

```c
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>

// Estrutura para armazenar metadados dos dados
typedef struct {
    int tamanho;
    bool ordenado;
    bool distribuicao_uniforme;
    int num_buscas_esperadas;
    bool cache_friendly;
} MetadadosBusca;

// Enum para tipos de algoritmo
typedef enum {
    ALG_LINEAR,
    ALG_LINEAR_SENTINELA,
    ALG_BINARIA,
    ALG_INTERPOLADA,
    ALG_HASH,
    ALG_HIBRIDO
} TipoAlgoritmo;

// Estrutura de decis√£o
typedef struct {
    TipoAlgoritmo algoritmo;
    char razao[200];
} DecisaoBusca;

/**
 * Sistema Adaptativo de Sele√ß√£o de Algoritmo de Busca
 * Analisa caracter√≠sticas dos dados e escolhe algoritmo √≥timo
 */
DecisaoBusca selecionar_algoritmo(MetadadosBusca* meta) {
    DecisaoBusca decisao;
    
    // Regra 1: Arrays muito pequenos -> Linear sempre
    if (meta->tamanho < 32) {
        decisao.algoritmo = ALG_LINEAR;
        sprintf(decisao.razao, 
                "Array pequeno (n=%d < 32): overhead de outros algoritmos n√£o compensa",
                meta->tamanho);
        return decisao;
    }
    
    // Regra 2: N√£o ordenado, poucas buscas -> Linear
    if (!meta->ordenado && meta->num_buscas_esperadas < 3) {
        decisao.algoritmo = ALG_LINEAR_SENTINELA;
        sprintf(decisao.razao,
                "N√£o ordenado + poucas buscas (%d): custo de ordenar (O(n log n)) n√£o compensa",
                meta->num_buscas_esperadas);
        return decisao;
    }
    
    // Regra 3: N√£o ordenado, muitas buscas -> considerar hash ou ordenar
    if (!meta->ordenado && meta->num_buscas_esperadas > 10) {
        if (meta->tamanho > 10000) {
            decisao.algoritmo = ALG_HASH;
            sprintf(decisao.razao,
                    "N√£o ordenado + muitas buscas (%d) + grande (n=%d): Hash Table O(1)",
                    meta->num_buscas_esperadas, meta->tamanho);
        } else {
            decisao.algoritmo = ALG_BINARIA;
            sprintf(decisao.razao,
                    "N√£o ordenado + muitas buscas: ordenar O(n log n) + buscas O(k log n) compensa");
        }
        return decisao;
    }
    
    // Regra 4: Ordenado, tamanho m√©dio -> Bin√°ria
    if (meta->ordenado && meta->tamanho < 100000) {
        decisao.algoritmo = ALG_BINARIA;
        sprintf(decisao.razao,
                "Ordenado + tamanho m√©dio (n=%d): Bin√°ria O(log n) √© √≥tima e simples",
                meta->tamanho);
        return decisao;
    }
    
    // Regra 5: Ordenado, muito grande, distribui√ß√£o uniforme -> Interpolada
    if (meta->ordenado && meta->tamanho >= 100000 && meta->distribuicao_uniforme) {
        decisao.algoritmo = ALG_INTERPOLADA;
        sprintf(decisao.razao,
                "Ordenado + muito grande (n=%d) + uniforme: Interpolada O(log log n)",
                meta->tamanho);
        return decisao;
    }
    
    // Regra 6: Ordenado, muito grande, n√£o uniforme -> Bin√°ria ou h√≠brido
    if (meta->ordenado && meta->tamanho >= 100000) {
        decisao.algoritmo = ALG_HIBRIDO;
        sprintf(decisao.razao,
                "Ordenado + muito grande (n=%d) + n√£o uniforme: H√≠brido (tenta interpola√ß√£o, cai para bin√°ria)",
                meta->tamanho);
        return decisao;
    }
    
    // Default: Bin√°ria (seguro e eficiente)
    decisao.algoritmo = ALG_BINARIA;
    sprintf(decisao.razao, "Caso padr√£o: Bin√°ria √© segura e eficiente para dados ordenados");
    return decisao;
}

/**
 * Analisa distribui√ß√£o para verificar uniformidade
 */
bool analisar_uniformidade(int arr[], int n) {
    if (n < 10) return false;
    
    // Calcula diferen√ßa m√©dia
    double diff_total = arr[n-1] - arr[0];
    double diff_esperada = diff_total / n;
    
    // Conta viola√ß√µes (diferen√ßas muito maiores que a m√©dia)
    int violacoes = 0;
    for (int i = 1; i < n; i++) {
        double diff_local = arr[i] - arr[i-1];
        if (diff_local > 3 * diff_esperada || diff_local < diff_esperada / 3) {
            violacoes++;
        }
    }
    
    // Se menos de 10% s√£o outliers, considera uniforme
    return (violacoes < n * 0.10);
}

/**
 * Verifica se array est√° ordenado
 */
bool verificar_ordenado(int arr[], int n) {
    for (int i = 1; i < n; i++) {
        if (arr[i] < arr[i-1]) return false;
    }
    return true;
}

/**
 * Sistema completo de busca adaptativa
 */
int busca_adaptativa(int arr[], int n, int valor, int num_buscas_futuras) {
    // Analisa caracter√≠sticas dos dados
    MetadadosBusca meta;
    meta.tamanho = n;
    meta.ordenado = verificar_ordenado(arr, n);
    meta.distribuicao_uniforme = meta.ordenado ? analisar_uniformidade(arr, n) : false;
    meta.num_buscas_esperadas = num_buscas_futuras;
    
    // Seleciona algoritmo apropriado
    DecisaoBusca decisao = selecionar_algoritmo(&meta);
    
    // Log da decis√£o (em produ√ß√£o, usar sistema de logging)
    printf("[BUSCA ADAPTATIVA] Algoritmo selecionado: ");
    switch(decisao.algoritmo) {
        case ALG_LINEAR: printf("LINEAR"); break;
        case ALG_LINEAR_SENTINELA: printf("LINEAR COM SENTINELA"); break;
        case ALG_BINARIA: printf("BIN√ÅRIA"); break;
        case ALG_INTERPOLADA: printf("INTERPOLADA"); break;
        case ALG_HASH: printf("HASH TABLE"); break;
        case ALG_HIBRIDO: printf("H√çBRIDO"); break;
    }
    printf("\n[RAZ√ÉO] %s\n", decisao.razao);
    
    // Executa busca com algoritmo selecionado
    switch(decisao.algoritmo) {
        case ALG_LINEAR:
        case ALG_LINEAR_SENTINELA:
            return busca_linear(arr, n, valor);
        
        case ALG_BINARIA:
            if (!meta.ordenado) {
                printf("[INFO] Ordenando array antes da busca bin√°ria...\n");
                qsort(arr, n, sizeof(int), comparar);
            }
            return busca_binaria(arr, n, valor);
        
        case ALG_INTERPOLADA:
            return busca_interpolada(arr, n, valor);
        
        case ALG_HIBRIDO:
            return busca_hibrida(arr, n, valor);
        
        case ALG_HASH:
            printf("[INFO] Para m√∫ltiplas buscas, considere criar hash table\n");
            return busca_linear(arr, n, valor);
    }
    
    return -1;
}

// Implementa√ß√µes dos algoritmos (simplificadas)
int busca_linear(int arr[], int n, int valor) {
    for (int i = 0; i < n; i++) {
        if (arr[i] == valor) return i;
    }
    return -1;
}

int busca_binaria(int arr[], int n, int valor) {
    int esq = 0, dir = n - 1;
    while (esq <= dir) {
        int meio = esq + (dir - esq) / 2;
        if (arr[meio] == valor) return meio;
        if (arr[meio] < valor) esq = meio + 1;
        else dir = meio - 1;
    }
    return -1;
}

int busca_interpolada(int arr[], int n, int valor) {
    int esq = 0, dir = n - 1;
    
    while (esq <= dir && valor >= arr[esq] && valor <= arr[dir]) {
        if (esq == dir) {
            return (arr[esq] == valor) ? esq : -1;
        }
        
        // Interpola√ß√£o
        int pos = esq + ((double)(valor - arr[esq]) / (arr[dir] - arr[esq])) * (dir - esq);
        
        if (arr[pos] == valor) return pos;
        if (arr[pos] < valor) esq = pos + 1;
        else dir = pos - 1;
    }
    return -1;
}

int busca_hibrida(int arr[], int n, int valor) {
    // Tenta interpola√ß√£o por algumas itera√ß√µes
    int tentativas_max = (int)log2(n) + 1;
    int esq = 0, dir = n - 1, tentativas = 0;
    
    while (esq <= dir && tentativas < tentativas_max && 
           valor >= arr[esq] && valor <= arr[dir]) {
        int pos = esq + ((double)(valor - arr[esq]) / (arr[dir] - arr[esq])) * (dir - esq);
        
        if (arr[pos] == valor) return pos;
        if (arr[pos] < valor) esq = pos + 1;
        else dir = pos - 1;
        
        tentativas++;
    }
    
    // Se n√£o encontrou, usa busca bin√°ria no intervalo restante
    printf("[H√çBRIDO] Mudando para busca bin√°ria ap√≥s %d tentativas\n", tentativas);
    return busca_binaria(arr + esq, dir - esq + 1, valor);
}

int comparar(const void* a, const void* b) {
    return (*(int*)a - *(int*)b);
}

// Exemplo de uso
int main() {
    // Teste 1: Array pequeno
    int arr1[] = {5, 2, 8, 1, 9};
    printf("\n=== TESTE 1: Array pequeno ===\n");
    busca_adaptativa(arr1, 5, 8, 1);
    
    // Teste 2: Array grande ordenado uniforme
    int arr2[100000];
    for (int i = 0; i < 100000; i++) arr2[i] = i * 10;
    printf("\n=== TESTE 2: Grande ordenado uniforme ===\n");
    busca_adaptativa(arr2, 100000, 50000, 100);
    
    // Teste 3: Array grande n√£o uniforme
    int arr3[10000];
    for (int i = 0; i < 10000; i++) arr3[i] = i * i;
    printf("\n=== TESTE 3: Grande n√£o uniforme ===\n");
    busca_adaptativa(arr3, 10000, 10000, 50);
    
    return 0;
}
```

**Caracter√≠sticas do Sistema**:

1. **An√°lise Autom√°tica**: Detecta ordena√ß√£o e uniformidade
2. **Sele√ß√£o Inteligente**: Usa regras heur√≠sticas baseadas em teoria
3. **Fallback Seguro**: Sempre tem op√ß√£o confi√°vel (busca bin√°ria)
4. **Logging**: Explica decis√µes para debugging
5. **Flex√≠vel**: F√°cil adicionar novos algoritmos e regras

**Extens√µes Poss√≠veis**:
- **Aprendizado**: Coletar estat√≠sticas e ajustar regras
- **Cache**: Manter √≠ndices para buscas repetidas
- **Paraleliza√ß√£o**: Busca linear paralela para arrays muito grandes
- **Estruturas auxiliares**: Criar √≠ndices sob demanda

---

## üí° Quest√µes Adicionais Avan√ßadas

### 6. Explique como a hierarquia de mem√≥ria (cache) afeta a performance real dos algoritmos de busca.

**Resposta**:

A hierarquia de mem√≥ria moderna (Cache L1 ‚Üí L2 ‚Üí L3 ‚Üí RAM) introduz lat√™ncias vari√°veis que n√£o s√£o capturadas pela an√°lise Big O tradicional.

**Lat√™ncias T√≠picas**:
```
Registrador CPU: 0 ciclos
Cache L1: 4 ciclos (~1ns)
Cache L2: 12 ciclos (~3ns)
Cache L3: 38 ciclos (~12ns)
RAM: 200+ ciclos (~60ns)
```

**Busca Linear**:
- **Padr√£o de acesso**: Sequencial
- **Cache behavior**: √ìtimo - prefetching autom√°tico
- **Cache misses**: ~n/64 (assumindo cache lines de 64 bytes)
- **Tempo real**: Dominado por velocidade de cache L1/L2

**Busca Bin√°ria**:
- **Padr√£o de acesso**: Aleat√≥rio (jumps grandes)
- **Cache behavior**: Ruim - muitos cache misses
- **Cache misses**: ~log n (cada compara√ß√£o pode ser um miss)
- **Tempo real**: Dominado por lat√™ncia de RAM

**Impacto Pr√°tico**:
```
Array de 10.000 inteiros (40KB, n√£o cabe em L1 32KB)

Busca Linear:
- Compara√ß√µes: 5.000 (caso m√©dio)
- Cache misses: ~80 (acesso sequencial)
- Tempo: 5.000 √ó 1ns + 80 √ó 60ns ‚âà 10 ¬µs

Busca Bin√°ria:
- Compara√ß√µes: 14
- Cache misses: ~10 (cada acesso pode ser miss)
- Tempo: 14 √ó 1ns + 10 √ó 60ns ‚âà 0.6 ¬µs

Bin√°ria ainda ganha, mas n√£o por fator de 357√ó (5000/14)
```

**Para arrays que cabem em cache** (< 32KB):
```
Linear: muito r√°pida (tudo em L1)
Bin√°ria: ainda r√°pida (tudo em L1)
Bin√°ria vence, mas gap menor
```

**Otimiza√ß√µes cache-aware**:
1. **B-tree search**: Minimiza cache misses em √°rvores
2. **Blocked algorithms**: Divide dados em blocos do tamanho do cache
3. **Eytzinger layout**: Reorganiza array para busca bin√°ria cache-friendly

---

### 7. Como implementar busca bin√°ria para encontrar o menor elemento maior ou igual a um valor (lower bound)?

**Resposta**:

**Lower bound**: Menor elemento ‚â• valor procurado (√∫til em C++ STL)

```c
/**
 * Retorna √≠ndice do menor elemento >= valor
 * Se todos < valor, retorna n
 */
int lower_bound(int arr[], int n, int valor) {
    int esq = 0, dir = n;
    
    while (esq < dir) {
        int meio = esq + (dir - esq) / 2;
        
        if (arr[meio] < valor) {
            esq = meio + 1;  // Elemento[meio] muito pequeno
        } else {
            dir = meio;       // Elemento[meio] pode ser resposta
        }
    }
    
    return esq;  // Retorna posi√ß√£o onde valor deveria ser inserido
}
```

**Upper bound**: Menor elemento > valor

```c
int upper_bound(int arr[], int n, int valor) {
    int esq = 0, dir = n;
    
    while (esq < dir) {
        int meio = esq + (dir - esq) / 2;
        
        if (arr[meio] <= valor) {  // Diferen√ßa: <= ao inv√©s de <
            esq = meio + 1;
        } else {
            dir = meio;
        }
    }
    
    return esq;
}
```

**Aplica√ß√µes**:
1. **Inser√ß√£o em array ordenado**: `insert(arr, lower_bound(...), valor)`
2. **Range queries**: Elementos entre [a,b] = [lower_bound(a), upper_bound(b))
3. **Aproxima√ß√£o**: Encontrar valor mais pr√≥ximo

---

### 8. Por que a busca tern√°ria (divide em 3) n√£o √© mais eficiente que bin√°ria (divide em 2)?

**Resposta**:

Intuitivamente, dividir em 3 partes parece melhor, mas matematicamente n√£o √©.

**An√°lise de Compara√ß√µes**:

**Busca Bin√°ria**:
- 1 compara√ß√£o por n√≠vel
- log‚ÇÇ(n) n√≠veis
- **Total**: log‚ÇÇ(n) compara√ß√µes

**Busca Tern√°ria**:
- 2 compara√ß√µes por n√≠vel (verificar m1 e m2)
- log‚ÇÉ(n) n√≠veis  
- **Total**: 2 √ó log‚ÇÉ(n) compara√ß√µes

**Convers√£o para mesma base**:
```
2 √ó log‚ÇÉ(n) = 2 √ó log‚ÇÇ(n) / log‚ÇÇ(3)
             = 2 √ó log‚ÇÇ(n) / 1.585
             ‚âà 1.26 √ó log‚ÇÇ(n)
```

**Conclus√£o**: Tern√°ria usa ~26% mais compara√ß√µes!

**Raz√£o**: Reduzir espa√ßo de busca para n/3 (vs n/2) n√£o compensa o custo de 2 compara√ß√µes (vs 1).

**Onde tern√°ria √© √∫til**:
- **Otimiza√ß√£o de fun√ß√µes unimodais** (encontrar m√≠nimo/m√°ximo)
- N√£o para busca em arrays ordenados

---

### 9. Como busca bin√°ria se relaciona com √°rvores de decis√£o e teoria da informa√ß√£o?

**Resposta**:

**√Årvore de Decis√£o**:
Cada execu√ß√£o da busca bin√°ria pode ser representada como uma √°rvore bin√°ria:
- **N√≥s internos**: Compara√ß√µes
- **Folhas**: Resultado (posi√ß√£o encontrada ou n√£o existe)
- **Altura**: N√∫mero de compara√ß√µes no pior caso

**Limite Inferior via Teoria da Informa√ß√£o**:

Para distinguir entre n possibilidades, precisamos de log‚ÇÇ(n) bits de informa√ß√£o.

Cada compara√ß√£o bin√°ria fornece no m√°ximo 1 bit de informa√ß√£o:
```
Antes: n possibilidades ‚Üí log‚ÇÇ(n) bits de incerteza
Compara√ß√£o: resposta sim/n√£o ‚Üí 1 bit de informa√ß√£o
Depois: n/2 possibilidades ‚Üí log‚ÇÇ(n) - 1 bits restantes
```

**Teorema**: Qualquer algoritmo baseado em compara√ß√µes precisa de pelo menos log‚ÇÇ(n) compara√ß√µes no pior caso.

**Busca bin√°ria atinge este limite** ‚Üí √© √≥tima!

**Conex√£o com Entropia**:
```
Entropia de Shannon: H = -Œ£ p(i) log‚ÇÇ p(i)

Para busca uniforme: p(i) = 1/n para todo i
H = -n √ó (1/n) log‚ÇÇ(1/n) = log‚ÇÇ(n)

Interpreta√ß√£o: Precisa de log‚ÇÇ(n) bits para codificar a resposta
```

---

### 10. Como realizar busca eficiente em uma matriz ordenada tanto por linhas quanto por colunas?

**Resposta**:

**Matriz Young** (ordenada em linhas e colunas):
```
[1,   3,   5,   7]
[2,   4,   6,   8]
[9,  10,  11,  12]
[13, 14,  15,  16]
```

**Algoritmo Escalonado (Staircase Search)**:

```c
/**
 * Busca em matriz m√ón ordenada nas duas dimens√µes
 * Complexidade: O(m + n)
 */
int busca_matriz_ordenada(int matriz[][4], int m, int n, int valor) {
    int linha = 0;
    int coluna = n - 1;  // Come√ßa no canto superior direito
    
    while (linha < m && coluna >= 0) {
        if (matriz[linha][coluna] == valor) {
            printf("Encontrado em [%d][%d]\n", linha, coluna);
            return 1;
        }
        
        if (matriz[linha][coluna] > valor) {
            coluna--;  // Elimina coluna inteira
        } else {
            linha++;   // Elimina linha inteira
        }
    }
    
    return 0;  // N√£o encontrado
}
```

**Por que funciona**:
1. **Canto superior direito**: maior da linha, menor da coluna
2. **Se > valor**: toda coluna pode ser eliminada
3. **Se < valor**: toda linha pode ser eliminada
4. **A cada passo**: elimina linha OU coluna completa

**Visualiza√ß√£o**:
```
Buscar: 10

Passo 1: [0][3] = 7 < 10 ‚Üí elimina linha 0
Passo 2: [1][3] = 8 < 10 ‚Üí elimina linha 1
Passo 3: [2][3] = 12 > 10 ‚Üí elimina coluna 3
Passo 4: [2][2] = 11 > 10 ‚Üí elimina coluna 2
Passo 5: [2][1] = 10 == 10 ‚Üí ENCONTRADO!

Total: 5 passos para matriz 4√ó4
Busca linear seria: at√© 16 passos
```

**Complexidade**:
- No pior caso: elimina m linhas + n colunas
- **Tempo**: O(m + n)
- **Espa√ßo**: O(1)

**Compara√ß√£o**:
- Busca linear: O(m √ó n)
- Busca escalonada: O(m + n)
- Para matriz 1000√ó1000: 1.000.000 vs 2.000 opera√ß√µes!

## üìñ Exerc√≠cios Pr√°ticos

1. **B√°sico**: Implemente uma vers√£o recursiva da busca bin√°ria
2. **Intermedi√°rio**: Crie uma busca bin√°ria que retorne todas as posi√ß√µes de elementos duplicados
3. **Avan√ßado**: Desenvolva uma busca h√≠brida que escolha automaticamente entre linear e bin√°ria baseado no tamanho dos dados
4. **Desafio**: Implemente busca tern√°ria e compare sua performance com a busca bin√°ria

## üìö Refer√™ncias Acad√™micas e Bibliografia

### Livros Fundamentais

#### Obras Cl√°ssicas em An√°lise de Algoritmos

1. **Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C.** (2009). *Introduction to Algorithms* (3rd ed.). MIT Press.
   - **Cap√≠tulo 2.3**: An√°lise de algoritmos - Busca linear
   - **Cap√≠tulo 12**: √Årvores de busca bin√°ria
   - **Se√ß√µes 2.2, 12.2**: Complexidade e invariantes de loop
   - ISBN: 978-0262033848
   - *Considerado a "b√≠blia" dos algoritmos, com provas formais detalhadas*

2. **Knuth, D. E.** (1998). *The Art of Computer Programming, Volume 3: Sorting and Searching* (2nd ed.). Addison-Wesley.
   - **Se√ß√£o 6.2.1**: Busca sequencial e suas variantes
   - **Se√ß√£o 6.2.2**: Busca bin√°ria e an√°lise matem√°tica detalhada
   - **Se√ß√£o 6.4**: Hashing e m√©todos de acesso direto
   - ISBN: 978-0201896855
   - *An√°lise matem√°tica rigorosa, incluindo constantes ocultas*

3. **Sedgewick, R., & Wayne, K.** (2011). *Algorithms* (4th ed.). Addison-Wesley.
   - **Cap√≠tulo 1.4**: An√°lise de algoritmos
   - **Cap√≠tulo 3.1**: Tabelas de s√≠mbolos e busca
   - **Cap√≠tulo 3.2**: √Årvores de busca bin√°ria
   - ISBN: 978-0321573513
   - *Abordagem pr√°tica com implementa√ß√µes em Java*

4. **Aho, A. V., Hopcroft, J. E., & Ullman, J. D.** (1974). *The Design and Analysis of Computer Algorithms*. Addison-Wesley.
   - **Cap√≠tulo 3**: Limites inferiores em modelos de compara√ß√£o
   - **Cap√≠tulo 4**: Busca em estruturas de dados
   - ISBN: 978-0201000290
   - *Cl√°ssico sobre limites te√≥ricos de algoritmos*

### Artigos Seminais

#### Busca Bin√°ria

5. **Bottenbruch, H.** (1962). "Structure and Use of ALGOL 60". *Journal of the ACM*, 9(2), 161-221.
   - DOI: 10.1145/321119.321120
   - *Primeira publica√ß√£o formal do algoritmo de busca bin√°ria*

6. **Knuth, D. E.** (2000). "Ancient Babylonian Algorithms". *Communications of the ACM*, 15(7), 671-677.
   - DOI: 10.1145/361454.361514
   - *Discute origens hist√≥ricas de algoritmos de busca*

#### Busca Interpolada

7. **Peterson, W. W.** (1957). "Addressing for Random-Access Storage". *IBM Journal of Research and Development*, 1(2), 130-146.
   - DOI: 10.1147/rd.12.0130
   - *Trabalho original propondo busca interpolada*

8. **Perl, Y., Itai, A., & Avni, H.** (1978). "Interpolation Search‚ÄîA Log Log N Search". *Communications of the ACM*, 21(7), 550-553.
   - DOI: 10.1145/359545.359557
   - *Prova matem√°tica da complexidade O(log log n)*

9. **Yao, A. C., & Yao, F. F.** (1976). "The Complexity of Searching an Ordered Random Table". *Proceedings of 17th Annual Symposium on Foundations of Computer Science*, 173-177.
   - DOI: 10.1109/SFCS.1976.12
   - *An√°lise probabil√≠stica de busca em dados uniformes*

### Teoria da Complexidade e Limites Inferiores

10. **Moret, B. M. E.** (1982). "Decision Trees and Diagrams". *Computing Surveys*, 14(4), 593-623.
    - DOI: 10.1145/356893.356898
    - *√Årvores de decis√£o como modelo para provar limites inferiores*

11. **Ben-Or, M.** (1983). "Lower Bounds for Algebraic Computation Trees". *Proceedings of the 15th Annual ACM Symposium on Theory of Computing*, 80-86.
    - DOI: 10.1145/800061.808735
    - *Limites inferiores para algoritmos baseados em compara√ß√µes*

12. **Fredman, M. L.** (1976). "How Good is the Information Theory Bound in Sorting?". *Theoretical Computer Science*, 1(4), 355-361.
    - DOI: 10.1016/0304-3975(76)90078-5
    - *Conex√£o entre teoria da informa√ß√£o e limites de busca/ordena√ß√£o*

### Estruturas de Dados e Otimiza√ß√µes

13. **Brodnik, A., Carlsson, S., Demaine, E. D., Munro, J. I., & Sedgewick, R.** (1999). "Resizable Arrays in Optimal Time and Space". *Workshop on Algorithms and Data Structures*, 37-48.
    - DOI: 10.1007/3-540-48447-7_4
    - *Arrays din√¢micos e an√°lise amortizada*

14. **Pugh, W.** (1990). "Skip Lists: A Probabilistic Alternative to Balanced Trees". *Communications of the ACM*, 33(6), 668-676.
    - DOI: 10.1145/78973.78977
    - *Estrutura alternativa com busca O(log n) esperada*

15. **Bentley, J. L., & Yao, A. C.** (1976). "An Almost Optimal Algorithm for Unbounded Searching". *Information Processing Letters*, 5(3), 82-87.
    - DOI: 10.1016/0020-0190(76)90071-5
    - *Busca exponencial para arrays sem tamanho conhecido*

### Otimiza√ß√µes e Aspectos Pr√°ticos

16. **Brodal, G. S., & Moruz, G.** (2006). "Skewed Binary Search Trees". *Algorithms‚ÄìESA 2006*, 708-719.
    - DOI: 10.1007/11841036_63
    - *Busca bin√°ria otimizada para dados n√£o uniformes*

17. **Khuong, P. V., & Morin, P.** (2017). "Array Layouts for Comparison-Based Searching". *Journal of Experimental Algorithmics*, 22, Article 1.3.
    - DOI: 10.1145/3053370
    - *Layouts de array otimizados para cache*

18. **Manber, U., & Myers, G.** (1993). "Suffix Arrays: A New Method for On-Line String Searches". *SIAM Journal on Computing*, 22(5), 935-948.
    - DOI: 10.1137/0222058
    - *Aplica√ß√£o de busca bin√°ria em processamento de strings*

### An√°lise Probabil√≠stica e Randomiza√ß√£o

19. **Gonnet, G. H., Rogers, L. D., & George, J. A.** (1980). "An Algorithmic and Complexity Analysis of Interpolation Search". *Acta Informatica*, 13(1), 39-52.
    - DOI: 10.1007/BF00288537
    - *An√°lise detalhada de performance esperada*

20. **Andersson, A., & Thorup, M.** (2000). "Tight(er) Worst-Case Bounds on Dynamic Searching and Priority Queues". *Proceedings of the 32nd Annual ACM Symposium on Theory of Computing*, 335-342.
    - DOI: 10.1145/335305.335345
    - *Limites apertados para busca din√¢mica*

### Cache e Hierarquia de Mem√≥ria

21. **Frigo, M., Leiserson, C. E., Prokop, H., & Ramachandran, S.** (1999). "Cache-Oblivious Algorithms". *Proceedings of 40th Annual Symposium on Foundations of Computer Science*, 285-297.
    - DOI: 10.1109/SFFCS.1999.814600
    - *Algoritmos otimizados para hierarquia de mem√≥ria*

22. **Ladner, R. E., Fix, J. D., & LaMarca, A.** (1999). "Cache Performance Analysis of Traversals and Random Accesses". *Proceedings of the 10th Annual ACM-SIAM Symposium on Discrete Algorithms*, 613-622.
    - *Impacto de cache em busca bin√°ria vs linear*

### Aplica√ß√µes e Varia√ß√µes

23. **Willard, D. E.** (1983). "Log-logarithmic Worst-Case Range Queries are Possible in Space Œò(N)". *Information Processing Letters*, 17(2), 81-84.
    - DOI: 10.1016/0020-0190(83)90075-3
    - *Busca em intervalos com complexidade sublogar√≠tmica*

24. **van Emde Boas, P.** (1977). "Preserving Order in a Forest in Less Than Logarithmic Time". *Proceedings of 16th Annual Symposium on Foundations of Computer Science*, 75-84.
    - DOI: 10.1109/SFCS.1977.32
    - *Estrutura com busca O(log log U) onde U √© universo*

### Recursos Online e Materiais Complementares

25. **MIT OpenCourseWare**: Introduction to Algorithms (6.006)
    - URL: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/
    - *V√≠deos e materiais das aulas do MIT*

26. **Visualgo**: Algorithm Visualizations
    - URL: https://visualgo.net/en/bst
    - *Visualiza√ß√µes interativas de algoritmos de busca*

27. **Big-O Cheat Sheet**: Complexity Reference
    - URL: https://www.bigocheatsheet.com/
    - *Refer√™ncia r√°pida de complexidades*

### Padr√µes e Melhores Pr√°ticas

28. **Bentley, J.** (1999). *Programming Pearls* (2nd ed.). Addison-Wesley.
    - **Coluna 4**: "Writing Correct Programs" - Busca bin√°ria
    - **Coluna 9**: "Code Tuning" - Otimiza√ß√µes pr√°ticas
    - ISBN: 978-0201657883
    - *Discuss√µes sobre bugs comuns em busca bin√°ria*

29. **Bloch, J.** (2006). "Extra, Extra - Read All About It: Nearly All Binary Searches and Mergesorts are Broken". *Google Research Blog*.
    - URL: https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html
    - *Bug de overflow em implementa√ß√µes de busca bin√°ria*

### Hist√≥rico e Curiosidades

30. **Katajainen, J.** (2010). "In the Footsteps of a Giant: Donald Knuth at 72". *Theoretical Computer Science*, 412(1-2), 1-2.
    - DOI: 10.1016/j.tcs.2010.10.002
    - *Contribui√ß√µes de Knuth para an√°lise de algoritmos*

31. **Dijkstra, E. W.** (1982). "Why Numbering Should Start at Zero". EWD831.
    - URL: https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html
    - *Argumenta√ß√£o sobre indexa√ß√£o em arrays*

### Benchmarking e An√°lise Experimental

32. **McGeoch, C. C.** (2012). *A Guide to Experimental Algorithmics*. Cambridge University Press.
    - ISBN: 978-0521173018
    - *Metodologia para benchmarks e an√°lise emp√≠rica*

33. **Mitzenmacher, M., & Upfal, E.** (2005). *Probability and Computing: Randomized Algorithms and Probabilistic Analysis*. Cambridge University Press.
    - ISBN: 978-0521835404
    - *An√°lise probabil√≠stica de algoritmos*

### Normas e Padr√µes

34. **ISO/IEC 9899:2018**: Programming Languages ‚Äî C (C18)
    - *Padr√£o da linguagem C, incluindo comportamento de arrays*

35. **IEEE Std 754-2019**: IEEE Standard for Floating-Point Arithmetic
    - *Importante para busca interpolada com ponto flutuante*

### Notas Sobre Cita√ß√µes

**Como citar este material** (formato ABNT):
```
CAPARROZ, Prof. Luis. Algoritmos de Pesquisa em C. In: Estrutura de Dados em C. 
GitHub, 2024. Dispon√≠vel em: <https://github.com/profluiscaparroz/estrutura-dados-c>.
Acesso em: [data].
```

**Como citar** (formato APA):
```
Caparroz, L. (2024). Algoritmos de Pesquisa em C. In Estrutura de Dados em C. 
GitHub. https://github.com/profluiscaparroz/estrutura-dados-c
```

---

## üìñ Leitura Recomendada por N√≠vel

### Iniciante
- Sedgewick & Wayne (2011) - Cap√≠tulos 1 e 3
- Cormen et al. (2009) - Cap√≠tulo 2
- Programming Pearls - Coluna 4

### Intermedi√°rio
- Knuth (1998) - Se√ß√µes 6.2.1 e 6.2.2
- Cormen et al. (2009) - Cap√≠tulo 12
- Perl, Itai & Avni (1978) - Artigo sobre interpola√ß√£o

### Avan√ßado
- Aho, Hopcroft & Ullman (1974) - Limites inferiores
- Ben-Or (1983) - Complexidade alg√©brica
- Frigo et al. (1999) - Algoritmos cache-oblivious

### Pesquisa
- Willard (1983) - Busca sublogar√≠tmica
- van Emde Boas (1977) - Estruturas de dados avan√ßadas
- Andersson & Thorup (2000) - Limites apertados